## Symmetric Positive Definite (SPD) Matrices

### Introdução
Este capítulo se concentra em **matrizes simétricas definidas positivas (SPD)**, um tipo especial de matriz que desempenha um papel fundamental em várias áreas da matemática, estatística e engenharia [^278]. Exploraremos a definição formal de matrizes SPD [^278], suas propriedades essenciais e sua conexão com a decomposição de Cholesky [^278]. A discussão complementará os tópicos anteriores, como eliminação gaussiana, fatoração LU e outros métodos para resolver sistemas lineares, fornecendo uma perspectiva sobre como essas técnicas podem ser especializadas e otimizadas para matrizes SPD.

### Conceitos Fundamentais

**Definição:** Uma matriz real $A$ de tamanho $n \times n$ é chamada de **simétrica definida positiva (SPD)** se for simétrica e se $x^T A x > 0$ para todo vetor não nulo $x$ em $R^n$ [^278].

Esta definição compreende duas condições principais [^278]:
1. **Simetria:** $A = A^T$, ou seja, $a_{ij} = a_{ji}$ para todos os índices $i$ e $j$.
2. **Definitividade Positiva:** $x^T A x > 0$ para todo $x \in R^n$, $x \neq 0$. Esta condição implica que a forma quadrática associada à matriz $A$ é estritamente positiva para todos os vetores não nulos.

**Propriedades Importantes das Matrizes SPD [^278]:**

1. **Invertibilidade:** Uma matriz SPD é sempre invertível [^278]. Isso decorre do fato de que se $Ax = 0$, então $x^T A x = 0$, o que implica $x = 0$ devido à definitividade positiva. Portanto, o núcleo de $A$ é trivial, e $A$ é invertível.
2. **Autovalores Positivos:** Todos os autovalores de uma matriz SPD são positivos [^287].
3. **Decomposição de Cholesky:** Uma matriz SPD possui uma decomposição de Cholesky única, ou seja, existe uma matriz triangular inferior real $B$ com elementos diagonais positivos tal que $A = BB^T$ [^282].
4. **Convexidade:** O conjunto de matrizes SPD $n \times n$ reais é convexo [^278]. Isso significa que se $A$ e $B$ são matrizes SPD, então $(1 - \lambda)A + \lambda B$ também é SPD para qualquer $\lambda \in [0, 1]$.
5. **Cone:** O conjunto de matrizes SPD $n \times n$ reais forma um cone [^278]. Isso significa que se $A$ é SPD e $\lambda > 0$ é um escalar real, então $\lambda A$ também é SPD.

**Decomposição de Cholesky:**

A decomposição de Cholesky é uma ferramenta poderosa para trabalhar com matrizes SPD [^282]. Dado que $A$ é uma matriz SPD, podemos expressá-la como $A = BB^T$, onde $B$ é uma matriz triangular inferior com elementos diagonais positivos [^282]. O algoritmo para calcular $B$ é derivado diretamente da definição [^283]:

Para $j = 1, \dots, n$:
$$b_{jj} = \sqrt{a_{jj} - \sum_{k=1}^{j-1} b_{jk}^2}$$

Para $i = j+1, \dots, n$:
$$b_{ij} = \frac{a_{ij} - \sum_{k=1}^{j-1} b_{ik}b_{jk}}{b_{jj}}$$

**Proposição:** Se $A$ é uma matriz simétrica definida positiva real, então $A(1:k, 1:k)$ é simétrica definida positiva e, portanto, invertível para $k = 1, \dots, n$ [^278, 281].

**Prova:** Como $A$ é simétrica, cada $A(1:k, 1:k)$ também é simétrica [^281]. Seja $w \in R^k$, com $1 \leq k \leq n$. Definimos $x \in R^n$ como $x_i = w_i$ para $i = 1, \dots, k$ e $x_i = 0$ para $i = k+1, \dots, n$. Como $A$ é SPD, temos $x^TAx > 0$ para todo $x \neq 0$ em $R^n$. Claramente,
$$x^TAx = w^TA(1:k, 1:k)w$$
Isso implica que $A(1:k, 1:k)$ é simétrica definida positiva [^281]. Portanto, pelo fato 1 acima, $A(1:k, 1:k)$ também é invertível. $\blacksquare$

### Conclusão
As matrizes SPD são uma classe importante de matrizes com propriedades únicas e aplicações generalizadas. A definitividade positiva garante a invertibilidade e autovalores positivos, enquanto a simetria permite a aplicação da decomposição de Cholesky, facilitando a solução de sistemas lineares e problemas de otimização. A compreensão das propriedades e decomposições das matrizes SPD é essencial para muitos problemas em matemática aplicada e computação científica. <!-- END -->