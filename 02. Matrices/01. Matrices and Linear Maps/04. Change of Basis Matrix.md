## Capítulo 4: Matrizes e Aplicações Lineares
### 4.4 Efeito da Mudança de Base na Representação Matricial de Aplicações Lineares

### Introdução

Nos tópicos anteriores, estabelecemos como aplicações lineares $f: E \to F$ entre espaços vetoriais de dimensão finita podem ser representadas por matrizes, uma vez que bases para $E$ e $F$ são escolhidas [^1, ^2, ^4]. Especificamente, a matriz $M(f)$ tem suas colunas formadas pelas coordenadas das imagens dos vetores da base de $E$ na base de $F$ [^4]. Também introduzimos o conceito de **matriz de mudança de base**, $P$, que relaciona as coordenadas de um vetor em duas bases diferentes do mesmo espaço vetorial [^13, ^15]. Uma questão fundamental surge naturalmente: como a matriz $M(f)$ que representa uma aplicação linear $f$ se transforma quando mudamos as bases dos espaços vetoriais $E$ e $F$? Este capítulo explora essa transformação, detalhando como a representação matricial é afetada pela escolha das bases, preservando a natureza intrínseca da aplicação linear subjacente [^original_prompt_context]. Investigaremos o caso geral $f: E \to F$ e o caso particular importante $f: E \to E$.

### O Efeito Geral da Mudança de Bases

Consideremos a situação geral descrita na **Proposição 4.5** [^17]. Sejam $E$ e $F$ espaços vetoriais. Sejam $U = (u_1, \dots, u_n)$ e $U\' = (u\'_1, \dots, u\'_n)$ duas bases de $E$, e sejam $V = (v_1, \dots, v_m)$ e $V\' = (v\'_1, \dots, v\'_m)$ duas bases de $F$. Seja $f: E \to F$ uma aplicação linear qualquer. Denotamos por $M(f) = M_{U,V}(f)$ a matriz associada a $f$ em relação às bases $U$ e $V$, e por $M\'(f) = M_{U\',V\'}(f)$ a matriz associada a $f$ em relação às bases $U\'$ e $V\'$ [^17].

Introduzimos as matrizes de mudança de base. Seja $P = P_{U\',U}$ a matriz de mudança de base de $U$ para $U\'$ [^15]. Recordemos que as colunas de $P$ são as coordenadas dos vetores de $U\'$ expressos na base $U$ [^13]. Da mesma forma, seja $Q = P_{V\',V}$ a matriz de mudança de base de $V$ para $V\'$ [^15]. Note que a matriz de mudança de base de $V\'$ para $V$ é $Q^{-1} = P_{V,V\'}$ [^15]. A Proposição 4.5 estabelece a relação entre $M(f)$ e $M\'(f)$:

> **Proposição 4.5:** Nas condições acima, temos
> $$ M\'(f) = Q^{-1} M(f) P $$
> ou, mais explicitamente,
> $$ M_{U\',V\'}(f) = P_{V,V\'} M_{U,V}(f) P_{U\',U} $$
> [^17]

**Prova:** A aplicação linear $f: E \to F$ pode ser vista como a composição $f = id_F \circ f \circ id_E$, onde $id_E: E \to E$ e $id_F: F \to F$ são as aplicações identidade. Queremos a matriz de $f$ que leva coordenadas na base $U\'$ para coordenadas na base $V\'$. Podemos analisar a composição através do diagrama [^17]:

```mermaid
graph TD
    E_U[E (base U)] -- M(f) = M<sub>U,V</sub>(f) --> F_V[F (base V)]
    E_U_prime[E (base U\')] -- id<sub>E</sub> --> E_U
    F_V -- id<sub>F</sub> --> F_V_prime[F (base V\')]
    E_U_prime -- M\'(f) = M<sub>U\',V\'</sub>(f) --> F_V_prime

    subgraph "id_E: U\' -> U"
    E_U_prime -- P = P<sub>U\',U</sub> --> E_U
    end

    subgraph "f: U -> V"
     E_U -- M(f) --> F_V
    end

    subgraph "id_F: V -> V\'"
     F_V -- Q<sup>-1</sup> = P<sub>V,V\'</sub> --> F_V_prime
    end
```

A matriz de $id_E$ tomando a base $U\'$ em $E$ e a base $U$ em $E$ é $P = P_{U\',U}$ (transforma coordenadas de $U\'$ para $U$) - não, a Prova 4.5 afirma que $P = P_{U\',U}$ é a matriz de $id_E$ com respeito às bases $(u\'_1, \dots, u\'_n)$ e $(u_1, \dots, u_n)$ [^17]. No entanto, a definição 4.3 [^13] diz que $P=P_{U\',U}$ tem colunas $u\'_j$ na base $U$. A equação de coordenadas é $x_U = P x_{U\'}$ [^15]. A aplicação $id_E$ mapeia um vetor $x$ para si mesmo. Se $x$ tem coordenadas $x_{U\'}$ na base $U\'$ e $x_U$ na base $U$, então $id_E(x) = x$. A matriz $M_{U\',U}(id_E)$ transforma $x_{U\'}$ em $x_U$. De fato, $x_U = P x_{U\'}$, então $M_{U\',U}(id_E) = P = P_{U\',U}$.
Similarmente, a matriz de $id_F$ tomando a base $V$ em $F$ e a base $V\'$ em $F$ é $Q^{-1} = P_{V,V\'}$ [^17] (transforma coordenadas de $V$ para $V\'$).
A matriz de $f$ de $E$ (base $U$) para $F$ (base $V$) é $M(f) = M_{U,V}(f)$.
Pela **Proposição 4.2** [^10], a composição de aplicações lineares corresponde à multiplicação de suas matrizes nas bases apropriadas. Portanto, a matriz da aplicação composta $id_F \circ f \circ id_E$ em relação às bases $U\'$ (domínio) e $V\'$ (contradomínio) é o produto das matrizes:
$M_{U\',V\'}(f) = M_{V,V\'}(id_F) \cdot M_{U,V}(f) \cdot M_{U\',U}(id_E) = Q^{-1} M(f) P$.
Isto completa a prova [^17]. $\blacksquare$

### O Caso de Endomorfismos e Matrizes Similares

Um caso particularmente importante ocorre quando $E=F$, ou seja, $f$ é um endomorfismo $f: E \to E$. Neste caso, usualmente escolhemos a mesma base para o domínio e o contradomínio. Seja $U = (u_1, \dots, u_n)$ e $U\' = (u\'_1, \dots, u\'_n)$ duas bases de $E$. Seja $P = P_{U\',U}$ a matriz de mudança de base de $U$ para $U\'$. Seja $M(f) = M_U(f)$ a matriz de $f$ em relação à base $U$, e $M\'(f) = M_{U\'}(f)$ a matriz de $f$ em relação à base $U\'$. O **Corolário 4.6** [^17] é uma consequência direta da Proposição 4.5, tomando $E=F$, $U=V$ e $U\'=V\'$, de modo que $Q=P$.

> **Corolário 4.6:** Nas condições acima, para uma aplicação linear $f: E \to E$, temos
> $$ M\'(f) = P^{-1} M(f) P $$
> ou, mais explicitamente,
> $$ M_{U\'}(f) = P_{U,U\'} M_U(f) P_{U\',U} $$
> [^17]

O diagrama ilustrativo para este caso é [^18]:
```mermaid
graph TD
    E_U[E (base U)] -- M(f) = M<sub>U</sub>(f) --> E_U_copy[E (base U)]
    E_U_prime[E (base U\')] -- id<sub>E</sub> --> E_U
    E_U_copy -- id<sub>E</sub> --> E_U_prime_copy[E (base U\')]
    E_U_prime -- M\'(f) = M<sub>U\'</sub>(f) --> E_U_prime_copy

    subgraph "id_E: U\' -> U"
    E_U_prime -- P = P<sub>U\',U</sub> --> E_U
    end

    subgraph "f: U -> U"
     E_U -- M(f) --> E_U_copy
    end

    subgraph "id_E: U -> U\'"
     E_U_copy -- P<sup>-1</sup> = P<sub>U,U\'</sub> --> E_U_prime_copy
    end
```

Esta relação $M\'(f) = P^{-1} M(f) P$ motiva uma definição fundamental em álgebra linear.

> **Definição 4.5:** Duas matrizes quadradas $A, B \in M_n(K)$ são ditas **similares** (*similar*) se existe alguma matriz invertível $P$ tal que
> $$ B = P^{-1} A P $$
> [^18]

É fácil verificar que a similaridade é uma relação de equivalência [^18]. A importância desta definição advém diretamente do Corolário 4.6: *duas matrizes $n \times n$, $A$ e $B$, são similares se e somente se elas representam a mesma aplicação linear $f: E \to E$ em relação a duas bases diferentes $U$ e $U\'$ de $E$* [^18]. A matriz $P$ na definição de similaridade é precisamente a matriz de mudança de base $P = P_{U\',U}$ [^17].

O **Exemplo 4.3** [^18] ilustra este conceito. Seja $E = \mathbb{R}^2$, $U = (e_1, e_2)$ a base canônica, e $V = (v_1, v_2) = (e_1, e_1 - e_2)$ outra base. Considere a aplicação linear $f$ representada na base canônica pela matriz $A = \begin{pmatrix} 2 & 1 \\\\ 0 & 1 \end{pmatrix}$. A matriz de mudança de base de $U$ para $V$ é $P = P_{V,U} = \begin{pmatrix} 1 & 1 \\\\ 0 & -1 \end{pmatrix}$ [^18]. Sua inversa é $P^{-1} = P = \begin{pmatrix} 1 & 1 \\\\ 0 & -1 \end{pmatrix}$ [^18]. A matriz $A\'$ que representa $f$ na base $V$ é dada por:
$$ A\' = M_V(f) = P^{-1} A P = P A P = \begin{pmatrix} 1 & 1 \\\\ 0 & -1 \end{pmatrix} \begin{pmatrix} 2 & 1 \\\\ 0 & 1 \end{pmatrix} \begin{pmatrix} 1 & 1 \\\\ 0 & -1 \end{pmatrix} = \begin{pmatrix} 2 & 0 \\\\ 0 & 1 \end{pmatrix} = D $$
Esta matriz $A\' = D$ é diagonal [^18]. Na base $V$, a ação de $f$ é mais simples de entender: é uma dilatação por um fator 2 na direção de $v_1$ e a identidade na direção de $v_2$ [^18]. Este processo é conhecido como **diagonalização** da matriz $A$. As entradas diagonais 2 e 1 são os **eigenvalues** de $A$ (e de $f$), e $v_1, v_2$ são os **eigenvectors** correspondentes [^18]. Este exemplo mostra vividamente como uma mudança de base pode simplificar a representação matricial de uma aplicação linear, revelando sua estrutura geométrica.

É importante notar também como as matrizes de mudança de base se compõem. Se $U, V, W$ são três bases de $E$, e $P = P_{V,U}$ é a matriz de mudança de base de $U$ para $V$, e $Q = P_{W,V}$ é a matriz de mudança de base de $V$ para $W$, então a matriz de mudança de base de $U$ para $W$ é $PQ = P_{V,U} P_{W,V}$ [^20]. Esta propriedade é consistente com a composição de aplicações identidade e a multiplicação de matrizes.

### Conclusão

A representação matricial de uma aplicação linear $f: E \to F$ depende crucialmente das bases escolhidas para $E$ e $F$. Quando mudamos as bases de $U$ para $U\'$ em $E$ (com matriz de mudança $P=P_{U\',U}$) e de $V$ para $V\'$ em $F$ (com matriz $Q=P_{V\',V}$), a nova matriz $M\'(f)$ está relacionada à antiga $M(f)$ pela fórmula $M\'(f) = Q^{-1} M(f) P$ [^17]. No caso especial de um endomorfismo $f: E \to E$, usando bases $U$ e $U\'$ (com $P=P_{U\',U}$), a relação torna-se $M\'(f) = P^{-1} M(f) P$ [^17]. Este resultado leva diretamente ao conceito de **matrizes similares**, que são precisamente as matrizes que representam a mesma aplicação linear $f: E \to E$ sob diferentes bases [^18]. Embora as matrizes mudem com a base, a aplicação linear subjacente permanece a mesma. Como enfatizado no texto de referência [^21]:

> *linear maps are more fundamental because they are intrinsic objects that do not depend on the choice of bases.*

Compreender como a representação matricial muda permite-nos escolher bases que simplifiquem a matriz (e.g., diagonalização) e revelem propriedades geométricas da aplicação linear.

### Referências
[^1]: Capítulo 4, p. 113: Proposition 3.18 shows that given two vector spaces E and F and a basis (uj)jej of E, every linear map f: E → F is uniquely determined by the family (f(uj))jej of the images under f of the vectors in the basis (uj)j∈J.
[^2]: Capítulo 4, p. 113: If we also have a basis (vi)iel of F, then every vector f(uj) can be written in a unique way as f(uj) = ∑i∈I aijvi, where j ∈ J, for a family of scalars (aij)i∈I. Thus, with respect to the two bases (uj)j∈J of E and (vi)iel of F, the linear map f is completely determined by a “I × J-matrix” M(f) = (aij)(i,j)∈I×J.
[^3]: Capítulo 4, p. 114: When E and F have finite dimension, linear maps can be very conveniently represented by matrices... Let f: E → F be a linear map between E and F. Then for every x = x1u1 + ··· + xnun in E, by linearity, we have f(x) = x1f(u1) + ··· + xnf(un). Let f(uj) = ∑i=1^m aijvi for every j, 1 ≤ j ≤ n. This can be expressed by writing the coefficients a1j, a2j,..., amj of f(uj) over the basis (v1, ..., vm), as the jth column of a matrix...\
[^4]: Capítulo 4, p. 116: Definition 4.1. Let E and F be two vector spaces, and let (u1,..., un) be a basis for E, and (v1,..., vm) be a basis for F... Every linear map f: E → F is represented by the matrix M(f) = (aij), where aij is the i-th component of the vector f(uj) over the basis (v1, ..., vm), i.e., where f(uj) = ∑i=1^m aijvi, for every j, 1 ≤ j ≤ n. The coefficients a1j, a2j,..., amj of f(uj) over the basis (v1,..., vm) form the jth column of the matrix M(f)... The matrix M(f) associated with the linear map f : E → F is called the matrix of f with respect to the bases (u1,..., un) and (v1,..., vm). When E = F and the basis (v1,..., vm) is identical to the basis (u1,..., un) of E, the matrix M(f) associated with f: E → E (as above) is called the matrix of f with respect to the basis (u1, ..., un).
[^10]: Capítulo 4, p. 120: Identity (4) shows that the composition of linear maps corresponds to the product of matrices. ... Proposition 4.2 ... M(f ◦ g) = M(f)M(g).
[^13]: Capítulo 4, p. 125: Definition 4.3. Given a vector space E of dimension n, for any two bases (u1,..., un) and (v1,..., vn) of E, let P = (aij) be the invertible matrix defined such that vj = ∑i=1^n aijui which is also the matrix of the identity id: E → E with respect to the bases (v1, . . ., vn) and (u1,..., un), in that order. ... The matrix P is called the change of basis matrix from (u1,..., un) to (v1,..., vn).
[^15]: Capítulo 4, p. 127: Definition 4.4. The change of basis matrix from U to V is denoted P<sub>V,U</sub>. Note that P<sub>U,V</sub> = P<sub>V,U</sub><sup>-1</sup>. Then, if we write x<sub>U</sub> = (x1,...,xn) for the old coordinates of x with respect to the basis U and x<sub>V</sub> = (x\'1,...,x\'n) for the new coordinates of x with respect to the basis V, we have x<sub>U</sub> = P<sub>V,U</sub> x<sub>V</sub>, x<sub>V</sub> = P<sub>V,U</sub><sup>-1</sup> x<sub>U</sub> = P<sub>U,V</sub> x<sub>U</sub>.
[^17]: Capítulo 4, p. 129: Proposition 4.5. Let E and F be vector spaces, let U = (u1,..., un) and U\' = (u\'1, ..., u\'n) be two bases of E, and let V = (v1,..., vm) and V\' = (v\'1,..., v\'m) be two bases of F. Let P = P<sub>U\',U</sub> be the change of basis matrix from U to U\', and let Q = P<sub>V\',V</sub> be the change of basis matrix from V to V\'. For any linear map f : E → F, let M(f) = M<sub>U,V</sub>(f) be the matrix associated to f w.r.t. the bases U and V, and let M\'(f) = M<sub>U\',V\'</sub>(f) be the matrix associated to f w.r.t. the bases U\' and V\'. We have M\'(f) = Q<sup>-1</sup>M(f)P, or more explicitly M<sub>U\',V\'</sub>(f) = P<sub>V,V\'</sub> M<sub>U,V</sub>(f) P<sub>U\',U</sub>. Proof. Since f : E → F can be written as f = id<sub>F</sub> ◦ f ◦ id<sub>E</sub>, since P = P<sub>U\',U</sub> is the matrix of id<sub>E</sub> w.r.t. the bases (u\'1,..., u\'n) and (u1,..., un), and Q<sup>-1</sup> = P<sub>V,V\'</sub> is the matrix of id<sub>F</sub> w.r.t. the bases (v1, ..., vm) and (v\'1,..., v\'m) as illustrated by the following diagram ... by Proposition 4.2, we have M\'(f) = Q<sup>-1</sup>M(f)P. ... Corollary 4.6. Let E be a vector space, and let U = (u1, ..., un) and U\' = (u\'1,..., u\'n) be two bases of E. Let P = P<sub>U\',U</sub> be the change of basis matrix from U to U\'. For any linear map f : E → E, let M(f) = M<sub>U</sub>(f) be the matrix associated to f w.r.t. the basis U, and let M\'(f) = M<sub>U\'</sub>(f) be the matrix associated to f w.r.t. the basis U\'. We have M\'(f) = P<sup>-1</sup>M(f)P, or more explicitly, M<sub>U\'</sub>(f) = P<sub>U,U\'</sub> M<sub>U</sub>(f) P<sub>U\',U</sub>.
[^18]: Capítulo 4, p. 130: as illustrated by the following diagram ... Example 4.3. Let E = R^2, U = (e1, e2) ... V = (v1, v2) = (e1, e1 - e2) ... A = [[2, 1], [0, 1]]. The change of basis matrix P = P<sub>V,U</sub> from U to V is P = [[1, 1], [0, -1]]. ... P<sup>-1</sup> = P. Therefore, in the basis V, the matrix representing the linear map f defined by A is A\' = P<sup>-1</sup>AP = PAP = ... = [[2, 0], [0, 1]] = D, a diagonal matrix. In the basis V, it is clear what the action of f is: it is a stretch by a factor of 2 in the v1 direction and it is the identity in the v2 direction. ... What happened is that we diagonalized the matrix A. The diagonal entries 2 and 1 are the eigenvalues of A (and f), and v1 and v2 are corresponding eigenvectors. ... Definition 4.5. Two n×n matrices A and B are said to be similar iff there is some invertible matrix P such that B = P<sup>-1</sup>AP. It is easily checked that similarity is an equivalence relation. From our previous considerations, two n × n matrices A and B are similar iff they represent the same linear map with respect to two different bases.
[^19]: Capítulo 4, p. 131: If U = (u1, ..., un) and V = (v1,..., vn) are two bases of E, the change of basis matrix P = P<sub>V,U</sub> = (aij) ... means that vj = ∑i=1^n aijui. It is natural to extend the matrix notation... but notice that the matrix involved is not P, but its transpose P<sup>T</sup>. ... This observation has the following consequence: if U = (u1, . . ., un) and V = (v1, ..., vn) are two bases of E and if (v1 ... vn)<sup>T</sup> = A (u1 ... un)<sup>T</sup>, that is, vi = ∑j=1^n aijuj...\
[^20]: Capítulo 4, p. 132: Also, if U = (u1,..., un), V = (v1, ..., vn), and W = (w1,..., wn) are three bases of E, and if the change of basis matrix from U to V is P = P<sub>V,U</sub> and the change of basis matrix from V to W is Q = P<sub>W,V</sub>, then ... which means that the change of basis matrix P<sub>W,U</sub> from U to W is PQ. This proves that P<sub>W,U</sub> = P<sub>V,U</sub>P<sub>W,V</sub>.
[^21]: Capítulo 4, p. 133: Even though matrices are indispensable ... one should not lose track of the fact that *linear maps are more fundamental because they are intrinsic objects that do not depend on the choice of bases*. Consequently, we advise the reader to try to think in terms of linear maps rather than reduce everything to matrices. ... After all, *a matrix is a representation of a linear map*, and most decompositions of a matrix reflect the fact that with a suitable choice of a basis (or bases), the linear map is a represented by a matrix having a special shape. ... Also, always try to keep in mind that *linear maps are geometric in nature; they act on space*.

<!-- END -->