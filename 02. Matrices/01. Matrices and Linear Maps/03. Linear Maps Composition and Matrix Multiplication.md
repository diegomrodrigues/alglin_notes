## Capítulo 4.2: Composição de Aplicações Lineares e Multiplicação Matricial

### Introdução

Continuando a exploração das **matrizes e aplicações lineares**, como detalhado na Seção 4.1 [^1, ^2, ^3, ^4], estabelecemos que toda aplicação linear $f: E \\to F$ entre espaços vetoriais de dimensão finita pode ser univocamente representada por uma matriz $M(f)$ com respeito a bases fixadas em $E$ e $F$. Vimos que a $j$-ésima coluna da matriz $M(f)$ é formada pelas componentes do vetor $f(u_j)$ na base de $F$, onde $u_j$ é o $j$-ésimo vetor da base de $E$ [^2, ^4]. Esta representação matricial transforma a ação da aplicação linear $f$ sobre um vetor $x$ na multiplicação da matriz $M(f)$ pelo vetor coluna $M(x)$ que representa $x$ [^3, ^8]. Este capítulo aprofunda essa conexão, demonstrando formalmente que a **composição de aplicações lineares** corresponde diretamente à **multiplicação das matrizes** que as representam. Esta correspondência é uma ferramenta poderosa para analisar sequências de transformações lineares e seu efeito combinado.

### A Correspondência entre Composição e Multiplicação

Consideremos agora como a composição de aplicações lineares se expressa em termos das bases e das matrizes associadas. Sejam $E$, $F$, e $G$ três espaços vetoriais sobre um corpo $K$, com respectivas bases finitas $U = (u_1, \\dots, u_p)$ para $E$, $V = (v_1, \\dots, v_n)$ para $F$, e $W = (w_1, \\dots, w_m)$ para $G$ [^6]. Sejam $g: E \\to F$ e $f: F \\to G$ duas aplicações lineares [^6].

Conforme estabelecido anteriormente [^1, ^2], a aplicação $g$ é determinada pelas imagens dos vetores da base $U$, e $f$ é determinada pelas imagens dos vetores da base $V$. Seja $B = (b_{kj})$ a matriz $n \\times p$ que representa $g$ com respeito às bases $U$ e $V$, de modo que para cada $j = 1, \\dots, p$:
$$ g(u_j) = \\sum_{k=1}^{n} b_{kj} v_k $$
Esta é a matriz $M(g)$ na notação anterior, onde a $j$-ésima coluna de $B$ contém as coordenadas de $g(u_j)$ na base $V$ [^6, ^7].

Analogamente, seja $A = (a_{ik})$ a matriz $m \\times n$ que representa $f$ com respeito às bases $V$ e $W$, de modo que para cada $k = 1, \\dots, n$:
$$ f(v_k) = \\sum_{i=1}^{m} a_{ik} w_i $$
Esta é a matriz $M(f)$, onde a $k$-ésima coluna de $A$ contém as coordenadas de $f(v_k)$ na base $W$ [^6, ^7].

Nosso objetivo é determinar a matriz que representa a aplicação composta $h = f \\circ g: E \\to G$ com respeito às bases $U$ e $W$. Para isso, calculamos a imagem de cada vetor da base $u_j$ de $E$ sob a aplicação $h$:
$$ h(u_j) = (f \\circ g)(u_j) = f(g(u_j)) $$
Utilizando a linearidade de $f$ e a expressão para $g(u_j)$, temos:
$$ f(g(u_j)) = f\\left(\\sum_{k=1}^{n} b_{kj} v_k\\right) = \\sum_{k=1}^{n} b_{kj} f(v_k) $$
Agora, substituindo a expressão para $f(v_k)$:
$$ \\sum_{k=1}^{n} b_{kj} f(v_k) = \\sum_{k=1}^{n} b_{kj} \\left(\\sum_{i=1}^{m} a_{ik} w_i\\right) $$
Reagrupando os termos para obter uma combinação linear dos vetores $w_i$ da base $W$:
$$ h(u_j) = \\sum_{i=1}^{m} \\left(\\sum_{k=1}^{n} a_{ik} b_{kj}\\right) w_i $$
Este resultado nos mostra que a imagem $h(u_j)$ do $j$-ésimo vetor da base $U$ é uma combinação linear dos vetores da base $W$. Por definição da matriz de uma aplicação linear [^2, ^4], a $j$-ésima coluna da matriz $M(h)$ que representa $h = f \\circ g$ com respeito às bases $U$ e $W$ é composta pelos coeficientes desta combinação linear. Portanto, a entrada na $i$-ésima linha e $j$-ésima coluna da matriz $M(h)$, que denotaremos por $c_{ij}$, é dada por [^7]:
$$ c_{ij} = \\sum_{k=1}^{n} a_{ik} b_{kj} $$
Reconhecemos esta expressão como a definição da entrada $(i, j)$ do produto das matrizes $A$ e $B$ [^8]. Ou seja, se $C = AB$, então $C = (c_{ij})$. Assim, demonstramos que a matriz que representa a composição $f \\circ g$ é o produto das matrizes que representam $f$ e $g$, na ordem correspondente:

> **Teorema:** Sejam $g: E \\to F$ e $f: F \\to G$ aplicações lineares, com $U, V, W$ sendo bases finitas de $E, F, G$ respectivamente. Se $A = M_{V,W}(f)$ é a matriz de $f$ com respeito às bases $V$ e $W$, e $B = M_{U,V}(g)$ é a matriz de $g$ com respeito às bases $U$ e $V$, então a matriz $C = M_{U,W}(f \\circ g)$ da aplicação composta $f \\circ g: E \\to G$ com respeito às bases $U$ e $W$ é dada pelo produto matricial $C = AB$. Isto é:
> $$ M_{U,W}(f \\circ g) = M_{V,W}(f) M_{U,V}(g) $$
> [^8, ^10]

É importante notar a ordem da composição e da multiplicação matricial. A escolha de considerar $g: E \\to F$ e $f: F \\to G$ resulta na composição $f \\circ g$ sendo representada pelo produto $AB = M(f)M(g)$ [^6]. Se tivéssemos considerado $f: E \\to F$ e $g: F \\to G$, a composição $g \\circ f$ seria representada pelo produto $BA = M(g)M(f)$ [^6]. A convenção adotada aqui, $f \\circ g$ correspondendo a $M(f)M(g)$, é frequentemente preferida por alinhar a ordem da aplicação das matrizes aos vetores coluna (da direita para a esquerda) com a ordem da composição funcional [^6].

### Transferência de Propriedades e Isomorfismo

A correspondência entre composição e multiplicação matricial é fundamental, pois permite transferir propriedades das operações com aplicações lineares para as operações com matrizes, e vice-versa [^9]. Uma ilustração importante disso é a prova da **associatividade da multiplicação matricial**, apresentada na Proposição 4.1(1) [^9].

**Proposição 4.1 (Extrato - Associatividade):** Dadas quaisquer matrizes $A \\in M_{m,n}(K)$, $B \\in M_{n,p}(K)$, e $C \\in M_{p,q}(K)$, temos $(AB)C = A(BC)$ [^9].

*Demonstração (Esboço via Aplicações Lineares):* Cada matriz $A, B, C$ define uma aplicação linear $f_A: K^n \\to K^m$, $f_B: K^p \\to K^n$, $f_C: K^q \\to K^p$ com respeito às bases canônicas, tal que $M(f_A) = A$, $M(f_B) = B$, $M(f_C) = C$ [^9]. Usando o teorema acima, temos $M(f_A \\circ f_B) = M(f_A)M(f_B) = AB$ e $M(f_B \\circ f_C) = M(f_B)M(f_C) = BC$ [^9]. Então,
$$ M((f_A \\circ f_B) \\circ f_C) = M(f_A \\circ f_B) M(f_C) = (AB)C $$
$$ M(f_A \\circ (f_B \\circ f_C)) = M(f_A) M(f_B \\circ f_C) = A(BC) $$
Como a composição de funções é associativa, $(f_A \\circ f_B) \\circ f_C = f_A \\circ (f_B \\circ f_C)$ [^10]. Uma vez que a representação matricial de uma aplicação linear é única para bases fixadas, as matrizes resultantes devem ser iguais: $(AB)C = A(BC)$ [^10]. $\\blacksquare$

Da mesma forma, as propriedades de **bilinearidade** da multiplicação matricial, como $(A+B)C = AC + BC$ e $A(C+D) = AC + AD$ [^9], podem ser demonstradas relacionando-as às propriedades de adição e composição de aplicações lineares [^10].

A função $M$ que associa a cada aplicação linear $f \\in \\text{Hom}(E, F)$ sua matriz $M(f)$ (com respeito a bases fixas $U$ de $E$ e $V$ de $F$) é mais do que uma simples correspondência; é um **isomorfismo de espaços vetoriais**, como afirmado na Proposição 4.2 [^10].

**Proposição 4.2 (Extrato):** A aplicação $M: \\text{Hom}(E, F) \\to M_{m,n}(K)$ (onde $m = \\dim F, n = \\dim E$) satisfaz $M(g+h) = M(g) + M(h)$, $M(\\lambda g) = \\lambda M(g)$, e $M(f \\circ g) = M(f)M(g)$ (quando as dimensões e espaços são compatíveis para a composição). Além disso, $M$ é bijetora [^10, ^11].

Este isomorfismo significa que o estudo de aplicações lineares entre espaços de dimensão finita é algebricamente equivalente ao estudo de matrizes. A propriedade $M(f \\circ g) = M(f)M(g)$ é crucial, pois mostra que a estrutura algébrica da composição é preservada na multiplicação matricial [^11]. Quando $E=F$ (e $U=V$), $M: \\text{Hom}(E, E) \\to M_n(K)$ torna-se um isomorfismo de anéis (e de álgebras) [^10, ^11].

Utilizando a notação introduzida na Definição 4.2 [^9], $M_{U,V}(f)$ denota a matriz de $f: E \\to F$ com respeito às bases $U$ e $V$. A ação de $f$ sobre $x \\in E$ para produzir $y = f(x) \\in F$ é expressa na forma matricial como $y_V = M_{U,V}(f) x_U$, onde $x_U$ e $y_V$ são os vetores coluna das coordenadas de $x$ e $y$ nas bases $U$ e $V$, respectivamente [^9]. Nesta notação, a composição $h = f \\circ g$ resulta na equação de coordenadas $z_W = M_{V,W}(f) y_V = M_{V,W}(f) (M_{U,V}(g) x_U) = (M_{V,W}(f) M_{U,V}(g)) x_U$, o que reafirma visualmente que $M_{U,W}(f \\circ g) = M_{V,W}(f) M_{U,V}(g)$.

### Conclusão

A correspondência direta entre a **composição de aplicações lineares** e a **multiplicação de matrizes** é um dos pilares da álgebra linear. Como demonstrado, a matriz que representa a aplicação composta $f \\circ g$ é precisamente o produto das matrizes $M(f)$ e $M(g)$, na ordem $M(f)M(g)$, assumindo a convenção de que $g$ é aplicada primeiro [^6, ^8]. Esta equivalência não é apenas computacionalmente útil, mas também conceitualmente poderosa, permitindo a transferência de propriedades estruturais, como associatividade e bilinearidade, entre o mundo das funções e o mundo das matrizes [^9, ^10]. O isomorfismo estabelecido pela Proposição 4.2 [^10, ^11] formaliza essa equivalência, solidificando a matriz como uma representação algébrica fiel da aplicação linear, inclusive no que diz respeito à operação de composição. Este resultado é essencial para análises mais avançadas e para a compreensão da estrutura algébrica subjacente às transformações lineares. Como enfatizado no contexto, embora as matrizes sejam ferramentas indispensáveis, é fundamental lembrar que as aplicações lineares são os objetos intrínsecos e geométricos, enquanto as matrizes são suas representações dependentes de base [^21].

### Referências
[^1]: Página 113, Início do Capítulo 4, Definição de espaços vetoriais sobre K.
[^2]: Página 113, Seção 4.1, Definição da matriz M(f) = (a_ij) onde f(u_j) = Σ a_ij v_i.
[^3]: Página 115, Equação (1), y_i = Σ a_ij x_j.
[^4]: Página 116, Definição 4.1 e a matriz M(f) com colunas sendo f(u_j).
[^5]: Página 117, Exemplo de cálculo de M(y) = M(f)M(x).
[^6]: Página 118, Seção 4.2, Setup com E, F, G, bases U, V, W, mapas g: E->F, f: F->G e suas representações matriciais A=M(f), B=M(g). Discussão sobre a ordem f o g vs g o f.
[^7]: Página 119, Derivação de z_i = Σ_j (Σ_k a_ik b_kj) x_j.
[^8]: Página 120, Definição de c_ij = Σ_k a_ik b_kj e conclusão que M(f o g) = C = AB = M(f)M(g) via Identidade (4). Relação y = f(x) e M(y) = M(f)M(x).
[^9]: Página 121, Definição 4.2 de M_{U,V}(f), y_V = M_{U,V}(f) x_U. Proposição 4.1(1) Associatividade (AB)C = A(BC), (2) Bilinearidade. Prova da associatividade via M(f_A o f_B) = AB.
[^10]: Página 122, Prova da associatividade concluída usando a associatividade da composição de funções. Prova da bilinearidade (A+B)C = AC+BC. Proposição 4.2 sobre M ser isomorfismo e M(f o g) = M(f)M(g).
[^11]: Página 123, Conclusão da Proposição 4.2, M é isomorfismo, M(f o g) = M(f)M(g).
[^12]: Página 124, Proposição 4.3 e 4.4 sobre matriz de mudança de base e invertibilidade.
[^13]: Página 125, Definição 4.3 da matriz de mudança de base P.
[^14]: Página 126, Relação entre coordenadas antigas e novas x = Px'.
[^15]: Página 127, Notação P_{V,U} para mudança de base.
[^16]: Página 128, Exemplos de mudança de base.
[^17]: Página 129, Proposição 4.5 sobre como M(f) muda com a mudança de base: M'(f) = Q⁻¹ M(f) P. Corolário 4.6 para E=F.
[^18]: Página 130, Exemplo de diagonalização e Definição 4.5 de matrizes similares.
[^19]: Página 131, Relação entre mudança de base e transposta.
[^20]: Página 132, Propriedade P_{W,U} = P_{V,U} P_{W,V}.
[^21]: Página 133, Discussão sobre a importância fundamental das aplicações lineares sobre as matrizes.
[^22]: Página 134, Sumário e Problemas.
<!-- END -->