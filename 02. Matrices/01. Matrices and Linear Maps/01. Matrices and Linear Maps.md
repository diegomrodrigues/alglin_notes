## Capítulo 4.1: Representação Matricial de Aplicações Lineares

### Introdução

Como estabelecido anteriormente (Proposição 3.18 [^1]), uma **aplicação linear** $f: E \to F$ entre dois espaços vetoriais $E$ e $F$ sobre um corpo $K$ é unicamente determinada pela sua ação sobre uma base de $E$. Especificamente, dada uma base $(u_j)_{j \in J}$ de $E$, a família de imagens $(f(u_j))_{j \in J}$ em $F$ define completamente a aplicação $f$ [^1]. Este capítulo explora como essa propriedade fundamental permite representar aplicações lineares através de **matrizes**, estabelecendo uma ponte crucial entre a álgebra linear abstrata e a álgebra matricial, especialmente em espaços de dimensão finita. Assumiremos, para concretude, que $K = \mathbb{R}$, embora a teoria se aplique a um corpo $K$ arbitrário [^1].

### Conceitos Fundamentais: A Matriz Associada a uma Aplicação Linear

Seja $f: E \to F$ uma aplicação linear. Consideremos uma base $(u_j)_{j \in J}$ para o espaço vetorial $E$ e uma base $(v_i)_{i \in I}$ para o espaço vetorial $F$ [^1]. Para cada vetor $u_j$ da base de $E$, sua imagem $f(u_j)$ pertence a $F$. Como $(v_i)_{i \in I}$ é uma base de $F$, cada vetor $f(u_j)$ pode ser escrito de forma única como uma combinação linear dos vetores $v_i$ [^1]:
$$ f(u_j) = \sum_{i \in I} a_{ij} v_i $$
onde $j \in J$ e $(a_{ij})_{i \in I}$ é uma família de escalares em $K$ [^1].

A coleção de todos esses escalares, indexada por $(i, j) \in I \times J$, define completamente a aplicação linear $f$ com respeito às bases escolhidas [^1]. Organizamos esses escalares numa **matriz** $M(f)$, denominada a **matriz de $f$ com respeito às bases $(u_j)_{j \in J}$ e $(v_i)_{i \in I}$**. Esta matriz é definida como $M(f) = (a_{ij})_{(i,j) \in I \times J}$ [^1].

No caso particularmente importante em que $E$ e $F$ têm dimensão finita, digamos $\dim(E) = n$ e $\dim(F) = m$, podemos escolher bases finitas $(u_1, \dots, u_n)$ para $E$ e $(v_1, \dots, v_m)$ para $F$ [^1]. Neste cenário, a matriz $M(f)$ é uma matriz $m \times n$. A definição acima implica que para cada $j$ (onde $1 \le j \le n$), o vetor $f(u_j)$ é dado por:
$$ f(u_j) = a_{1j} v_1 + a_{2j} v_2 + \dots + a_{mj} v_m = \sum_{i=1}^m a_{ij} v_i $$
Os coeficientes $a_{1j}, a_{2j}, \dots, a_{mj}$ de $f(u_j)$ na base $(v_1, \dots, v_m)$ formam a **j-ésima coluna** da matriz $M(f)$ [^1, ^2, ^4]. Explicitamente, a matriz $M(f)$ tem a forma:

$$
M(f) =
\begin{pmatrix}
a_{11} & a_{12} & \cdots & a_{1n} \\\\
a_{21} & a_{22} & \cdots & a_{2n} \\\\
\vdots & \vdots & \ddots & \vdots \\\\
a_{m1} & a_{m2} & \cdots & a_{mn}
\end{pmatrix}
\begin{matrix}
\leftarrow v_1 \\\\
\leftarrow v_2 \\\\
\vdots \\\\
\leftarrow v_m
\end{matrix}
$$
$$
\begin{matrix}
\uparrow & \uparrow & & \uparrow \\\\
f(u_1) & f(u_2) & \cdots & f(u_n)
\end{matrix}
$$

Esta estrutura visual [^2, ^4] reforça que a j-ésima coluna de $M(f)$ representa as coordenadas do vetor imagem $f(u_j)$ na base do contradomínio $F$.

**Definição 4.1:** Sejam $E$ e $F$ dois espaços vetoriais com bases finitas $U = (u_1, \dots, u_n)$ e $V = (v_1, \dots, v_m)$, respetivamente. A **matriz da aplicação linear $f: E \to F$ com respeito às bases $U$ e $V$** é a matriz $m \times n$, denotada por $M(f)$ (ou mais explicitamente $M_{U,V}(f)$ [^8, ^9]), cujas entradas $(a_{ij})$ são definidas por $f(u_j) = \sum_{i=1}^m a_{ij} v_i$, para cada $j = 1, \dots, n$ [^4]. O escalar $a_{ij}$ é a $i$-ésima componente (ou coordenada) do vetor $f(u_j)$ na base $V$ [^4]. Quando $E = F$ e as bases são idênticas, $U=V$, a matriz $M(f)$ é dita **matriz de $f$ com respeito à base $U$** [^4].

### Representação de Vetores e a Ação da Matriz

A representação matricial estende-se naturalmente aos próprios vetores. Um vetor $x \in E$, expresso unicamente na base $U$ como $x = x_1 u_1 + \dots + x_n u_n$ [^2], pode ser representado pela **matriz coluna** de suas coordenadas:
$$ M(x) = \begin{pmatrix} x_1 \\\\ \vdots \\\\ x_n \end{pmatrix} $$
Similarmente, um vetor $y \in F$, expresso como $y = y_1 v_1 + \dots + y_m v_m$ [^2], é representado por:
$$ M(y) = \begin{pmatrix} y_1 \\\\ \vdots \\\\ y_m \end{pmatrix} $$
A importância da matriz $M(f)$ reside na forma como ela relaciona as coordenadas de $x$ com as coordenadas de sua imagem $y = f(x)$. Pela linearidade de $f$, temos [^2]:
$$ f(x) = f\left(\sum_{j=1}^n x_j u_j\right) = \sum_{j=1}^n x_j f(u_j) $$
Substituindo a expressão de $f(u_j)$ na base $V$:
$$ f(x) = \sum_{j=1}^n x_j \left(\sum_{i=1}^m a_{ij} v_i\right) $$
Reagrupando os termos em relação aos vetores da base $V$, obtemos [^3]:
$$ f(x) = \sum_{i=1}^m \left(\sum_{j=1}^n a_{ij} x_j\right) v_i $$
Como $y = f(x) = \sum_{i=1}^m y_i v_i$, pela unicidade das coordenadas, concluímos que as coordenadas $y_i$ de $f(x)$ são dadas por [^3]:
$$ y_i = \sum_{j=1}^n a_{ij} x_j \quad \text{para todo } i, 1 \le i \le m $$
Esta é precisamente a definição da **multiplicação de matrizes**. A relação $y = f(x)$ no nível dos espaços vetoriais corresponde à equação matricial entre as coordenadas [^8]:
$$ M(y) = M(f) M(x) $$
ou, em notação explícita:
$$ \begin{pmatrix} y_1 \\\\ \vdots \\\\ y_m \end{pmatrix} = \begin{pmatrix} a_{11} & \cdots & a_{1n} \\\\ \vdots & \ddots & \vdots \\\\ a_{m1} & \cdots & a_{mn} \end{pmatrix} \begin{pmatrix} x_1 \\\\ \vdots \\\\ x_n \end{pmatrix} $$
Esta equação [^8] demonstra que a aplicação linear $f$ pode ser computacionalmente realizada através da multiplicação da matriz $M(f)$ pelo vetor de coordenadas de $x$.

**Exemplo Concreto (n=3, m=2):**
Consideremos $f: E \to F$ com $\dim(E)=3$, $\dim(F)=2$. Bases $U=(u_1, u_2, u_3)$ e $V=(v_1, v_2)$.
Temos $f(u_1) = a_{11}v_1 + a_{21}v_2$, $f(u_2) = a_{12}v_1 + a_{22}v_2$, $f(u_3) = a_{13}v_1 + a_{23}v_2$ [^3].
A matriz é $M(f) = \begin{pmatrix} a_{11} & a_{12} & a_{13} \\\\ a_{21} & a_{22} & a_{23} \end{pmatrix}$ [^3].
Para $x = x_1u_1 + x_2u_2 + x_3u_3$, temos $f(x) = x_1f(u_1) + x_2f(u_2) + x_3f(u_3)$ [^3].
Substituindo e agrupando, obtemos $f(x) = (a_{11}x_1 + a_{12}x_2 + a_{13}x_3)v_1 + (a_{21}x_1 + a_{22}x_2 + a_{23}x_3)v_2$ [^3].
Se $y = f(x) = y_1v_1 + y_2v_2$, então $y_1 = a_{11}x_1 + a_{12}x_2 + a_{13}x_3$ e $y_2 = a_{21}x_1 + a_{22}x_2 + a_{23}x_3$ [^3].
Isto corresponde exatamente à equação matricial $\begin{pmatrix} y_1 \\\\ y_2 \end{pmatrix} = \begin{pmatrix} a_{11} & a_{12} & a_{13} \\\\ a_{21} & a_{22} & a_{23} \end{pmatrix} \begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \end{pmatrix}$ [^3].

### Exemplo: A Matriz da Derivada

Seja $E = \mathbb{R}[X]_4$, o espaço vetorial dos polinómios de grau no máximo 4, e $F = \mathbb{R}[X]_3$, o espaço dos polinómios de grau no máximo 3 [^5]. Consideremos a aplicação linear $d: E \to F$ que calcula a derivada de um polinómio [^4]. Escolhemos a base canónica $U = (1, x, x^2, x^3, x^4)$ para $E$ e $V = (1, x, x^2, x^3)$ para $F$ [^5].
Para encontrar a matriz $D = M(d)$ com respeito a estas bases, calculamos a imagem de cada vetor da base $U$ e expressamo-la na base $V$:
$d(1) = 0 = 0 \cdot 1 + 0 \cdot x + 0 \cdot x^2 + 0 \cdot x^3$
$d(x) = 1 = 1 \cdot 1 + 0 \cdot x + 0 \cdot x^2 + 0 \cdot x^3$
$d(x^2) = 2x = 0 \cdot 1 + 2 \cdot x + 0 \cdot x^2 + 0 \cdot x^3$
$d(x^3) = 3x^2 = 0 \cdot 1 + 0 \cdot x + 3 \cdot x^2 + 0 \cdot x^3$
$d(x^4) = 4x^3 = 0 \cdot 1 + 0 \cdot x + 0 \cdot x^2 + 4 \cdot x^3$
As colunas da matriz $D$ são os vetores de coordenadas destas imagens [^5]:
$$ D = \begin{pmatrix} 0 & 1 & 0 & 0 & 0 \\\\ 0 & 0 & 2 & 0 & 0 \\\\ 0 & 0 & 0 & 3 & 0 \\\\ 0 & 0 & 0 & 0 & 4 \end{pmatrix} $$
Se considerarmos o polinómio $P(x) = 3x^4 - 5x^3 + x^2 - 7x + 5 \in E$, o seu vetor de coordenadas na base $U$ é $M(P) = (5, -7, 1, -5, 3)^T$ [^5]. A sua derivada é $dP(x) = 12x^3 - 15x^2 + 2x - 7 \in F$, com vetor de coordenadas $M(dP) = (-7, 2, -15, 12)^T$ [^5]. Verificamos a relação $M(dP) = D M(P)$:
$$ \begin{pmatrix} 0 & 1 & 0 & 0 & 0 \\\\ 0 & 0 & 2 & 0 & 0 \\\\ 0 & 0 & 0 & 3 & 0 \\\\ 0 & 0 & 0 & 0 & 4 \end{pmatrix} \begin{pmatrix} 5 \\\\ -7 \\\\ 1 \\\\ -5 \\\\ 3 \end{pmatrix} = \begin{pmatrix} -7 \\\\ 2 \\\\ -15 \\\\ 12 \end{pmatrix} $$
O que confirma o resultado esperado [^5].

### Conclusão

A representação de aplicações lineares $f: E \to F$ por matrizes $M(f)$ é uma ferramenta poderosa, especialmente em dimensões finitas. Ela traduz a ação da aplicação linear numa operação algébrica bem definida: a multiplicação de matrizes por vetores de coordenadas ($M(y) = M(f)M(x)$) [^8]. Esta correspondência depende crucialmente da escolha das bases $(u_j)$ para $E$ e $(v_i)$ para $F$ [^1, ^4]. Como veremos posteriormente, a composição de aplicações lineares corresponde à multiplicação das suas matrizes associadas (Proposição 4.1, Proposição 4.2 [^9, ^10]), e a mudança de bases induz transformações específicas nestas matrizes (Proposição 4.5 [^17]). Esta representação estabelece um **isomorfismo** entre o espaço das aplicações lineares $\mathrm{Hom}(E, F)$ e o espaço das matrizes $M_{m,n}(K)$ (Proposição 4.2 [^10, ^11]), solidificando a ligação entre os conceitos abstratos e as ferramentas computacionais. É fundamental, no entanto, ter sempre presente que *as aplicações lineares são objetos mais fundamentais e intrínsecos, independentes da escolha de bases*, enquanto as matrizes são representações que dependem dessa escolha [^21].

### Referências

[^1]: Trecho da página 113 do contexto OCR.
[^2]: Trecho da página 114 do contexto OCR.
[^3]: Trecho da página 115 do contexto OCR.
[^4]: Trecho da página 116 do contexto OCR (Definition 4.1).
[^5]: Trecho da página 117 do contexto OCR.
[^6]: Trecho da página 118 do contexto OCR.
[^7]: Trecho da página 119 do contexto OCR.
[^8]: Trecho da página 120 do contexto OCR.
[^9]: Trecho da página 121 do contexto OCR.
[^10]: Trecho da página 122 do contexto OCR.
[^11]: Trecho da página 123 do contexto OCR.
[^12]: Trecho da página 124 do contexto OCR.
[^13]: Trecho da página 125 do contexto OCR.
[^14]: Trecho da página 126 do contexto OCR.
[^15]: Trecho da página 127 do contexto OCR.
[^16]: Trecho da página 128 do contexto OCR.
[^17]: Trecho da página 129 do contexto OCR.
[^18]: Trecho da página 130 do contexto OCR.
[^19]: Trecho da página 131 do contexto OCR.
[^20]: Trecho da página 132 do contexto OCR.
[^21]: Trecho da página 133 do contexto OCR.
[^22]: Trecho da página 134 do contexto OCR.
<!-- END -->