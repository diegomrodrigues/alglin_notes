## Capítulo 4.3: A Matriz de Mudança de Base e Transformação de Coordenadas

### Introdução

Nos capítulos anteriores, estabelecemos como transformações lineares entre espaços vetoriais $E$ e $F$ podem ser representadas por matrizes, uma vez que bases $\\mathcal{U} = (u_1, \\dots, u_n)$ para $E$ e $\\mathcal{V} = (v_1, \\dots, v_m)$ para $F$ são escolhidas [^1], [^2]. Vimos que a matriz $M(f) = (a_{ij})$ é definida pela expressão das imagens dos vetores da base de $E$ como combinações lineares dos vetores da base de $F$, especificamente $f(u_j) = \\sum_{i=1}^m a_{ij} v_i$ [^2], [^4]. Também exploramos como a composição de transformações lineares corresponde à multiplicação de matrizes [^6], [^7]. No entanto, a representação matricial $M(f)$ depende crucialmente das bases escolhidas [^12]. Surge então a questão fundamental: como a representação de vetores e transformações lineares muda quando alteramos as bases dos espaços vetoriais envolvidos? Este capítulo foca na ferramenta central para responder a essa pergunta: a **matriz de mudança de base**. Investigaremos sua definição, propriedades e como ela relaciona as coordenadas de um vetor em diferentes bases.

### Conceitos Fundamentais

Seja $E$ um espaço vetorial de dimensão finita $n$ sobre um corpo $K$. Uma base para $E$ fornece um sistema de coordenadas único para cada vetor em $E$. Contudo, frequentemente é vantajoso ou necessário trabalhar com diferentes bases para o mesmo espaço vetorial. Precisamos, portanto, de um mecanismo formal para transitar entre essas diferentes representações.

Considere duas bases para $E$: uma base "antiga" $\\mathcal{U} = (u_1, \\dots, u_n)$ e uma base "nova" $\\mathcal{V} = (v_1, \\dots, v_n)$. Como $\\mathcal{U}$ é uma base, cada vetor da nova base $\\mathcal{V}$ pode ser expresso de forma única como uma combinação linear dos vetores de $\\mathcal{U}$.

**Definição 4.3 (Adaptada).** Dados um espaço vetorial $E$ de dimensão $n$ e duas bases $\\mathcal{U} = (u_1, \\dots, u_n)$ e $\\mathcal{V} = (v_1, \\dots, v_n)$ de $E$, a **matriz de mudança de base** da base $\\mathcal{U}$ para a base $\\mathcal{V}$ é a matriz $P = (a_{ij})$ cujas colunas são formadas pelas coordenadas dos vetores da *nova* base $\\mathcal{V}$ em relação à base *antiga* $\\mathcal{U}$ [^2]. Ou seja, para cada $j \\in \\{1, \\dots, n\\}$, temos:
$$ v_j = \\sum_{i=1}^n a_{ij} u_i $$
A $j$-ésima coluna de $P$ é, portanto, o vetor de coordenadas de $v_j$ na base $\\mathcal{U}$:
$$ \\text{col}_j(P) = \\begin{pmatrix} a_{1j} \\\\ a_{2j} \\\\ \\vdots \\\\ a_{nj} \\end{pmatrix} = [v_j]_\\mathcal{U} $$

É crucial observar que esta matriz $P$ está intrinsecamente ligada à aplicação identidade $id: E \\to E$. Especificamente, $P$ é a matriz que representa a aplicação identidade $id_E$ quando consideramos $\\mathcal{V}$ como a base do domínio *no sentido da definição original da matriz de uma transformação linear* (onde as colunas são as imagens dos vetores da base de entrada, expressos na base de saída) e $\\mathcal{U}$ como a base do contradomínio [^3]. Formalmente, $P = M_{\\mathcal{V},\\mathcal{U}}(id_E)$.

> A matriz $P = (a_{ij})$ tal que $v_j = \\sum_{i=1}^n a_{ij} u_i$ é a matriz de mudança de base de $\\mathcal{U}$ para $\\mathcal{V}$. Suas colunas são as coordenadas dos vetores da *nova* base ($v_j$) em relação à base *antiga* ($u_i$) [^2].

Uma propriedade fundamental, estabelecida na Proposição 4.3, é que a matriz $P$ definida acima é sempre invertível, pois relaciona duas bases do mesmo espaço vetorial [^1]. Isso decorre do fato de que a aplicação linear $f: E \\to E$ definida por $f(u_i) = v_i$ é um isomorfismo se e somente se $(v_1, \\dots, v_n)$ é uma base, e $P$ é precisamente a matriz dessa transformação $f$ na base $\\mathcal{U}$ (i.e., $P = M_\\mathcal{U}(f)$) [^1]. A invertibilidade de $P$ garante que podemos sempre reverter a mudança de base. A matriz de mudança de base de $\\mathcal{V}$ para $\\mathcal{U}$ é precisamente $P^{-1}$ [^6].

O propósito principal da matriz de mudança de base é facilitar a conversão das coordenadas de um vetor entre as duas bases. Seja $x \\in E$ um vetor qualquer. Ele pode ser expresso unicamente em ambas as bases:
$x = \\sum_{i=1}^n x_i u_i$ e $x = \\sum_{j=1}^n x\'_j v_j$.
O vetor coluna $x_\\mathcal{U} = (x_1, \\dots, x_n)^T$ contém as coordenadas de $x$ na base $\\mathcal{U}$ (coordenadas "antigas"), e $x_\\mathcal{V} = (x\'_1, \\dots, x\'_n)^T$ contém as coordenadas de $x$ na base $\\mathcal{V}$ (coordenadas "novas"). Como $P$ relaciona as bases, ela também relaciona os vetores de coordenadas. Substituindo a expressão de $v_j$ na segunda representação de $x$:
$$ x = \\sum_{j=1}^n x\'_j v_j = \\sum_{j=1}^n x\'_j \\left( \\sum_{i=1}^n a_{ij} u_i \\right) = \\sum_{i=1}^n \\left( \\sum_{j=1}^n a_{ij} x\'_j \\right) u_i $$
Comparando com $x = \\sum_{i=1}^n x_i u_i$, e devido à unicidade das coordenadas, obtemos a relação:
$$ x_i = \\sum_{j=1}^n a_{ij} x\'_j \\quad \\text{para } i = 1, \\dots, n $$
Esta relação pode ser expressa de forma concisa em notação matricial [^4]:
$$ x_\\mathcal{U} = P x_\\mathcal{V} $$

> A relação entre as coordenadas de um vetor $x$ na base antiga ($x_\\mathcal{U}$) e na base nova ($x_\\mathcal{V}$) é dada por $x_\\mathcal{U} = P x_\\mathcal{V}$, onde $P$ é a matriz de mudança de base de $\\mathcal{U}$ para $\\mathcal{V}$ [^4].

Esta fórmula pode parecer contraintuitiva à primeira vista, pois expressa as coordenadas *antigas* em termos das *novas*. No entanto, ela está correta e reflete o fato de que $P$ codifica os *novos* vetores de base em termos dos *antigos*. Para ilustrar, considere o exemplo $n=2$ fornecido no texto [^5]:
Se $v_1 = a_{11}u_1 + a_{21}u_2$ e $v_2 = a_{12}u_1 + a_{22}u_2$, então $P = \\begin{pmatrix} a_{11} & a_{12} \\\\ a_{21} & a_{22} \\end{pmatrix}$.
Um vetor $x = x\'_1 v_1 + x\'_2 v_2$ é:
$x = x\'_1(a_{11}u_1 + a_{21}u_2) + x\'_2(a_{12}u_1 + a_{22}u_2)$
$x = (a_{11}x\'_1 + a_{12}x\'_2)u_1 + (a_{21}x\'_1 + a_{22}x\'_2)u_2$
Comparando com $x = x_1 u_1 + x_2 u_2$, temos $x_1 = a_{11}x\'_1 + a_{12}x\'_2$ e $x_2 = a_{21}x\'_1 + a_{22}x\'_2$, que é exatamente $x_\\mathcal{U} = P x_\\mathcal{V}$ [^5].

Para obter as novas coordenadas a partir das antigas, usamos a matriz inversa:
$$ x_\\mathcal{V} = P^{-1} x_\\mathcal{U} $$
onde $P^{-1}$ é a matriz de mudança de base de $\\mathcal{V}$ para $\\mathcal{U}$ [^6].

**Notação Alternativa e Observações.**
É útil introduzir uma notação que explicite as bases envolvidas. Conforme a Definição 4.4, denotamos a matriz de mudança de base da base $\\mathcal{U}$ para a base $\\mathcal{V}$ como $P_{\\mathcal{V},\\mathcal{U}}$ [^7]. Esta notação enfatiza que $P_{\\mathcal{V},\\mathcal{U}}$ transforma coordenadas na base $\\mathcal{V}$ em coordenadas na base $\\mathcal{U}$:
$$ x_\\mathcal{U} = P_{\\mathcal{V},\\mathcal{U}} x_\\mathcal{V} $$
Com esta notação, a relação inversa é $P_{\\mathcal{U},\\mathcal{V}} = (P_{\\mathcal{V},\\mathcal{U}})^{-1}$ [^8], e a transformação de coordenadas para obter as novas coordenadas é:
$$ x_\\mathcal{V} = P_{\\mathcal{U},\\mathcal{V}} x_\\mathcal{U} $$ [^9].
É importante notar a ordem dos índices na notação $P_{\\mathcal{V},\\mathcal{U}}$: a primeira base ($\\mathcal{V}$) refere-se às coordenadas de *entrada* na fórmula $x_\\mathcal{U} = P_{\\mathcal{V},\\mathcal{U}} x_\\mathcal{V}$, enquanto a segunda base ($\\mathcal{U}$) refere-se às coordenadas de *saída*. O texto original menciona que $P_{\\mathcal{V},\\mathcal{U}}$ é a matriz da identidade $id_E$ com respeito às bases $\\mathcal{V}$ e $\\mathcal{U}$, *nessa ordem* (entrada $\\mathcal{V}$, saída $\\mathcal{U}$) [^7]. Alguns autores definem a matriz de mudança de base na ordem inversa, o que pode gerar confusão [^7].

O fato de as coordenadas de um vetor $(x_i)$ se transformarem usando a inversa da matriz $P$ que transforma as bases ($v_j = \\sum a_{ij} u_i$) leva alguns a dizer que as coordenadas se transformam de maneira **contravariante** em relação à base [^10]. No entanto, o texto adverte que essa terminologia pode ser enganosa, pois o vetor $x$ em si é uma entidade intrínseca, independente da base; são suas *coordenadas* que variam de forma específica quando a base muda [^10].

Se os vetores das bases $\\mathcal{U}$ e $\\mathcal{V}$ são eles mesmos vetores coluna em $K^n$, podemos organizar esses vetores como colunas de matrizes $U = [u_1 \\dots u_n]$ e $V = [v_1 \\dots v_n]$. A relação $v_j = \\sum_{i=1}^n a_{ij} u_i = \\sum_{i=1}^n u_i (P)_{ij}$ pode ser escrita matricialmente como $V = UP$ [^11]. Esta forma é útil em contextos computacionais.

Finalmente, considere três bases $\\mathcal{U}$, $\\mathcal{V}$, e $\\mathcal{W}$ de $E$. As matrizes de mudança de base entre elas satisfazem uma regra de composição natural. A mudança de $\\mathcal{U}$ para $\\mathcal{W}$ pode ser feita em duas etapas, de $\\mathcal{U}$ para $\\mathcal{V}$ e depois de $\\mathcal{V}$ para $\\mathcal{W}$. A matriz correspondente é o produto das matrizes intermediárias:
$$ P_{\\mathcal{W},\\mathcal{U}} = P_{\\mathcal{V},\\mathcal{U}} P_{\\mathcal{W},\\mathcal{V}} $$ [^12]. Esta relação é consistente com a composição de transformações lineares e a multiplicação de matrizes.

**Exemplos Concretos.**

1.  **Espaço $\\mathbb{R}^2$** [^13]: Seja $\\mathcal{U} = (u_1, u_2)$ a base canônica com $u_1 = (1, 0)$ e $u_2 = (0, 1)$. Seja $\\mathcal{V} = (v_1, v_2)$ uma nova base com $v_1 = (1, 1)$ e $v_2 = (-1, 1)$.
    Expressando $v_1$ e $v_2$ na base $\\mathcal{U}$:
    $v_1 = 1u_1 + 1u_2$
    $v_2 = -1u_1 + 1u_2$
    A matriz de mudança de base de $\\mathcal{U}$ para $\\mathcal{V}$ é $P = P_{\\mathcal{V},\\mathcal{U}} = \\begin{pmatrix} 1 & -1 \\\\ 1 & 1 \\end{pmatrix}$.
    Sua inversa é $P^{-1} = P_{\\mathcal{U},\\mathcal{V}} = \\frac{1}{2} \\begin{pmatrix} 1 & 1 \\\\ -1 & 1 \\end{pmatrix}$.
    Se um vetor $x$ tem coordenadas $(x_1, x_2)$ na base $\\mathcal{U}$, suas coordenadas $(x\'_1, x\'_2)$ na base $\\mathcal{V}$ são dadas por $x_\\mathcal{V} = P^{-1} x_\\mathcal{U}$:
    $\\begin{pmatrix} x\'_1 \\\\ x\'_2 \\end{pmatrix} = \\frac{1}{2} \\begin{pmatrix} 1 & 1 \\\\ -1 & 1 \\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix}$.
    Inversamente, $x_\\mathcal{U} = P x_\\mathcal{V}$: $\\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix} = \\begin{pmatrix} 1 & -1 \\\\ 1 & 1 \\end{pmatrix} \\begin{pmatrix} x\'_1 \\\\ x\'_2 \\end{pmatrix}$.

2.  **Polinômios de Bernstein** [^14]: Considere $E = \\mathbb{R}[X]_3$, o espaço dos polinômios de grau $\\le 3$. Seja $\\mathcal{U} = (1, x, x^2, x^3)$ a base monomial (antiga) e $\\mathcal{V} = (B_0^3(x), B_1^3(x), B_2^3(x), B_3^3(x))$ a base de Bernstein (nova), onde $B_k^3(x) = \\binom{3}{k} (1-x)^{3-k} x^k$.
    Expandindo os polinômios de Bernstein:
    $B_0^3(x) = (1-x)^3 = 1 - 3x + 3x^2 - x^3$
    $B_1^3(x) = 3(1-x)^2 x = 3x - 6x^2 + 3x^3$
    $B_2^3(x) = 3(1-x) x^2 = 3x^2 - 3x^3$
    $B_3^3(x) = x^3$
    A matriz de mudança de base de $\\mathcal{U}$ para $\\mathcal{V}$, $P = P_{\\mathcal{V},\\mathcal{U}}$, tem como colunas as coordenadas dos $B_k^3$ na base $\\mathcal{U}$:
    $$ P = P_{\\mathcal{V},\\mathcal{U}} = \\begin{pmatrix} 1 & 0 & 0 & 0 \\\\ -3 & 3 & 0 & 0 \\\\ 3 & -6 & 3 & 0 \\\\ -1 & 3 & -3 & 1 \\end{pmatrix} $$
    A matriz inversa $P^{-1} = P_{\\mathcal{U},\\mathcal{V}}$ permite converter coordenadas da base monomial para a base de Bernstein. Por exemplo, para o polinômio $p(x) = 2x^3 - x + 1$, seu vetor de coordenadas na base $\\mathcal{U}$ é $x_\\mathcal{U} = (1, -1, 0, 2)^T$. As coordenadas na base $\\mathcal{V}$ são $x_\\mathcal{V} = P^{-1} x_\\mathcal{U}$. O texto calcula $P^{-1}$ [^14] e encontra as coordenadas de $2x^3 - x + 1$ na base $\\mathcal{V}$ como $(1, 2/3, 1/3, 2)^T$, significando $p(x) = 1 B_0^3(x) + \\frac{2}{3} B_1^3(x) + \\frac{1}{3} B_2^3(x) + 2 B_3^3(x)$ [^14].

### Conclusão

A matriz de mudança de base $P_{\\mathcal{V},\\mathcal{U}}$ é uma ferramenta essencial em álgebra linear, fornecendo a ligação algébrica entre diferentes representações coordenadas do mesmo espaço vetorial $E$. Ela codifica os vetores da nova base $\\mathcal{V}$ em termos da base antiga $\\mathcal{U}$ e permite a conversão de coordenadas entre as bases através da relação $x_\\mathcal{U} = P_{\\mathcal{V},\\mathcal{U}} x_\\mathcal{V}$. A invertibilidade desta matriz garante a reversibilidade do processo. Compreender a matriz de mudança de base é fundamental para analisar como a representação matricial de uma transformação linear $f: E \\to F$ é afetada por mudanças nas bases de $E$ e $F$, um tópico explorado na Proposição 4.5 e Corolário 4.6 [^15]. Isso leva diretamente ao conceito de **matrizes similares**, que representam a mesma transformação linear $f: E \\to E$ em relação a bases diferentes [^16]. A distinção cuidadosa entre a transformação da base e a transformação (contravariante) das coordenadas é crucial para a aplicação correta dessas ferramentas.

### Referências

[^1]: Proposition 4.3, Page 124.
[^2]: Definition 4.3, Page 125.
[^3]: Definition 4.3, Page 125.
[^4]: Definition 4.3, Page 125.
[^5]: Page 126.
[^6]: Definition 4.3, Page 125.
[^7]: Definition 4.4, Page 127.
[^8]: Definition 4.4, Page 127.
[^9]: Definition 4.4, Page 127.
[^10]: Page 127.
[^11]: Page 126.
[^12]: Page 132.
[^13]: Example 4.1, Page 128.
[^14]: Example 4.2, Page 128.
[^15]: Proposition 4.5, Corollary 4.6, Pages 129-130.
[^16]: Definition 4.5, Page 130.
[^17]: Proposition 3.18, Page 113 (Implicit reference for map representation).
[^18]: Section 4.1, Pages 113-117 (General context of matrix representation).
[^19]: Section 4.2, Pages 118-123 (Composition and matrix multiplication).
[^20]: Proposition 4.4, Page 124 (Invertibility and linear independence).

<!-- END -->