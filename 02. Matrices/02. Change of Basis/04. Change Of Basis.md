## Relação entre Coordenadas na Mudança de Base

### Introdução

Em capítulos anteriores, estabelecemos que qualquer vetor $x$ em um espaço vetorial $E$ de dimensão finita $n$ pode ser unicamente representado como uma combinação linear dos vetores de uma base $U = (u_1, \dots, u_n)$. Essa representação associa ao vetor $x$ um vetor coluna de coordenadas, $x_U$, cujas entradas são os escalares da combinação linear [^8]. Contudo, a escolha da base é arbitrária. Se optarmos por uma nova base $V = (v_1, \dots, v_n)$ para o mesmo espaço $E$, o mesmo vetor $x$ terá um novo vetor de coordenadas, $x_V$ [^7]. Este capítulo dedica-se a explorar a relação matemática precisa entre os vetores de coordenadas $x_U$ e $x_V$ de um mesmo vetor $x$ quando a base de representação é alterada. Faremos uso extensivo do conceito de **matriz de mudança de base**, introduzido formalmente na Definition 4.3 [^6], para derivar a lei de transformação das coordenadas.

### Conceitos Fundamentais

Seja $E$ um espaço vetorial de dimensão $n$ sobre um corpo $K$. Consideremos duas bases para $E$: a base "antiga" $U = (u_1, \dots, u_n)$ e a base "nova" $V = (v_1, \dots, v_n)$.

A **matriz de mudança de base** da base $U$ para a base $V$, denotada por $P_{V,U}$ de acordo com a Definition 4.4 [^11], é definida como a matriz cujas colunas são as coordenadas dos vetores da *nova* base $V$ expressas em termos da *antiga* base $U$ [^6, ^15]. Explicitamente, se $v_j = \sum_{i=1}^n a_{ij} u_i$ para $j = 1, \dots, n$, então $P_{V,U} = (a_{ij})$ [^6]. A $j$-ésima coluna de $P_{V,U}$ é, portanto, o vetor de coordenadas de $v_j$ na base $U$, isto é, $(a_{1j}, a_{2j}, \dots, a_{nj})^T$ [^15]. Conforme estabelecido na Proposition 4.3, como $U$ e $V$ são bases, a matriz $P_{V,U}$ é sempre invertível [^14].

Agora, consideremos um vetor arbitrário $x \in E$. Este vetor pode ser expresso unicamente em ambas as bases:
1.  Na base antiga $U$: $x = \sum_{i=1}^n x_i u_i$. O vetor de coordenadas (antigas) é $x_U = (x_1, \dots, x_n)^T$ [^8].
2.  Na base nova $V$: $x = \sum_{k=1}^n x'_k v_k$. O vetor de coordenadas (novas) é $x_V = (x'_1, \dots, x'_n)^T$ [^7].

Nosso objetivo é encontrar a relação entre $x_U$ e $x_V$. Para isso, substituímos a expressão de cada $v_k$ (em termos da base $U$) na segunda representação de $x$:
$$ x = \sum_{k=1}^n x'_k v_k = \sum_{k=1}^n x'_k \left( \sum_{i=1}^n a_{ik} u_i \right) $$
Podemos reorganizar a ordem das somas, uma vez que são finitas:
$$ x = \sum_{i=1}^n \left( \sum_{k=1}^n a_{ik} x'_k \right) u_i $$
Temos agora duas expressões para $x$ como combinação linear dos vetores da base $U$: $x = \sum_{i=1}^n x_i u_i$ e $x = \sum_{i=1}^n (\sum_{k=1}^n a_{ik} x'_k) u_i$. Como a representação de um vetor numa base é única (propriedade fundamental das bases), os coeficientes correspondentes devem ser iguais:
$$ x_i = \sum_{k=1}^n a_{ik} x'_k \quad \text{para todo } i = 1, \dots, n $$
Esta relação é precisamente a definição de multiplicação de matrizes. Se considerarmos os vetores coluna de coordenadas $x_U = (x_1, \dots, x_n)^T$ e $x_V = (x'_1, \dots, x'_n)^T$, e a matriz $P_{V,U} = (a_{ik})$, a equação acima pode ser escrita de forma matricial como:
$$ x_U = P_{V,U} x_V $$
Esta é a relação fundamental que governa a mudança de coordenadas de um vetor quando a base do espaço vetorial é alterada [^1, ^10]. A derivação aqui apresentada confirma a afirmação encontrada na página 125 e formalizada na página 127 [^1, ^13].

> **Caixa de Destaque:** A equação $x_U = P_{V,U} x_V$ demonstra que as **coordenadas antigas** ($x_U$) de um vetor $x$ são obtidas multiplicando a matriz de mudança de base $P_{V,U}$ (de $U$ para $V$) pelas **coordenadas novas** ($x_V$) do mesmo vetor [^1, ^9]. Este fato, como mencionado na página 126 [^9], pode parecer não intuitivo à primeira vista, pois a matriz $P_{V,U}$ codifica a *nova* base em termos da *antiga*.

Como $P_{V,U}$ é invertível [^14], podemos isolar as novas coordenadas $x_V$ em termos das antigas $x_U$:
$$ x_V = P_{V,U}^{-1} x_U $$ [^12].
É importante notar que a matriz inversa $P_{V,U}^{-1}$ é, por sua vez, a matriz de mudança de base da base $V$ para a base $U$ [^2]. Utilizando a notação da Definition 4.4, temos $P_{U,V} = P_{V,U}^{-1}$ [^2]. Portanto, a relação inversa pode ser escrita como:
$$ x_V = P_{U,V} x_U $$ [^12].

Essa relação inversa elucida o termo **contravariante** usado para descrever a transformação das coordenadas [^3]. A matriz $P_{V,U}$ descreve como os vetores da *nova* base $V$ se relacionam com os da *antiga* base $U$. No entanto, para obter as *novas* coordenadas $x_V$ a partir das *antigas* $x_U$, utilizamos a matriz *inversa*, $P_{V,U}^{-1} = P_{U,V}$. As coordenadas transformam-se "contrariamente" à forma como a base é transformada pela matriz $P_{V,U}$. Conforme citado na página 127, *"the coordinates (xi) of a vector x vary in the opposite direction of the change of basis"* [^3]. É fundamental entender que o vetor $x$ em si é uma entidade geométrica intrínseca, independente da base escolhida; são apenas as suas *coordenadas* que mudam (de forma contravariante) com a mudança de base [^3].

Finalmente, podemos interpretar a matriz $P_{V,U}$ no contexto da representação matricial de aplicações lineares. A matriz $P_{V,U}$ é precisamente a matriz da aplicação identidade $id_E: E \to E$, quando consideramos a base $V$ no espaço de partida e a base $U$ no espaço de chegada [^4, ^13]. Ou seja, $P_{V,U} = M_{V,U}(id_E)$ [^13]. Isso é consistente com a fórmula geral $y_V = M_{U,V}(f) x_U$ [^8], onde, no nosso caso, $y=x$, $f=id_E$, a base de entrada é $V$ (coordenadas $x_V$) e a base de saída é $U$ (coordenadas $x_U$), resultando em $x_U = M_{V,U}(id_E) x_V = P_{V,U} x_V$.

### Conclusão

Demonstramos que, dada uma mudança da base $U$ para a base $V$ em um espaço vetorial $E$, descrita pela matriz de mudança de base $P_{V,U}$ (cujas colunas são as coordenadas dos vetores de $V$ na base $U$ [^15]), as coordenadas $x_U$ e $x_V$ de um mesmo vetor $x$ nas bases antiga e nova, respectivamente, estão relacionadas por $x_U = P_{V,U} x_V$ [^1]. Inversamente, as novas coordenadas são dadas por $x_V = P_{V,U}^{-1} x_U = P_{U,V} x_U$ [^12, ^2]. Esta relação inversa justifica a designação de **transformação contravariante** para as coordenadas de um vetor [^3]: elas transformam-se utilizando a inversa da matriz que descreve a transformação direta da base. A compreensão clara desta relação e da notação associada ($P_{V,U}$ versus $P_{U,V}$) é crucial para trabalhar eficazmente com representações matriciais em diferentes bases.

### Referências

[^1]: Page 127, Definition 4.4 and subsequent equation: "Then, if we write $x_U = (x_1, \dots, x_n)$ for the old coordinates of $x$ with respect to the basis $U$ and $x_V = (x'_1, \dots, x'_n)$ for the new coordinates of $x$ with respect to the basis $V$, we have $x_U = P_{V,U} x_V$."
[^2]: Page 127, Note following Definition 4.4: "Note that $P_{U,V} = P_{V,U}^{-1}$."
[^3]: Page 127, Paragraph discussing contravariance: "Since the matrix $P = P_{V,U}$ expresses the new basis $(v_1, \dots, v_n)$ in terms of the old basis $(u_1, \dots, u_n)$, we observe that the coordinates $(x_i)$ of a vector $x$ vary in the opposite direction of the change of basis. For this reason, vectors are sometimes said to be contravariant. However, this expression does not make sense! Indeed, a vector in an intrinsic quantity that does not depend on a specific basis. What makes sense is that the coordinates of a vector vary in a contravariant fashion."
[^4]: Page 125, Definition 4.3: "... P = (a_ij) be the invertible matrix defined such that $v_j = \sum_{i=1}^n a_{ij} u_i$ which is also the matrix of the identity id: E -> E with respect to the bases $(v_1, ..., v_n)$ and $(u_1, ..., u_n)$, in that order."
[^5]: Page 127, Paragraph discussing notation: "... remember that the matrix $M_{U,V}(f)$ takes input expressed over the basis U to output expressed over the basis V. Consequently, $P_{V,U}$ takes input expressed over the basis V to output expressed over the basis U, and $x_U = P_{V,U} x_V$ matches this point of view!"
[^6]: Page 125, Definition 4.3: "Given a vector space E of dimension n, for any two bases $(u_1, \dots, u_n)$ and $(v_1, \dots, v_n)$ of E, let $P = (a_{ij})$ be the invertible matrix defined such that $v_j = \sum_{i=1}^n a_{ij} u_i$."
[^7]: Page 125, Equation preceding the matrix equation: "... if $x = x_1 u_1 + \dots + x_n u_n$ over the basis $(u_1, \dots, u_n)$ and $x = x'_1 v_1 + \dots + x'_n v_n$ over the basis $(v_1, \dots, v_n)$..."
[^8]: Page 116, Definition 4.1 and Page 120, Definition 4.2: Defines representation of vectors as column matrices of coordinates, $M(x)$, and introduces notation $x_U$.
[^9]: Page 126, Derivation for n=2 and the resulting equations: "$x_1 = a_{11}x'_1 + a_{12}x'_2$, $x_2 = a_{21}x'_1 + a_{22}x'_2$", which is the component form of $x_U = P x_V$. The text notes: "showing that the old coordinates ($x_i$) of x ... are expressed in terms of the new coordinates ($x'_i$) of x..."
[^10]: Page 125, Matrix equation: Shows the matrix equation $\begin{pmatrix} x_1 \\\\ \vdots \\\\ x_n \end{pmatrix} = \begin{pmatrix} a_{11} & \dots & a_{1n} \\\\ \vdots & \ddots & \vdots \\\\ a_{n1} & \dots & a_{nn} \end{pmatrix} \begin{pmatrix} x'_1 \\\\ \vdots \\\\ x'_n \end{pmatrix}$.
[^11]: Page 127, Definition 4.4: "The change of basis matrix from U to V is denoted $P_{V,U}$."
[^12]: Page 127, Equation following $x_U = P_{V,U} x_V$: "$x_V = P_{V,U}^{-1} x_U = P_{U,V} x_U$."
[^13]: Page 127, Paragraph discussing notation: "Because the change of basis matrix from U to V is the matrix of the identity map $id_E$ with respect to the bases V and U in that order, we could denote it by $M_{V,U}(id)$. We prefer to use an abbreviation for $M_{V,U}(id)$." followed by Definition 4.4.
[^14]: Page 124, Proposition 4.3: "Let E be a vector space, and let $(u_1, \dots, u_n)$ be a basis of E. For every family $(v_1, \dots, v_n)$, let $P = (a_{ij})$ be the matrix defined such that $v_j = \sum_{i=1}^n a_{ij} u_i$. The matrix P is invertible iff $(v_1, \dots, v_n)$ is a basis of E."
[^15]: Page 125, Matrix representation below Definition 4.3: Shows the matrix $P$ where the $j$-th column contains the coefficients $a_{1j}, \dots, a_{nj}$ representing $v_j$ in the basis $U$.
[^16]: Page 114, Recall statement: "Recall that we have shown that every vector $x \in E$ can be written in a unique way as $x = x_1 u_1 + \dots + x_n u_n$."

<!-- END -->