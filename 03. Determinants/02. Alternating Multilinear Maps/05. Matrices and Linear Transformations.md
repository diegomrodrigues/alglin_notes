## A Relação entre Matrizes $n \\times n$ e Transformações Lineares em $E^n$

### Introdução

No contexto do estudo de determinantes e suas propriedades fundamentais, como apresentado no Capítulo 7, torna-se essencial estabelecer uma conexão formal entre a álgebra de matrizes e a teoria das transformações lineares. Embora intuitivamente associemos matrizes a transformações lineares, uma construção explícita solidifica essa relação e permite a exploração de propriedades importantes. Este capítulo foca na definição e nas propriedades elementares da aplicação $L(A): E^n \\rightarrow E^n$ associada a uma matriz $A$ de ordem $n \\times n$, conforme introduzido na seção sobre *Alternating Multilinear Maps* [^1]. Analisaremos sua **linearidade** e, crucialmente, como a **composição** dessas aplicações se relaciona com o produto de matrizes, uma propriedade fundamental que permeia muitos resultados em álgebra linear. Assume-se que todos os espaços vetoriais são definidos sobre um corpo arbitrário $K$.

### Conceitos Fundamentais

Seja $E$ um espaço vetorial sobre um corpo $K$. Dada uma **matriz** $A = (a_{ij})$ de ordem $n \\times n$ com coeficientes em $K$, podemos definir uma aplicação $L(A): E^n \\rightarrow E^n$ [^1]. É importante notar que $E^n$ representa o produto cartesiano de $E$ consigo mesmo $n$ vezes, $E \\times \\dots \\times E$, cujos elementos são $n$-uplas ordenadas $u = (u_1, \\dots, u_n)$ onde cada $u_k \\in E$.

> A aplicação $L(A)$ é definida por suas componentes da seguinte forma: para $u = (u_1, \\dots, u_n) \\in E^n$, a $i$-ésima componente do vetor imagem $L(A)(u)$ é dada por:
> $$L(A)_i(u) = a_{i1}u_1 + a_{i2}u_2 + \\dots + a_{in}u_n = \\sum_{j=1}^{n} a_{ij}u_j$$
> para cada $i = 1, \\dots, n$ [^1].

**Linearidade de L(A)**

A aplicação $L(A)$ assim definida é uma **transformação linear** de $E^n$ em $E^n$. O texto do contexto afirma que *isto é imediatamente verificado* [^2]. Para explicitar, consideremos $u = (u_1, \\dots, u_n)$ e $v = (v_1, \\dots, v_n)$ em $E^n$ e $\\lambda \\in K$. A $i$-ésima componente de $L(A)(u+v)$ é:
$$L(A)_i(u+v) = \\sum_{j=1}^{n} a_{ij}(u_j + v_j)$$
Usando a distributividade da multiplicação escalar sobre a adição vetorial em $E$, temos:
$$L(A)_i(u+v) = \\sum_{j=1}^{n} (a_{ij}u_j + a_{ij}v_j) = \\sum_{j=1}^{n} a_{ij}u_j + \\sum_{j=1}^{n} a_{ij}v_j = L(A)_i(u) + L(A)_i(v)$$
Assim, $L(A)(u+v) = L(A)(u) + L(A)(v)$.
Similarmente, a $i$-ésima componente de $L(A)(\\lambda u)$ é:
$$L(A)_i(\\lambda u) = \\sum_{j=1}^{n} a_{ij}(\\lambda u_j)$$
Usando a associatividade/comutatividade da multiplicação escalar em $E$:
$$L(A)_i(\\lambda u) = \\sum_{j=1}^{n} \\lambda (a_{ij} u_j) = \\lambda \\sum_{j=1}^{n} a_{ij} u_j = \\lambda L(A)_i(u)$$
Logo, $L(A)(\\lambda u) = \\lambda L(A)(u)$. Conclui-se que $L(A)$ é de fato **linear**.

**Notação Matricial Conveniente**

É conveniente utilizar uma notação matricial para descrever o efeito da transformação linear $L(A)$ [^3]. Embora os componentes $u_j$ do vetor $u$ sejam elementos do espaço vetorial $E$ (e não necessariamente escalares de $K$), a estrutura da definição permite a seguinte representação visual [^3]:
$$\\begin{pmatrix} L(A)_1(u) \\\\ L(A)_2(u) \\\\ \\vdots \\\\ L(A)_n(u) \\end{pmatrix} =
\\begin{pmatrix} a_{11} & a_{12} & \\cdots & a_{1n} \\\\ a_{21} & a_{22} & \\cdots & a_{2n} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ a_{n1} & a_{n2} & \\cdots & a_{nn} \\end{pmatrix}
\\begin{pmatrix} u_1 \\\\ u_2 \\\\ \\vdots \\\\ u_n \\end{pmatrix}$$
Esta notação, embora um ligeiro abuso se $E \\neq K$, é extremamente útil e visualmente alinhada com a multiplicação matriz-vetor padrão quando $E=K$.

**Composição de Aplicações e Produto de Matrizes**

Uma propriedade crucial que conecta a álgebra de matrizes à composição de transformações lineares é estabelecida a seguir. Dadas duas matrizes $n \\times n$, $A = (a_{ij})$ e $B = (b_{ij})$, podemos considerar suas transformações lineares associadas, $L(A)$ e $L(B)$. O contexto afirma que, repetindo os cálculos que estabelecem o produto de matrizes, pode-se mostrar que [^4]:
$$L(AB) = L(A) \\circ L(B)$$
onde $\\circ$ denota a **composição** de funções. Vamos demonstrar essa propriedade fundamental. Seja $C = AB$ a matriz produto, onde $c_{ik} = \\sum_{j=1}^{n} a_{ij}b_{jk}$. Precisamos mostrar que para qualquer $u \\in E^n$, $L(C)(u) = (L(A) \\circ L(B))(u)$.

Calculamos a $i$-ésima componente de $L(C)(u)$:
$$L(C)_i(u) = \\sum_{k=1}^{n} c_{ik} u_k = \\sum_{k=1}^{n} \\left( \\sum_{j=1}^{n} a_{ij}b_{jk} \\right) u_k$$
Pela distributividade e associatividade em $E$, podemos rearranjar a soma:
$$L(C)_i(u) = \\sum_{j=1}^{n} \\sum_{k=1}^{n} a_{ij} (b_{jk} u_k) = \\sum_{j=1}^{n} a_{ij} \\left( \\sum_{k=1}^{n} b_{jk} u_k \\right)$$
Agora, calculamos a $i$-ésima componente de $(L(A) \\circ L(B))(u)$. Seja $v = L(B)(u)$. Então, a $j$-ésima componente de $v$ é $v_j = L(B)_j(u) = \\sum_{k=1}^{n} b_{jk} u_k$.
A composição é $L(A)(v)$, e sua $i$-ésima componente é:
$$L(A)_i(v) = \\sum_{j=1}^{n} a_{ij} v_j = \\sum_{j=1}^{n} a_{ij} \\left( \\sum_{k=1}^{n} b_{jk} u_k \\right)$$
Comparando as expressões para $L(C)_i(u)$ e $L(A)_i(v)$, vemos que são idênticas. Portanto, $L(AB)(u) = (L(A) \\circ L(B))(u)$ para todo $u \\in E^n$, o que confirma a igualdade $L(AB) = L(A) \\circ L(B)$ [^4]. $\\blacksquare$

Esta propriedade estabelece um homomorfismo entre a álgebra das matrizes $n \\times n$ sob multiplicação e a álgebra das transformações lineares do tipo $L(A)$ em $E^n$ sob composição.

### Conclusão

A introdução da aplicação **linear** $L(A): E^n \\rightarrow E^n$ associada a uma matriz $A = (a_{ij})$ fornece uma ponte explícita e rigorosa entre matrizes $n \\times n$ e transformações lineares, um conceito fundamental explorado no Capítulo 7 [^1]. Demonstramos sua **linearidade** e a propriedade essencial de que a **composição** de tais aplicações corresponde ao produto das matrizes associadas, $L(AB) = L(A) \\circ L(B)$ [^4]. Esta correspondência é vital, pois permite que propriedades algébricas de matrizes, como a invertibilidade e o determinante (que será explorado extensivamente neste capítulo), sejam interpretadas em termos das propriedades geométricas e estruturais das transformações lineares que elas representam. A construção de $L(A)$ [^1], embora apresentada como preliminar às *alternating multilinear maps*, fundamenta a aplicação de conceitos matriciais à análise de transformações em espaços vetoriais.

### Referências

[^1]: Definição da aplicação $L(A): E^n \\rightarrow E^n$ e seus componentes. (Contexto, p. 211 / OCR page 7)
[^2]: Afirmação da linearidade de $L(A)$. (Contexto, p. 211 / OCR page 7)
[^3]: Notação matricial para a ação de $L(A)$. (Contexto, p. 211 / OCR page 7)
[^4]: Propriedade $L(AB) = L(A) \\circ L(B)$. (Contexto, p. 211 / OCR page 7)
[^context_intro]: Definição de espaços vetoriais sobre um corpo K. (Contexto, p. 205 / OCR page 1)

<!-- END -->