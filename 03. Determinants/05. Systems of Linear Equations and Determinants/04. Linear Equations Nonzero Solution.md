## Capítulo 7.5.1: Determinantes e a Existência de Soluções Não-Triviais em Sistemas Lineares Homogêneos

### Introdução

Nos capítulos anteriores e nas seções iniciais deste capítulo, exploramos a teoria dos **determinantes**, iniciando com permutações e suas assinaturas [^1, ^2, ^3, ^4], definindo mapas multilineares alternados [^5, ^6] e culminando na definição formal de um determinante como um mapa $D: M_n(K) \to K$ que é $n$-linear alternado nas colunas e $D(I_n) = 1$ [^9]. Vimos como calcular determinantes usando a expansão de Laplace [^10, ^11] e estabelecemos sua unicidade através da fórmula explícita envolvendo permutações [^13]. Propriedades fundamentais como $det(A) = det(A^T)$ [^14] e $det(AB) = det(A)det(B)$ [^17] foram demonstradas. Além disso, a conexão crucial entre o determinante e a invertibilidade de uma matriz foi estabelecida: uma matriz $A$ é invertível se, e somente se, $det(A)$ for invertível no anel comutativo $K$ [^19], o que se simplifica para $det(A) \neq 0$ quando $K$ é um corpo [^21].

Com base nesses fundamentos, este capítulo aprofunda a aplicação dos determinantes na análise de **sistemas de equações lineares**. Especificamente, focaremos no caso fundamental dos **sistemas lineares homogêneos**, da forma $Ax = 0$. Investigaremos rigorosamente a condição necessária e suficiente para a existência de **soluções não-nulas** (ou não-triviais) para tais sistemas, demonstrando que esta condição está intrinsecamente ligada ao anulamento do determinante da matriz de coeficientes $A$. Este resultado é uma pedra angular na álgebra linear, oferecendo insights sobre o espaço nulo de uma matriz e a dependência linear de seus vetores coluna.

### Conceitos Fundamentais: Sistemas Homogêneos e Dependência Linear

Um **sistema linear homogêneo** de $n$ equações com $n$ incógnitas é representado pela equação matricial $Ax = 0$, onde $A$ é uma matriz $n \times n$ com coeficientes em um corpo $K$ (como $\mathbb{R}$ ou $\mathbb{C}$ [^21]), $x$ é um vetor coluna de variáveis $n \times 1$, e $0$ é o vetor nulo $n \times 1$.
É crucial observar que o sistema $Ax = 0$ sempre admite a **solução trivial** $x = 0$. A questão central que abordaremos é determinar quando existem outras soluções, ou seja, soluções $x \neq 0$.

Como discutido anteriormente [^21], a equação matricial $Ax = 0$ é equivalente a uma combinação linear dos vetores coluna de $A$, $A^1, \dots, A^n$:
$$x_1A^1 + x_2A^2 + \dots + x_nA^n = 0$$
onde $x = (x_1, x_2, \dots, x_n)^T$. Portanto, a existência de uma **solução não-nula** $x \neq 0$ para $Ax = 0$ é precisamente a condição para que os vetores coluna $A^1, \dots, A^n$ sejam **linearmente dependentes** [^21].

A conexão entre a dependência linear das colunas e o determinante foi estabelecida formalmente na Proposição 7.11:

> **Proposição 7.11.** Dada uma matriz $n \times n$ $A$ sobre um corpo $K$, as colunas $A^1, \dots, A^n$ de $A$ são linearmente dependentes se, e somente se, $det(A) = det(A^1, \dots, A^n) = 0$. Equivalentemente, $A$ tem posto $n$ (ou seja, as colunas são linearmente independentes) se, e somente se, $det(A) \neq 0$ [^21].

Esta proposição é a chave para o resultado principal deste capítulo.

### Teorema Principal e Demonstração

Agora estamos prontos para enunciar e demonstrar formalmente o teorema que relaciona o determinante nulo à existência de soluções não-triviais para sistemas homogêneos. Este resultado é apresentado diretamente como parte (3) da Proposição 7.12 no texto de referência.

**Teorema (Baseado na Proposição 7.12(3))**: *O sistema de equações lineares $Ax = 0$ possui uma solução não-nula se, e somente se, $det(A) = 0$* [^22].

**Demonstração:**

Este teorema é uma consequência direta da Proposição 7.11 e da equivalência entre soluções não-nulas de $Ax=0$ e a dependência linear das colunas de $A$. Apresentamos a demonstração bidirecional:

($\Rightarrow$) Suponha que o sistema $Ax = 0$ possui uma solução não-nula $x = (x_1, \dots, x_n)^T$, onde pelo menos um $x_j \neq 0$. Como vimos [^21], a existência de tal solução significa que a combinação linear $x_1A^1 + x_2A^2 + \dots + x_nA^n = 0$ se mantém com coeficientes não todos nulos. Por definição, isso implica que os vetores coluna $A^1, \dots, A^n$ são **linearmente dependentes**. De acordo com a Proposição 7.11 [^21], a dependência linear das colunas de $A$ é equivalente à condição $det(A) = 0$. Portanto, se existe uma solução não-nula, então $det(A) = 0$.

($\Leftarrow$) Reciprocamente, suponha que $det(A) = 0$. Pela Proposição 7.11 [^21], a condição $det(A) = 0$ implica que os vetores coluna $A^1, \dots, A^n$ de $A$ são **linearmente dependentes**. Por definição de dependência linear, existem escalares $x_1, \dots, x_n \in K$, não todos nulos, tais que $x_1A^1 + x_2A^2 + \dots + x_nA^n = 0$. Construindo o vetor coluna $x = (x_1, \dots, x_n)^T$, temos que $x \neq 0$ (pois nem todos $x_j$ são nulos) e a equação de combinação linear é precisamente a forma vetorial do sistema homogêneo $Ax = 0$ [^21]. Logo, o sistema $Ax = 0$ possui a solução não-nula $x$.

A demonstração estabelece a equivalência desejada. $\blacksquare$

*Observação:* A própria demonstração da Proposição 7.12(3) no texto original [^23] faz referência direta à Proposição 7.11, confirmando que a dependência linear das colunas é o elo fundamental entre $Ax=0$ ter solução não-nula e $det(A)=0$.

### Discussão e Implicações

O teorema estabelece um critério simples e poderoso baseado no determinante para decidir sobre a natureza do conjunto solução de um sistema linear homogêneo.

Se $det(A) \neq 0$, então, pelo teorema que acabamos de provar (na sua forma contrapositiva), a única solução para $Ax = 0$ é a **solução trivial** $x = 0$. Isso está em consonância com outros resultados que vimos: $det(A) \neq 0$ implica que as colunas de $A$ são linearmente independentes (Proposição 7.11 [^21]), que $A$ é invertível (Proposição 7.10 [^19], assumindo $K$ como corpo [^21]), e que o sistema não-homogêneo $Ax = b$ tem uma solução única para qualquer $b$ (Proposição 7.12(1) [^22]). Neste caso, o **espaço nulo** (ou **kernel**) de $A$, que é o conjunto de todas as soluções para $Ax = 0$, contém apenas o vetor nulo: $N(A) = \{0\}$.

Por outro lado, se $det(A) = 0$, o teorema garante a existência de pelo menos uma solução não-nula. Como qualquer múltiplo escalar de uma solução de $Ax = 0$ também é uma solução, e a soma de duas soluções também é uma solução (propriedades de subespaço vetorial), a existência de *uma* solução não-nula implica a existência de *infinitas* soluções (assumindo que o corpo $K$ é infinito, como $\mathbb{R}$ ou $\mathbb{C}$). O **espaço nulo** $N(A)$ terá dimensão maior ou igual a 1. A condição $det(A) = 0$ sinaliza uma "degenerescência" na transformação linear representada por $A$, onde um conjunto de vetores de dimensão maior ou igual a 1 é mapeado para o vetor nulo.

Esta condição é fundamental em muitas áreas, incluindo a determinação de **autovalores** $\lambda$ de uma matriz $A$, que são definidos como os escalares para os quais o sistema $(A - \lambda I)x = 0$ possui soluções não-nulas $x$ (os autovetores). Pelo nosso teorema, isso requer que $det(A - \lambda I) = 0$. A expressão $P_A(\lambda) = det(\lambda I - A)$ é definida como o **polinômio característico** de $A$ [^24], cujas raízes são precisamente os autovalores.

### Conclusão

Demonstramos rigorosamente, com base nas propriedades dos determinantes e na sua relação com a dependência linear estabelecida na Proposição 7.11 [^21], o teorema fundamental que afirma: *um sistema linear homogêneo $Ax = 0$ admite soluções não-triviais se, e somente se, o determinante da matriz de coeficientes $A$ é igual a zero* [^22]. Este resultado não é apenas teoricamente elegante, mas também pragmaticamente útil, fornecendo um teste computacional (o cálculo do determinante) para verificar a existência de soluções além da trivial. Ele interliga conceitos de invertibilidade de matrizes, dependência linear de vetores, dimensão do espaço nulo e, como brevemente mencionado, a teoria de autovalores e autovetores [^24, ^29], reforçando o papel central dos determinantes na álgebra linear.

### Referências
[^1]: Página 205: Introdução ao Capítulo 7, mencionando permutações e determinantes.
[^2]: Página 205: Definição 7.1 de permutação e transposição.
[^3]: Página 207: Proposição 7.1 sobre decomposição de permutações.
[^4]: Página 208: Definição 7.2 da assinatura ε(π) e Proposição 7.2 sobre a paridade.
[^5]: Página 209: Definição 7.3 de mapa multilinear.
[^6]: Página 210: Definição de mapa multilinear alternado e Proposição 7.3 sobre suas propriedades.
[^9]: Página 213: Definição 7.4 de determinante como mapa D: Mn(K) -> K, n-linear alternado nas colunas com D(In) = 1.
[^10]: Página 214: Definição 7.5 de menor e Definição 7.6 da definição indutiva D(A) via expansão de Laplace.
[^11]: Página 215: Expansão de Laplace e cofatores.
[^12]: Página 216: Lemma 7.5 mostrando que os mapas D em Dn são determinantes (alternados, multilineares, D(In)=1).
[^13]: Página 217: Teorema 7.6 provando a unicidade do determinante e a fórmula explícita D(A) = Σ ε(π)aπ(1),1...aπ(n),n.
[^14]: Página 218: Corolário 7.7 provando que det(A) = det(A^T).
[^17]: Página 221: Proposição 7.9 provando que det(AB) = det(A)det(B).
[^19]: Página 223: Proposição 7.10 sobre a adjunta AÃ = ÃA = det(A)In e a consequência sobre invertibilidade.
[^21]: Página 225: Seção 7.5, Proposição 7.11 conectando dependência linear das colunas A^1,...,A^n com det(A)=0. Equivalência de Ax=b com x1A^1+...+xnA^n=b. Menção a K ser um corpo. A invertível sse det(A) != 0 quando K é corpo.
[^22]: Página 226: Proposição 7.12 sobre soluções de Ax=b. (1) unicidade sse det(A)!=0. (2) Regra de Cramer. (3) Ax=0 tem solução não-nula sse det(A)=0.
[^23]: Página 227: Demonstração da Proposição 7.12(3), referenciando a Proposição 7.11.
[^24]: Página 228: Definição 7.9 do polinômio característico PA(X) = det(XI - A).
[^29]: Página 233: Menção aos zeros do polinômio característico como autovalores.
<!-- END -->