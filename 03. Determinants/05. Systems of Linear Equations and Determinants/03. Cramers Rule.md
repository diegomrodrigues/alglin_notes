## Capítulo 7.5.1: A Regra de Cramer e a Solução Explícita de Sistemas Lineares

### Introdução

Em continuidade à nossa exploração dos determinantes e suas propriedades fundamentais, abordamos agora uma de suas aplicações teóricas mais notáveis: a resolução de sistemas de equações lineares. Como vimos na seção anterior, o determinante de uma matriz quadrada $A$ está intimamente ligado à invertibilidade da matriz [^1] e à independência linear de seus vetores coluna (Proposição 7.11 [^3]). Especificamente, uma matriz $A \in M_n(K)$ sobre um corpo $K$ é invertível se, e somente se, $det(A) \neq 0$. Esta condição é também equivalente à afirmação de que as colunas $A^1, ..., A^n$ de $A$ formam uma base para $K^n$ [^3]. Com base nesses resultados, este capítulo detalha a **Regra de Cramer**, uma fórmula explícita para a solução única de um sistema linear $Ax = b$ quando $A$ é invertível.

### Conceitos Fundamentais: Derivação e Aplicação da Regra de Cramer

Consideremos um sistema de $n$ equações lineares com $n$ incógnitas, representado na forma matricial $Ax = b$, onde $A$ é uma matriz $n \times n$ sobre um corpo $K$, $x$ é o vetor coluna das variáveis $(x_1, ..., x_n)^T$, e $b$ é um vetor coluna $(b_1, ..., b_n)^T$ [^2]. Este sistema é equivalente à equação vetorial:

$$ x_1 A^1 + \dots + x_j A^j + \dots + x_n A^n = b $$

onde $A^1, ..., A^n$ denotam as colunas da matriz $A$ [^2].

A questão central é determinar o vetor $x$ que satisfaz esta equação. A Proposição 7.12 estabelece as condições para a existência e unicidade da solução, bem como uma fórmula explícita para ela [^4].

**Proposição 7.12 (Resumo Relevante):** Dada uma matriz $n \times n$ $A$ sobre um corpo $K$:
(1) Para todo vetor coluna $b$, existe um único vetor coluna $x$ tal que $Ax = b$ se, e somente se, a única solução para $Ax = 0$ é o vetor trivial $x = 0$, o que ocorre se, e somente se, $det(A) \neq 0$ [^4].
(2) Se $det(A) \neq 0$, a única solução de $Ax = b$ é dada pelas expressões:

> $$ x_j = \frac{det(A^1, ..., A^{j-1}, b, A^{j+1}, ..., A^n)}{det(A^1, ..., A^{j-1}, A^j, A^{j+1}, ..., A^n)} $$
> conhecidas como **Regra de Cramer** [^5].

A condição $det(A) \neq 0$ é crucial. Ela garante que $A$ é invertível (Proposição 7.10 [^1]) e que suas colunas são linearmente independentes (Proposição 7.11 [^3]), assegurando assim a existência de uma única solução para qualquer vetor $b$ [^4], [^6].

**Demonstração da Regra de Cramer (Proposição 7.12(2)):**

Assumimos que $Ax = b$ e $det(A) \neq 0$. Partimos da representação do sistema como combinação linear das colunas de $A$:
$b = x_1 A^1 + \dots + x_j A^j + \dots + x_n A^n$.

Agora, calculamos o determinante da matriz formada substituindo a $j$-ésima coluna de $A$ pelo vetor $b$:
$det(A^1, ..., A^{j-1}, b, A^{j+1}, ..., A^n)$.

Substituindo a expressão de $b$ nesta fórmula, obtemos:
$det(A^1, ..., A^{j-1}, (x_1 A^1 + \dots + x_j A^j + \dots + x_n A^n), A^{j+1}, ..., A^n)$ [^6].

Utilizando a propriedade de **multilinearidade** do determinante em relação à $j$-ésima coluna (consequência da definição de determinante, Lema 7.5 [^8]), podemos expandir esta expressão numa soma de determinantes:
$\sum_{k=1}^{n} x_k \cdot det(A^1, ..., A^{j-1}, A^k, A^{j+1}, ..., A^n)$ [^6].

Lembremos que o determinante é uma função **alternada** (Proposição 7.3 [^9]), o que implica que se uma matriz tem duas colunas idênticas, seu determinante é zero [^9], [^6]. Portanto, na soma acima, todos os termos onde $k \neq j$ serão nulos, pois a matriz correspondente terá a coluna $A^k$ repetida (uma vez na posição $k$ - se $k<j$ ou $k>j$ - e outra na posição $j$). O único termo não nulo é aquele para $k = j$:

$x_j \cdot det(A^1, ..., A^{j-1}, A^j, A^{j+1}, ..., A^n)$ [^6].

Reconhecemos que $det(A^1, ..., A^{j-1}, A^j, A^{j+1}, ..., A^n)$ é simplesmente $det(A)$. Assim, temos a igualdade:

$det(A^1, ..., A^{j-1}, b, A^{j+1}, ..., A^n) = x_j \cdot det(A)$ [^6].

Como partimos da hipótese de que $det(A) \neq 0$, podemos dividir ambos os lados por $det(A)$ para isolar $x_j$:

$$ x_j = \frac{det(A^1, ..., A^{j-1}, b, A^{j+1}, ..., A^n)}{det(A)} $$

Esta é exatamente a fórmula da Regra de Cramer [^5], [^6]. $\blacksquare$

**Observações sobre a Regra de Cramer:**

Embora a Regra de Cramer forneça uma fórmula elegante e explícita para a solução de $Ax=b$, ela é geralmente considerada *impraticável* para cálculos numéricos, especialmente para matrizes de grande dimensão, devido ao alto custo computacional do cálculo de múltiplos determinantes [^7]. Métodos como a eliminação gaussiana são computacionalmente mais eficientes.

No entanto, a Regra de Cramer tem valor teórico significativo. Por exemplo, ela demonstra explicitamente que cada componente $x_j$ da solução é um quociente de dois determinantes. Como os determinantes são funções polinomiais das entradas da matriz $A$ e do vetor $b$ [^7], a Regra de Cramer implica que a solução $x$ varia continuamente (e até diferencialmente, se as entradas forem funções diferenciáveis de um parâmetro $t$) em relação às entradas de $A$ e $b$, desde que $det(A)$ permaneça diferente de zero [^7]. Isso tem implicações importantes na análise de sensibilidade e na teoria de perturbações de sistemas lineares.

### Conclusão

A Regra de Cramer, derivada diretamente das propriedades de multilinearidade e alternância dos determinantes, oferece uma expressão teórica direta para a solução única $x$ de um sistema linear $Ax=b$, sob a condição essencial de que $det(A) \neq 0$. Embora seu uso prático em computação seja limitado, ela solidifica a conexão entre determinantes, invertibilidade de matrizes e a estrutura das soluções de sistemas lineares, além de fornecer insights sobre a dependência da solução em relação aos dados do problema. Ela representa um marco teórico importante no estudo de equações lineares, complementando os resultados sobre determinantes e matrizes inversas discutidos anteriormente.

### Referências
[^1]: Proposição 7.10, Página 223: AÃ = ÃA = det(A)In. Como consequência, A é invertível sse det(A) é invertível.
[^2]: Página 225: Definição do sistema Ax = b e sua equivalência com x₁A¹ + ... + xnAn = b.
[^3]: Proposição 7.11, Página 225: As colunas A¹, ..., An de A são linearmente dependentes sse det(A) = det(A¹, ..., An) = 0. Equivalente, A tem rank n sse det(A) ≠ 0.
[^4]: Proposição 7.12(1), Página 226: Para todo b, existe um único x tal que Ax = b sse a única solução para Ax = 0 é x = 0, sse det(A) ≠ 0.
[^5]: Proposição 7.12(2), Página 226: Se det(A) ≠ 0, a única solução de Ax = b é dada pela expressão xj = det(A¹, ..., Aʲ⁻¹, b, Aʲ⁺¹, ..., Aⁿ) / det(A¹, ..., Aʲ⁻¹, Aʲ, Aʲ⁺¹, ..., Aⁿ), conhecida como Regra de Cramer.
[^6]: Prova da Proposição 7.12(2), Página 227: Demonstração da fórmula de Cramer usando multilinearidade e o fato de que det(..., Aᵏ, ...) = 0 se Aᵏ aparece duas vezes.
[^7]: Página 227: Discussão sobre a impraticabilidade da Regra de Cramer para computação, mas seu valor teórico, incluindo a continuidade/diferenciabilidade da solução xj(t) se as entradas aij(t) e bj(t) forem contínuas/diferenciáveis e det(A(t)) ≠ 0.
[^8]: Lema 7.5, Página 216: Prova que D (definido indutivamente via expansão de Laplace) é um mapa multilinear alternado com D(In)=1. A multilinearidade é usada na prova de Cramer.
[^9]: Proposição 7.3, Página 210: Propriedades de mapas multilineares alternados, incluindo f(..., xi, ..., xj, ...) = 0 se xi = xj. Usado na prova de Cramer para anular termos com colunas repetidas.
<!-- END -->