## Capítulo 7.3.1: Propriedades Fundamentais: Determinante da Transposta e do Produto de Matrizes

### Introdução

Após estabelecermos a definição formal de um **determinante** como uma aplicação $D: M_n(K) \to K$ que é **n-linear alternada** nas colunas da matriz e tal que $D(I_n) = 1$ [^9], e demonstrarmos sua unicidade e equivalência com a fórmula explícita baseada em permutações (Teorema 7.6 [^13]), podemos agora derivar algumas de suas propriedades algébricas mais fundamentais. Este capítulo foca em duas propriedades cruciais que simplificam cálculos e possuem implicações teóricas importantes: a relação entre o determinante de uma matriz e sua transposta, e o comportamento do determinante sob o produto de matrizes. Estas propriedades emergem diretamente da definição e das caracterizações que exploramos anteriormente.

### Propriedade 1: Determinante da Matriz Transposta

Uma das simetrias notáveis da função determinante é sua invariância sob a operação de transposição. Como vimos no Corolário 7.7 [^14], o determinante de uma matriz quadrada é igual ao determinante de sua transposta.

**Corolário 7.7.** *Para toda matriz $A \in M_n(K)$, temos $\det(A) = \det(A^T)$.* [^14]

**Prova.** Pelo Teorema 7.6 [^13], o determinante de $A = (a_{ij})$ é dado pela fórmula explícita:
$$ \det(A) = \sum_{\pi \in S_n} \varepsilon(\pi) a_{\pi(1), 1} \cdots a_{\pi(n), n} $$
onde a soma percorre todas as **permutações** $\pi$ do conjunto $\{1, \dots, n\}$ [^2], $S_n$ é o grupo de permutações [^2], e $\varepsilon(\pi)$ é a **assinatura** da permutação $\pi$ [^4]. Como cada permutação $\pi$ é uma bijeção, cada produto no somatório contém exatamente um elemento de cada linha e cada coluna de $A$. O produto $a_{\pi(1), 1} \cdots a_{\pi(n), n}$ pode ser reordenado de acordo com o primeiro índice (índice de linha). Se $i = \pi(j)$, então $j = \pi^{-1}(i)$. Assim, reordenando os termos para que os índices de linha apareçam em ordem crescente, temos:
$$ a_{\pi(1), 1} \cdots a_{\pi(n), n} = a_{1, \pi^{-1}(1)} \cdots a_{n, \pi^{-1}(n)} $$
[^14]
Lembramos que a assinatura da inversa de uma permutação é igual à assinatura da própria permutação, ou seja, $\varepsilon(\pi^{-1}) = \varepsilon(\pi)$ [^5]. Além disso, a aplicação $\pi \mapsto \pi^{-1}$ é uma bijeção de $S_n$ para si mesma. Portanto, podemos substituir $\pi$ por $\sigma = \pi^{-1}$ no somatório. Quando $\pi$ percorre todas as permutações em $S_n$, $\sigma$ também percorre todas as permutações. Assim, obtemos:
$$ \det(A) = \sum_{\pi \in S_n} \varepsilon(\pi) a_{1, \pi^{-1}(1)} \cdots a_{n, \pi^{-1}(n)} = \sum_{\sigma \in S_n} \varepsilon(\sigma^{-1}) a_{1, \sigma(1)} \cdots a_{n, \sigma(n)} $$
$$ \det(A) = \sum_{\sigma \in S_n} \varepsilon(\sigma) a_{1, \sigma(1)} \cdots a_{n, \sigma(n)} $$
[^14]
A expressão final é precisamente a definição do determinante da matriz transposta $A^T$, cujos elementos $(A^T)_{ij}$ são $a_{ji}$. Se definirmos $(A^T)_{ij} = a'_{ij} = a_{ji}$, a fórmula se torna $\sum_{\sigma \in S_n} \varepsilon(\sigma) a'_{ \sigma(1), 1} \cdots a'_{ \sigma(n), n}$ (se pensarmos na definição aplicada às colunas de $A^T$) ou, equivalentemente, $\sum_{\sigma \in S_n} \varepsilon(\sigma) a'_{1, \sigma(1)} \cdots a'_{n, \sigma(n)}$ (se pensarmos na definição aplicada às linhas de $A^T$, que são as colunas de A). A expressão $\sum_{\sigma \in S_n} \varepsilon(\sigma) a_{1, \sigma(1)} \cdots a_{n, \sigma(n)}$ corresponde diretamente à definição do determinante de $A^T$ via Teorema 7.6, considerando a fórmula alternativa mencionada no Remark da página 213 [^9]. Portanto,
$$ \det(A^T) = \sum_{\sigma \in S_n} \varepsilon(\sigma) a_{1, \sigma(1)} \cdots a_{n, \sigma(n)} $$
[^14]
Comparando as expressões, concluímos que $\det(A) = \det(A^T)$. [^14] $\blacksquare$

> Uma consequência útil do Corolário 7.7 é que o determinante de uma matriz também é uma **aplicação multilinear alternada** de suas *linhas*. [^14] Isso significa que todas as propriedades que derivamos para colunas (como a troca de duas colunas multiplicar o determinante por -1 [^6], ou o determinante ser zero se duas colunas forem iguais [^6]) também valem para as linhas.

### Propriedade 2: Determinante do Produto de Matrizes

Outra propriedade central é a relação entre o determinante de um produto de matrizes e os determinantes das matrizes individuais. Esta propriedade é fundamental, por exemplo, na teoria de grupos lineares e na análise de similaridade de matrizes.

**Proposição 7.9.** *Para quaisquer duas matrizes $A, B \in M_n(K)$, temos $\det(AB) = \det(A)\det(B)$.* [^17]

**Prova.** A prova utiliza a reformulação do Lema 7.4 apresentada na Proposição 7.8 [^17]. Seja $(e_1, \dots, e_n)$ a base canônica de $K^n$ [^13]. As colunas da matriz $AB$ são os vetores $(AB)e_j$, que denotaremos por $w_j$. Ou seja, $w_j = (AB)^j$. Pela definição de determinante como uma aplicação n-linear alternada tal que $\det(I_n) = \det(e_1, \dots, e_n) = 1$ [^9, ^12], temos:
$$ \det(AB) = \det(w_1, \dots, w_n) $$
[^17]
Seja $v_j = Be_j$ o vetor correspondente à j-ésima coluna da matriz $B$, ou seja, $v_j = B^j$. Então, pela Proposição 7.8 [^17], que afirma que para uma aplicação n-linear alternada $f$ e vetores $v_j = \sum_k a_{kj} u_k$ (ou $v = A^T u$), temos $f(v_1, \dots, v_n) = \det(A^T) f(u_1, \dots, u_n)$, ou equivalentemente, se $v_j = \sum_k a_{jk} u_k$ (ou $v = Au$), então $f(v_1, \dots, v_n) = \det(A) f(u_1, \dots, u_n)$ [^17]. Aplicando isso à função determinante $f = \det$ e aos vetores $v_j = Be_j = \sum_k b_{kj} e_k$, temos:
$$ \det(v_1, \dots, v_n) = \det(B) \det(e_1, \dots, e_n) = \det(B) \cdot 1 = \det(B) $$
[^18]
Agora, observe que $w_j = (AB)e_j = A(Be_j) = Av_j$. Ou seja, os vetores coluna $w_j$ da matriz $AB$ são obtidos aplicando a transformação linear representada por $A$ aos vetores coluna $v_j$ da matriz $B$. Novamente, aplicando a Proposição 7.8 [^17] com $f = \det$, $u_j = v_j$ e a matriz de transformação sendo $A$, temos:
$$ \det(w_1, \dots, w_n) = \det(A) \det(v_1, \dots, v_n) $$
[^18]
Combinando as equações, obtemos:
$$ \det(AB) = \det(w_1, \dots, w_n) = \det(A) \det(v_1, \dots, v_n) = \det(A) \det(B) $$
[^18]
Isso completa a prova. $\blacksquare$

> É importante notar que, como mencionado na página 222 [^18], os resultados desta seção, incluindo $\det(A) = \det(A^T)$ e $\det(AB) = \det(A)\det(B)$, também são válidos quando $K$ é um anel comutativo, não necessariamente um corpo.

### Conclusão

As propriedades $\det(A) = \det(A^T)$ e $\det(AB) = \det(A)\det(B)$ são pilares fundamentais da teoria dos determinantes. A primeira estabelece uma simetria entre linhas e colunas, permitindo que resultados derivados para colunas sejam aplicados diretamente às linhas. A segunda propriedade, a multiplicatividade do determinante, é essencial para entender como transformações lineares compostas afetam volumes (interpretando o determinante como volume orientado [^13]) e é crucial para definir o determinante de um operador linear de forma independente da base [^24] e para analisar a invertibilidade de matrizes [^19, ^20] e operadores. Essas propriedades, derivadas diretamente da definição n-linear alternada, solidificam o determinante como uma ferramenta algébrica poderosa em álgebra linear e suas aplicações.

### Referências

[^1]: Capítulo 7: Determinantes. Neste capítulo, todos os espaços vetoriais são definidos sobre um corpo arbitrário K.
[^2]: Definição 7.1: Permutação, Transposição. $S_n$ denota o grupo de permutações em $[n]$.
[^3]: Proposição 7.1: Toda permutação é um produto de transposições.
[^4]: Definição 7.2: Assinatura $\varepsilon(\pi) = (-1)^{n-r}$. Se $\tau$ é uma transposição, $\varepsilon(\tau)=-1$.
[^5]: Proposição 7.2: $\varepsilon(\tau \circ \pi) = -\varepsilon(\pi)$. Consequentemente, $\varepsilon(\pi) = (-1)^m$ se $\pi$ é produto de $m$ transposições. $\varepsilon(\pi^{-1}) = \varepsilon(\pi)$.
[^6]: Proposição 7.3: Propriedades de mapas multilineares alternados $f$. (1) $f(\dots, x_i, x_{i+1}, \dots) = -f(\dots, x_{i+1}, x_i, \dots)$. (2) $f(\dots, x_i, \dots, x_j, \dots) = 0$ se $x_i = x_j$. (3) $f(\dots, x_i, \dots, x_j, \dots) = -f(\dots, x_j, \dots, x_i, \dots)$.
[^7]: Lema 7.4: Seja $f: E \times \dots \times E \to F$ um mapa n-linear alternado. Sejam $(u_1, \dots, u_n)$ e $(v_1, \dots, v_n)$ famílias de vetores tais que $v_j = \sum_k a_{kj} u_k$.
[^8]: Lema 7.4 (Resultado): $f(v_1, \dots, v_n) = (\sum_{\pi \in S_n} \varepsilon(\pi) a_{\pi(1), 1} \cdots a_{\pi(n), n}) f(u_1, \dots, u_n)$. Note que a matriz que relaciona $v$ e $u$ é $A^T$, onde $A=(a_{ij})$.
[^9]: Definição 7.4: Um determinante é um mapa $D: M_n(K) \to K$ que, visto como um mapa nas $n$ colunas de uma matriz, é n-linear alternado e tal que $D(I_n)=1$.
[^10]: Definição 7.5: Menor $A_{ij}$ de uma matriz.
[^11]: Definição 7.6: Definição indutiva do determinante via expansão de Laplace. $D(A) = \sum_{j=1}^n (-1)^{i+j} a_{ij} D(A_{ij})$.
[^12]: Lema 7.5: Para cada $D \in D_n$ (definido indutivamente), $D$ é um mapa multilinear alternado tal que $D(I_n)=1$.
[^13]: Teorema 7.6: Para cada $D \in D_n$, $D(A) = \sum_{\pi \in S_n} \varepsilon(\pi) a_{\pi(1), 1} \cdots a_{\pi(n), n}$. Como consequência, $D_n$ consiste de um único mapa. Notação $\det(A)$ favorecida. Interpretação geométrica como volume orientado de um paralelepípedo.
[^14]: Corolário 7.7: Para toda matriz $A \in M_n(K)$, temos $\det(A) = \det(A^T)$. A prova usa a fórmula do Teorema 7.6 e $\varepsilon(\pi^{-1}) = \varepsilon(\pi)$. Consequência: det é multilinear alternado nas linhas.
[^15]: Exemplo 7.2: Determinante de Vandermonde.
[^16]: Exemplo 7.3: Determinante de matrizes triangulares superiores por blocos.
[^17]: Proposição 7.8: Reformulação do Lema 7.4. Se $v_j = \sum_k a_{jk} u_k$ (i.e., $v = Au$), então $f(v_1, \dots, v_n) = \det(A) f(u_1, \dots, u_n)$. Prova usa Lema 7.4 e Corolário 7.7. Proposição 7.9: Para quaisquer $A, B \in M_n(K)$, $\det(AB) = \det(A)\det(B)$.
[^18]: Prova da Proposição 7.9: Usa Prop. 7.8 com $f=\det$, base canônica $e_j$, $w_j = (AB)e_j$, $v_j = Be_j$. $\det(w_1, \dots, w_n) = \det(AB)\det(e_1, \dots, e_n) = \det(AB)$. $\det(v_1, \dots, v_n) = \det(B)\det(e_1, \dots, e_n) = \det(B)$. $\det(w_1, \dots, w_n) = \det(A)\det(v_1, \dots, v_n)$. Combinando, $\det(AB) = \det(A)\det(B)$. Resultados válidos para anéis comutativos.
[^19]: Proposição 7.10: $A \tilde{A} = \tilde{A} A = \det(A) I_n$. $A$ é invertível sse $\det(A)$ é invertível. Se $K$ é corpo, $A$ é invertível sse $\det(A) \neq 0$.
[^20]: Proposição 7.11: Colunas de $A$ são linearmente dependentes sse $\det(A)=0$. $A$ tem posto $n$ sse $\det(A) \neq 0$.
[^21]: Proposição 7.12: Sistemas $Ax=b$. Solução única sse $\det(A) \neq 0$. Regra de Cramer. $Ax=0$ tem solução não-trivial sse $\det(A)=0$.
[^22]: Seção 7.6: Determinante de um Mapa Linear. $\det(f) = \det(M(f))$.
[^23]: Definição 7.8: $\det(f)$ é definido como $\det(M(f))$ para qualquer base. Independência da base segue de $\det(P^{-1}MP) = \det(M)$.
[^24]: Proposição 7.13: $f: E \to E$ é invertível sse $\det(f) \neq 0$.

<!-- END -->