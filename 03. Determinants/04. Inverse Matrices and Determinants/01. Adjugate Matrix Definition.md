## Capítulo 7: Determinantes (Continuação) - A Matriz Adjunta e a Inversão de Matrizes

### Introdução

Continuando nossa exploração das propriedades e aplicações dos determinantes, iniciada com a discussão de permutações [^1], mapas multilineares [^8] e a definição formal de determinantes [^16], abordamos agora um conceito central que conecta determinantes à teoria de inversão de matrizes: a **matriz adjunta**. Como estabelecido anteriormente, o determinante de uma matriz $A \in M_n(K)$, onde $K$ é um corpo [^1] ou, mais geralmente, um anel comutativo [^32], é um escalar que encapsula propriedades fundamentais da transformação linear associada a $A$. Vimos que $det(A)$ pode ser calculado via expansão de Laplace [^19] e que possui propriedades cruciais como $det(A) = det(A^T)$ [^25] e $det(AB) = det(A)det(B)$ [^30].

Nesta seção, introduziremos formalmente a matriz adjunta, denotada por $\hat{A}$, e demonstraremos sua relação fundamental com o determinante e a matriz identidade. Esta relação não só fornece uma fórmula explícita para a inversa de uma matriz, quando existente, mas também reforça a importância do determinante como um indicador da invertibilidade [^37, ^41]. O desenvolvimento será feito considerando $K$ como um anel comutativo [^32], alinhando-se com a generalidade apresentada no contexto.

### Conceitos Fundamentais

#### Definição da Matriz Adjunta

A construção da matriz adjunta baseia-se nos conceitos de **menores** e **cofatores** de uma matriz, introduzidos previamente no contexto da expansão de Laplace [^17, ^19].

> **Definição 7.7 (Adaptada).** Seja $K$ um anel comutativo. Dada uma matriz $A \in M_n(K)$, a **matriz adjunta** de $A$, denotada por $\hat{A}$, é a matriz $(b_{ij})$ cujas entradas são dadas por:
> $$ b_{ij} = (-1)^{i+j} \det(A_{ji}) $$
> onde $A_{ji}$ é a matriz $(n-1) \times (n-1)$ obtida pela remoção da $j$-ésima linha (*row j*) e da $i$-ésima coluna (*column i*) de $A$ [^33]. Cada matriz $A_{ji}$ é chamada de **menor** da matriz $A$ [^33]. O termo $(-1)^{j+i} \det(A_{ji})$ é o **cofator** do elemento $a_{ji}$ [^19, ^33].

É crucial observar a inversão dos índices na definição: a entrada $(i,j)$ da matriz adjunta $\hat{A}$, $b_{ij}$, depende do determinante do menor $A_{ji}$, que é obtido removendo a linha $j$ e a coluna $i$ de $A$ [^34]. Consequentemente, a matriz adjunta $\hat{A}$ é a **transposta da matriz de cofatores** dos elementos de $A$ [^35].

*Exemplo:* Considere a matriz $A \in M_3(K)$ dada por [^33]:
$$ A = \begin{pmatrix} 1 & 1 & 1 \\\\ 2 & -2 & -2 \\\\ 3 & 3 & -3 \end{pmatrix} $$
Calculando algumas entradas de $\hat{A} = (b_{ij})$ usando a definição $b_{ij} = (-1)^{i+j} \det(A_{ji})$:
$b_{11} = (-1)^{1+1} \det(A_{11}) = \det \begin{pmatrix} -2 & -2 \\\\ 3 & -3 \end{pmatrix} = (-2)(-3) - (-2)(3) = 6 + 6 = 12$ [^34].
$b_{12} = (-1)^{1+2} \det(A_{21}) = -\det \begin{pmatrix} 1 & 1 \\\\ 3 & -3 \end{pmatrix} = -((1)(-3) - (1)(3)) = -(-3 - 3) = 6$ [^34].
$b_{21} = (-1)^{2+1} \det(A_{12}) = -\det \begin{pmatrix} 2 & -2 \\\\ 3 & -3 \end{pmatrix} = -((2)(-3) - (-2)(3)) = -(-6 + 6) = 0$ [^34].
Continuando esses cálculos para todas as entradas, obtemos a matriz adjunta:
$$ \hat{A} = \begin{pmatrix} 12 & 6 & 0 \\\\ 0 & -6 & 4 \\\\ 12 & 0 & -4 \end{pmatrix} $$
[^34].

#### Propriedade Fundamental (AÂ = ÂA = det(A)In)

A propriedade mais importante da matriz adjunta é sua relação com a matriz original $A$ e seu determinante $det(A)$.

> **Proposição 7.10.** Seja $K$ um anel comutativo. Para toda matriz $A \in M_n(K)$, temos:
> $$ A\hat{A} = \hat{A}A = \det(A)I_n $$
> onde $I_n$ é a matriz identidade $n \times n$ [^36].

*Demonstração:* Seja $A = (a_{ij})$ e $\hat{A} = (b_{ij})$, onde $b_{kj} = (-1)^{k+j} \det(A_{jk})$. Considere o produto $C = A\hat{A}$, cuja entrada $(i,j)$ é dada por $c_{ij} = \sum_{k=1}^{n} a_{ik} b_{kj}$. Substituindo $b_{kj}$, temos:
$$ c_{ij} = \sum_{k=1}^{n} a_{ik} b_{kj} = \sum_{k=1}^{n} a_{ik} (-1)^{k+j} \det(A_{jk}) $$
[^37].

Caso $j = i$:
$$ c_{ii} = \sum_{k=1}^{n} a_{ik} (-1)^{k+i} \det(A_{ik}) $$
Esta é precisamente a expansão de Laplace do determinante de $A$ ao longo da $i$-ésima linha (*i-th Row*) [^19, ^37]. Portanto, $c_{ii} = \det(A)$.

Caso $j \neq i$:
$$ c_{ij} = \sum_{k=1}^{n} a_{ik} (-1)^{k+j} \det(A_{jk}) $$
Considere uma matriz $A'$ formada substituindo a $j$-ésima linha de $A$ pela $i$-ésima linha de $A$. Assim, $A'$ tem duas linhas idênticas (a $i$-ésima e a $j$-ésima). O menor $A'_{jk}$ obtido removendo a linha $j$ e a coluna $k$ de $A'$ é idêntico ao menor $A_{jk}$ obtido removendo a linha $j$ e a coluna $k$ de $A$, pois ambas as matrizes $A$ e $A'$ só diferem na $j$-ésima linha, que é removida [^38]. Além disso, a entrada $(j,k)$ de $A'$ é $a'_{jk} = a_{ik}$. A expansão de Laplace de $\det(A')$ ao longo da $j$-ésima linha é:
$$ \det(A') = \sum_{k=1}^{n} a'_{jk} (-1)^{j+k} \det(A'_{jk}) = \sum_{k=1}^{n} a_{ik} (-1)^{j+k} \det(A_{jk}) = c_{ij} $$
Como $A'$ possui duas linhas idênticas (a $i$-ésima e a $j$-ésima) e o determinante é uma função alternante das linhas (uma consequência de $det(A) = det(A^T)$ [^25] e da propriedade alternante sobre as colunas [^9, ^22]), temos que $\det(A') = 0$ [^38]. Logo, $c_{ij} = 0$ para $j \neq i$.

Combinando os dois casos, $c_{ii} = \det(A)$ e $c_{ij} = 0$ para $j \neq i$. Isso significa que $A\hat{A} = \det(A)I_n$ [^38].

Para provar $\hat{A}A = \det(A)I_n$, podemos aplicar o resultado que acabamos de provar à transposta $A^T$. Sabemos que $\det(A^T) = \det(A)$ [^25] e que a adjunta de $A^T$ é a transposta da adjunta de $A$, ou seja, $(A^T)\hat{} = (\hat{A})^T$ [^38]. Aplicando a primeira parte do teorema a $A^T$:
$$ A^T (A^T)\hat{} = \det(A^T)I_n $$
$$ A^T (\hat{A})^T = \det(A)I_n $$
Tomando a transposta de ambos os lados:
$$ (A^T (\hat{A})^T)^T = (\det(A)I_n)^T $$
$$ ((\hat{A})^T)^T (A^T)^T = \det(A)I_n^T $$
$$ \hat{A} A = \det(A)I_n $$
[^38]. Isso completa a demonstração. $\blacksquare$

#### Relação com a Matriz Inversa

A Proposição 7.10 estabelece uma condição clara para a invertibilidade de uma matriz e fornece uma fórmula para sua inversa.

> **Corolário (de Proposição 7.10).** Seja $K$ um anel comutativo. Uma matriz $A \in M_n(K)$ é invertível se e somente se $\det(A)$ é invertível em $K$. Se $\det(A)$ for invertível, então a inversa de $A$ é dada por:
> $$ A^{-1} = (\det(A))^{-1} \hat{A} $$
> [^37].

*Demonstração:* Se $\det(A)$ é invertível em $K$, existe $(\det(A))^{-1} \in K$. Multiplicando a equação $A\hat{A} = \det(A)I_n$ por $(\det(A))^{-1}$, obtemos $A ((\det(A))^{-1} \hat{A}) = I_n$. Similarmente, de $\hat{A}A = \det(A)I_n$, obtemos $((\det(A))^{-1} \hat{A}) A = I_n$. Isso mostra que $A$ é invertível e $A^{-1} = (\det(A))^{-1} \hat{A}$ [^37].
Reciprocamente, se $A$ é invertível, existe $A^{-1}$ tal que $AA^{-1} = I_n$. Aplicando o determinante, temos $\det(A A^{-1}) = \det(I_n)$. Usando a propriedade $\det(AB) = \det(A)\det(B)$ [^30], temos $\det(A)\det(A^{-1}) = 1$. Isso mostra que $\det(A)$ possui um inverso multiplicativo em $K$, que é $\det(A^{-1})$, e portanto $\det(A)$ é invertível em $K$ [^38]. $\blacksquare$

Quando $K$ é um corpo (como $\mathbb{R}$ ou $\mathbb{C}$), um elemento é invertível se e somente se ele é diferente de zero [^40]. Portanto, para matrizes sobre um corpo, $A$ é invertível se e somente se $\det(A) \neq 0$ [^41]. A fórmula $A^{-1} = (\det(A))^{-1} \hat{A}$ fornece uma expressão teórica para a inversa, embora seu cálculo direto via adjunta seja computacionalmente intensivo para matrizes grandes e geralmente não prático em comparação com outros métodos como a eliminação Gauss-Jordan [^40].

### Conclusão

A **matriz adjunta** $\hat{A}$ emerge como uma construção teórica fundamental no estudo dos determinantes e da inversão de matrizes sobre um anel comutativo $K$. Definida como a transposta da matriz de cofatores [^35], sua propriedade central $A\hat{A} = \hat{A}A = \det(A)I_n$ [^36] estabelece uma ligação direta e elegante entre uma matriz, seu determinante e a matriz identidade. Este resultado não apenas fornece um critério de invertibilidade – uma matriz $A$ é invertível se e somente se $\det(A)$ é invertível em $K$ [^37] – mas também oferece uma fórmula explícita para a inversa, $A^{-1} = (\det(A))^{-1} \hat{A}$. Embora não seja frequentemente o método mais eficiente para cálculo computacional da inversa [^40], a relação proporcionada pela matriz adjunta é de grande importância teórica, servindo de base para outras demonstrações e resultados, como as regras de Cramer para a solução de sistemas lineares [^42] e o Teorema de Cayley-Hamilton [^45, ^48].

### Referências

[^1]: Capítulo 7, Seção 7.1 (pg 205)
[^2]: Capítulo 7, Seção 7.1 (pg 206)
[^3]: Capítulo 7, Proposição 7.1 (pg 206)
[^4]: Capítulo 7, Proposição 7.1, Prova (pg 207)
[^5]: Capítulo 7, Definição 7.2 (pg 208)
[^6]: Capítulo 7, Proposição 7.2 (pg 208)
[^7]: Capítulo 7, Proposição 7.2, Prova (pg 209)
[^8]: Capítulo 7, Seção 7.2, Definição 7.3 (pg 209)
[^9]: Capítulo 7, Seção 7.2 (pg 210)
[^10]: Capítulo 7, Proposição 7.3 (pg 210)
[^11]: Capítulo 7, Proposição 7.3, Prova (pg 211)
[^12]: Capítulo 7, Lemma 7.4 (pg 211)
[^13]: Capítulo 7, Lemma 7.4, Prova (pg 212)
[^14]: Capítulo 7, Fim da Seção 7.2 (pg 212)
[^15]: Capítulo 7, Remark (pg 213)
[^16]: Capítulo 7, Seção 7.3, Definição 7.4 (pg 213)
[^17]: Capítulo 7, Definição 7.5 (pg 214)
[^18]: Capítulo 7, Definição 7.6 (pg 214)
[^19]: Capítulo 7, Definição 7.6 e texto subsequente (pg 215)
[^20]: Capítulo 7, Exemplo 7.1 (pg 215)
[^21]: Capítulo 7, Exemplo n=3 e fórmula explícita (pg 216)
[^22]: Capítulo 7, Lemma 7.5 (pg 216)
[^23]: Capítulo 7, Teorema 7.6 (pg 217)
[^24]: Capítulo 7, Remark (pg 217)
[^25]: Capítulo 7, Corolário 7.7 (pg 218)
[^26]: Capítulo 7, Consequência do Corolário 7.7 (pg 218)
[^27]: Capítulo 7, Exemplo 7.2 (pg 219)
[^28]: Capítulo 7, Exemplo 7.3 (pg 220)
[^29]: Capítulo 7, Proposição 7.8 (pg 221)
[^30]: Capítulo 7, Proposição 7.9 (pg 221)
[^31]: Capítulo 7, Remark (pg 222)
[^32]: Capítulo 7, Seção 7.4 (pg 222)
[^33]: Capítulo 7, Definição 7.7 (pg 222)
[^34]: Capítulo 7, Exemplo após Definição 7.7 e nota sobre índices (pg 223)
[^35]: Capítulo 7, Texto após exemplo (pg 223)
[^36]: Capítulo 7, Proposição 7.10 (pg 223)
[^37]: Capítulo 7, Consequência da Proposição 7.10 (pg 223)
[^38]: Capítulo 7, Prova da Proposição 7.10 (pg 223-224)
[^39]: Capítulo 7, Exemplo de cálculo (pg 225)
[^40]: Capítulo 7, Remark sobre corpo K e praticidade (pg 225)
[^41]: Capítulo 7, Proposição 7.11 (pg 225)
[^42]: Capítulo 7, Proposição 7.12 (pg 226)
[^43]: Capítulo 7, Prova da Proposição 7.12 (pg 227)
[^44]: Capítulo 7, Proposição 7.13 e Definição 7.9 (pg 228)
[^45]: Capítulo 7, Teorema 7.14 (Cayley-Hamilton) (pg 229)
[^46]: Capítulo 7, Prova do Teorema 7.14 (pg 230)
[^47]: Capítulo 7, Motivação para segunda prova (pg 231)
[^48]: Capítulo 7, Teorema 7.15 e prova (pg 232)
[^49]: Capítulo 7, Seção 7.8 (pg 233)
[^50]: Capítulo 7, Seção 7.8 (pg 234)
[^51]: Capítulo 7, Seção 7.8 (pg 235)
[^52]: Capítulo 7, Seção 7.9 (pg 236)
[^53]: Capítulo 7, Seção 7.10 (pg 237)

<!-- END -->