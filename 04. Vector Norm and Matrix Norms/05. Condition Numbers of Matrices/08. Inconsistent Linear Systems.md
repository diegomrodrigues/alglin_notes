## Resolvendo Sistemas Lineares Inconsistentes com Normas

### Introdução

Em muitos problemas práticos, deparamo-nos com sistemas lineares da forma $Ax = b$ que não possuem uma solução exata. Isso ocorre quando o vetor $b$ não pertence ao espaço coluna da matriz $A$ [^365]. Nesses casos, procuramos soluções *aproximadas* que minimizem algum tipo de erro [^1]. Este capítulo explora métodos para encontrar tais soluções, utilizando conceitos de normas vetoriais e matriciais, e introduz a ideia de *número de condição* que quantifica a sensibilidade da solução a pequenas perturbações nos dados.

### Conceitos Fundamentais

Quando um sistema linear $Ax = b$ é **inconsistente**, ou seja, não possui solução exata [^1, 358], podemos buscar uma solução que minimize o erro $||Ax - b||$ [^1]. Existem diversas maneiras de definir e minimizar este erro, levando a diferentes abordagens:

1.  **Mínimos Quadrados (Least Squares):**
    -   O objetivo é encontrar $x$ que minimize a norma Euclidiana (norma-2) do resíduo $r = Ax - b$, ou seja, minimizar $||Ax - b||_2^2$ [^358].
    -   Esta abordagem é equivalente a minimizar a soma dos quadrados dos erros individuais.
    -   A solução para o problema de mínimos quadrados é dada pelas equações normais: $A^T A x = A^T b$, onde $A^T$ representa a transposta da matriz $A$.
    -   Caso a matriz $A^T A$ seja invertível, a solução é dada por $x = (A^T A)^{-1} A^T b$.
    -   A solução de mínimos quadrados pode ser obtida utilizando a pseudo-inversa de Penrose $A^+$ de A, fornecida pela decomposição em valores singulares (SVD): $x = A^+b$ [^359].

2.  **Programação Linear:**
    -   Em vez de minimizar a norma-2, podemos minimizar a norma-1 do resíduo $r = Ax - b$, ou seja, minimizar $||Ax - b||_1$. Esta abordagem é menos sensível a *outliers* (pontos fora do padrão) [^359].
    -   O problema de minimizar $||Ax - b||_1$ pode ser reformulado como um problema de programação linear, que pode ser resolvido utilizando algoritmos específicos [^359].
    -   A minimização da norma-infinito $||Ax - b||_\infty$ também pode ser convertida em um problema de programação linear.

**Normas Vetoriais:** Uma norma vetorial $||.||$ em um espaço vetorial $E$ é uma função $||.||: E \rightarrow \mathbb{R}^+$ que satisfaz as seguintes propriedades [^323]:

*   Não-negatividade: $||x|| \geq 0$ para todo $x \in E$, e $||x|| = 0$ se e somente se $x = 0$.
*   Homogeneidade: $||\lambda x|| = |\lambda| ||x||$ para todo $x \in E$ e $\lambda \in K$, onde $K$ é o campo escalar (reais ou complexos).
*   Desigualdade triangular: $||x + y|| \leq ||x|| + ||y||$ para todos $x, y \in E$.

Exemplos comuns de normas vetoriais incluem [^324]:

*   Norma-1: $||x||_1 = \sum_{i=1}^n |x_i|$
*   Norma-2 (Euclidiana): $||x||_2 = \sqrt{\sum_{i=1}^n |x_i|^2}$
*   Norma-infinito: $||x||_\infty = \max_{1 \leq i \leq n} |x_i|$

**Normas Matriciais:** Uma norma matricial $||.||$ em um espaço de matrizes $M_{n}(K)$ (matrizes $n \times n$ sobre o campo $K$) é uma norma vetorial que também satisfaz a propriedade de submultiplicatividade [^335]:

*   Submultiplicatividade: $||AB|| \leq ||A|| ||B||$ para todas as matrizes $A, B \in M_{n}(K)$.

Exemplos comuns de normas matriciais incluem [^338, 341]:

*   Norma de Frobenius: $||A||_F = \sqrt{\sum_{i=1}^n \sum_{j=1}^n |a_{ij}|^2}$
*   Norma espectral (ou norma-2): $||A||_2 = \sqrt{\rho(A^*A)}$, onde $\rho(A^*A)$ é o maior autovalor de $A^*A$ [^341].
*   Norma subordinada (ou norma de operador): Definida como $||A||_{op} = \sup_{x \neq 0} \frac{||Ax||}{||x||}$ [^341].

**Número de Condição:** O **número de condição** de uma matriz invertível $A$, denotado por $cond(A)$, mede a sensibilidade da solução de um sistema linear $Ax = b$ a pequenas perturbações nos dados [^351]. É definido como:

$$ cond(A) = ||A|| ||A^{-1}|| $$

Um número de condição alto indica que o sistema é *mal condicionado*, ou seja, pequenas perturbações nos dados podem levar a grandes variações na solução [^351]. Um número de condição próximo de 1 indica um sistema *bem condicionado*.

### Condicionamento e Perturbações

A análise de condicionamento é crucial ao lidar com sistemas lineares inconsistentes, pois permite quantificar o impacto de erros nos dados de entrada sobre a solução aproximada. Pequenas alterações nos coeficientes da matriz $A$ ou no vetor $b$ podem resultar em variações significativas na solução $x$, especialmente se o sistema for mal condicionado.

Seja $Ax = b$ e $(A + \Delta A)(x + \Delta x) = b + \Delta b$. Podemos relacionar os erros relativos na solução, na matriz e no vetor da seguinte forma (assumindo que $||\Delta A|| < 1/||A^{-1}||$):

$$ \frac{||\Delta x||}{||x||} \leq \frac{cond(A)}{1 - ||A^{-1}|| ||\Delta A||} \left( \frac{||\Delta b||}{||b||} + \frac{||\Delta A||}{||A||} \right) $$

Esta desigualdade mostra que o erro relativo na solução é amplificado pelo número de condição de $A$.

### Conclusão

Resolver sistemas lineares inconsistentes requer o uso de métodos de aproximação, como mínimos quadrados ou programação linear, que minimizam o erro $||Ax - b||$. A escolha da norma utilizada para medir o erro influencia a solução obtida. Além disso, a análise do número de condição da matriz $A$ é fundamental para entender a sensibilidade da solução a perturbações nos dados. Um sistema mal condicionado pode gerar soluções imprecisas mesmo com pequenas alterações nos dados de entrada. Portanto, é crucial considerar o condicionamento do sistema ao interpretar os resultados obtidos por métodos de aproximação.

### Referências

[^1]: Solving inconsistent linear systems can be approached using methods like least squares or linear programming, which aim to minimize the error ||Ax - b||. These techniques provide approximate solutions when an exact solution does not exist.
[^323]: Definition 9.1. Let E be a vector space over a field K, where K is either the field R of reals, or the field C of complex numbers. A norm on E is a function || || : E → R+, assigning a nonnegative real number ||u|| to any vector u ∈ E, and satisfying the following conditions for all x, y ∈ E and X ∈ K:\n(N1) ||x|| ≥ 0, and ||x|| = 0 iff x = 0. (positivity)\n(N2) ||λx|| = |1| ||x||. (homogeneity (or scaling))\n(N3) ||x + y|| ≤ ||x|| + ||y||. (triangle inequality)\n[^324]: 3. Let E = R" (or E = C"). There are three standard norms. For every (x1,...,xn) ∈ E, we have the norm ||x||1, defined such that,\n||x||1 = |x1| +۰۰۰ + |xn|,\nwe have the Euclidean norm ||x||2, defined such that,\n||x||2 = (|x1|2 + ··· + |xn|2),\nand the sup-norm ||x||∞, defined such that,\n||x||∞ = max{|xi| | 1 ≤ i ≤ n}.\n[^335]: Definition 9.3. A matrix norm || || on the space of square n×n matrices in Mn(K), with K = R or K = C, is a norm on the vector space Mn(K), with the additional property called submultiplicativity that\n||AB|| ≤ ||A|| ||B||,\nfor all A, B ∈ Mn(K).\n[^338]: Proposition 9.6. For any matrix norm || || on Mn(C) and for any square n × n matrix А∈ Mn(C), we have ρ(A) ≤ ||A|| .\n[^341]: Definition 9.7. If || || is any norm on Cr, we define the function || || op on Mn(C) by\n||A||op = sup || Ax || = sup ||Ax || .\nxεση ||x|| x≠0 ||x||=1\n[^351]: Definition 9.10. For any subordinate matrix norm || ||, for any invertible matrix A, the number\ncond(A) = ||A|| ||A-1||\nis called the condition number of A relative to || ||.\n[^358]: The problem of solving an inconsistent linear system Ax b often arises in practice. This is a system where b does not belong to the column space of A, usually with more equations than variables. Thus, such a system has no solution. Yet we would still like to “solve” such a system, at least approximately.\n[^359]: It has been observed that solving in the least-squares sense may give too much weight to "outliers," that is, points clearly outside the best-fit plane. In this case, it is preferable to minimize (the l¹-norm)\nn\n☑ |axi + byi + d - zil.\ni=1

<!-- END -->