## Eigenvalores e Autovetores: Métodos Iterativos para a Determinação de Estruturas Espectrais

### Introdução
O cálculo de **eigenvalores** e **autovetores** é um problema central em álgebra linear numérica, com aplicações vastíssimas em diversas áreas da ciência e engenharia [^1]. A determinação destas quantidades permite a análise de sistemas lineares e a compreensão das propriedades intrínsecas de matrizes [^1]. Este capítulo explora métodos iterativos para a computação de eigenvalores e autovetores, focando em técnicas como os métodos de Jacobi, Givens-Householder, iteração QR, e Rayleigh-Ritz, com ênfase em matrizes simétricas [^1].

### Conceitos Fundamentais

#### Métodos Clássicos e sua Instabilidade
Em teoria, a determinação dos eigenvalores de uma matriz $A$ de dimensão $n \\times n$ poderia ser obtida através da computação da forma de Schur, $A = UTU^*$, onde $T$ é uma matriz triangular superior e $U$ é uma matriz unitária [^1]. Os eigenvalores seriam então os elementos diagonais de $T$. No entanto, este método requer a determinação das raízes de um polinômio, um processo numericamente instável [^1].

#### Paradigma Iterativo
A abordagem mais comum envolve a construção de uma sequência de matrizes $(A_k)$ tal que $A_k = P_kAP_k^*$ convirja, em algum sentido, para uma matriz cujos eigenvalores sejam facilmente determináveis [^1]. Frequentemente, $A_k$ torna-se triangular superior no limite, através da aplicação de matrizes ortogonais $P_k$ [^1].

#### O Algoritmo QR Básico
O **algoritmo QR** é um dos métodos mais eficientes para o cálculo de eigenvalores de matrizes não simétricas [^1]. Este algoritmo, devido a Rutishauser, Francis e Kublanovskaya, constrói uma sequência de matrizes $(A_k)$ onde $A_{k+1}$ é obtida a partir de $A_k$ através da decomposição QR: $A_k = Q_kR_k$, seguida da recombinação $A_{k+1} = R_kQ_k$ [^1]. É importante notar que $A_{k+1} = Q_k^*A_kQ_k$, garantindo que $A_k$ e $A_{k+1}$ possuem os mesmos eigenvalores, que são os eigenvalores de $A$ [^1].

##### Convergência do Algoritmo QR Básico
A convergência do algoritmo QR básico é garantida sob certas condições restritivas [^1]. Especificamente, se a matriz $A$ é diagonalizável e seus eigenvalores $\\lambda_1, \\lambda_2, ..., \\lambda_n$ possuem módulos distintos, ou seja, $|\\lambda_1| > |\\lambda_2| > ... > |\\lambda_n| > 0$, então a parte estritamente inferior da matriz $A_k$ converge para zero, e os elementos diagonais de $A_k$ convergem para os eigenvalores de $A$ [^1].
**Teorema 18.1**. Seja $A$ uma matriz $n \\times n$ (complexa) invertível e diagonalizável, com eigenvalores $\\lambda_1, \\lambda_2, ..., \\lambda_n$ tais que $|\\lambda_1| > |\\lambda_2| > ... > |\\lambda_n| > 0$. Se $A = PAP^{-1}$, onde $\\Lambda = diag(\\lambda_1, ..., \\lambda_n)$, e se $P^{-1}$ possui uma fatoração LU, então a parte estritamente triangular inferior de $A_k$ converge para zero, e a diagonal de $A_k$ converge para $\\Lambda$ [^4].

*Prova*. A estratégia é estudar o comportamento assintótico das matrizes $P_k = Q_1Q_2...Q_k$. Para isso, é necessário considerar as potências de $A$, onde $A^k = (Q_1Q_2...Q_k)(R_k...R_2R_1) = P_kR_k$ [^4]. Além disso, $A^k = PA^kP^{-1} = QRA^kLU = QR(A^kLA^{-k})A^kU$ [^5]. Aqui, $A^{-k}$ é a matriz diagonal com entradas $\\lambda_i^{-k}$. A razão para introduzir a matriz $A^kLA^{-k}$ é que seu comportamento assintótico é mais fácil de determinar [^5]. De fato,

$$(A^kLA^{-k})_{ij} = \\begin{cases} 0 & \\text{se } i < j \\\\ 1 & \\text{se } i = j \\\\ L_{ij} \\left(\\frac{\\lambda_i}{\\lambda_j}\\right)^k & \\text{se } i > j \\end{cases}$$

A hipótese de que $|\\lambda_i| > |\\lambda_{i+1}|$ implica que $\\lim_{k \\to \\infty} A^kLA^{-k} = I$ [^5].

Seja $A^{-k}LA = I + F_k$, com $\\lim_{k \\to \\infty} F_k = 0$ [^5]. Assim, $R(A^kLA^{-k}) = R(I + F_k) = R + RF_kR^{-1}R = (I + RF_kR^{-1})R$ [^5]. Pela Proposição 9.11(1), como $\\lim_{k \\to \\infty} F_k = 0$, as matrizes $I + RF_kR^{-1}$ são invertíveis para $k$ suficientemente grande [^5]. Consequentemente, para $k$ suficientemente grande, temos uma fatoração QR: $I + RF_kR^{-1} = Q_kR_k$, com $(R_k)_{ii} > 0$ para $i = 1,...,n$ [^5]. Como as matrizes $Q_k$ são unitárias, a sequência $(Q_k)$ é limitada. Portanto, existe uma subsequência convergente $(Q_e)$ que converge para alguma matriz $Q$, que também é unitária [^5]. Logo, $\\tilde{R_e} = (Q_e)^*(I + RF_kR^{-1})$ [^5].

Dessa forma, a subsequência $(\\tilde{R_e})$ também converge para alguma matriz $\\tilde{R}$, que também é triangular superior com entradas diagonais positivas [^6]. Passando ao limite (usando as subsequências), obtemos $R = (Q)^*$, ou seja, $I = QR$ [^6]. Pela unicidade da decomposição QR (quando as entradas diagonais de $R$ são positivas), obtemos $Q = R = I$ [^6].

Como o raciocínio acima se aplica a qualquer subsequência de $(Q_k)$ e $(R_k)$, pela unicidade dos limites, concluímos que as sequências "completas" $(Q_k)$ e $(R_k)$ convergem: $\\lim_{k \\to \\infty} Q_k = I, \\lim_{k \\to \\infty} R_k = I$ [^6].

Portanto, $A^k = QR(A^kLA^{-k})A^kU$, $R(A^kLA^{-k}) = (I + RF_kR^{-1})R$, $I + RF_kR^{-1} = Q_kR_k$, e $A^k = (QQ_k)(R_kRA^kU)$ [^6]. Observe que $QQ_k$ é uma matriz unitária e $R_kRA^kU$ é uma matriz triangular superior, como um produto de matrizes triangulares superiores [^6]. No entanto, algumas entradas em $A$ podem ser negativas, então não podemos afirmar que $R_kRA^kU$ tem entradas diagonais positivas. No entanto, temos outra decomposição QR de $A^k$, $A^k = (QQ_k)(R_kRA^kU) = P_kR_k$ [^6].

É fácil provar que existe uma matriz diagonal $D_k$ com $|(D_k)_{ii}| = 1$ para $i = 1, ..., n$, tal que $P_k = QQ_kD_k$ [^6]. A existência de $D_k$ é consequência do seguinte fato: se uma matriz invertível $B$ tem duas fatorações QR, $B = Q_1R_1 = Q_2R_2$, então existe uma matriz diagonal $D$ com entradas unitárias tal que $Q_2 = DQ_1$ [^6].

A expressão para $P_k$ em $P_k = QQ_kD_k$ é aquela que estávamos procurando [^6].

Como $A = PAP^{-1} = QRAR^{-1}Q^{-1}$ e $P_k = QQ_kD_k$, temos $A_{k+1} = D_k(Q_k)^*Q^*QRAR^{-1}Q^{-1}QQ_kD_k = D_k(Q_k)^*RAR^{-1}Q_kD_k$ [^6].

Definindo $D_k = (Q_k)^*RAR^{-1}Q_k$, então $A_{k+1} = D_kD_kD_k$, e como as matrizes $D_k$ são matrizes diagonais, temos $(A_{k+1})_{jj} = (D_kD_kD_k)_{ij} = (D_k)_{ii}(D_k)_{jj}(D_k)_{ij}$ [^7].

Portanto, $(A_{k+1})_{ii} = (D_k)_{i}$, para $i = 1,...,n$, uma vez que $|(D_k)_{ii}| = 1$ para $i = 1,...,n$ [^7]. Como $\\lim_{k \\to \\infty} D_k = RAR^{-1}$, concluímos que a parte estritamente triangular inferior de $A_{k+1}$ converge para zero, e a diagonal de $A_{k+1}$ converge para $\\Lambda$ [^7]. $\\blacksquare$

##### Limitações do Algoritmo QR Básico
O algoritmo QR básico apresenta dificuldades quando a matriz $A$ possui eigenvalores com o mesmo módulo [^1]. Nestes casos, o algoritmo pode não convergir para uma forma triangular superior. Além disso, se $A$ for uma matriz real com eigenvalores complexos, a parte inferior de $A_k$ não convergirá para zero [^4].

#### Hessenberg Matrices
Para melhorar a eficiência do algoritmo QR, é comum transformar a matriz original $A$ em uma matriz similar $H$ na forma de Hessenberg [^2]. Uma matriz de Hessenberg é "quase" triangular superior, admitindo elementos não nulos apenas na diagonal principal e na primeira subdiagonal [^2]. A transformação para a forma de Hessenberg pode ser realizada através de matrizes de Householder [^10].

**Definição 18.1**. Uma matriz $n \\times n$ (real ou complexa) $H$ é uma matriz de Hessenberg (superior) se ela é quase triangular, exceto que ela pode ter uma diagonal extra não nula abaixo da diagonal principal. Tecnicamente, $h_{jk} = 0$ para todo $(j, k)$ tal que $j - k > 1$ [^9].

**Teorema 18.2**. Toda matriz $n \\times n$ complexa ou real $A$ é similar a uma matriz de Hessenberg superior $H$, isto é, $A = UHU^*$ para alguma matriz unitária $U$ [^10]. Além disso, $U$ pode ser construída como um produto de matrizes de Householder [^10].

#### Algoritmo QR com Deslocamento (Shift)
Para acelerar a convergência do algoritmo QR, a técnica de deslocamento (shift) é utilizada [^2]. Nesta técnica, um valor $\\sigma_k$, estimado como próximo de um eigenvalor de $A$, é subtraído da matriz $A_k$ antes da decomposição QR: $A_k - \\sigma_kI = Q_kR_k$ [^2]. Em seguida, a matriz é recombinada e o deslocamento é adicionado: $A_{k+1} = R_kQ_k + \\sigma_kI$ [^2]. A escolha judiciosa de $\\sigma_k$ pode aumentar significativamente a velocidade de convergência [^2].

#### Algoritmo QR com Deslocamento Implícito
Uma otimização adicional consiste em calcular $A_{k+1} = Q_k^*A_kQ_k$ sem realizar explicitamente a decomposição QR de $A_k - \\sigma_kI$ [^2]. Este método, conhecido como **iteração QR com deslocamento implícito**, é particularmente útil quando $A_k$ está na forma de Hessenberg [^2].

#### Deflação
Se, em alguma etapa do algoritmo QR, um elemento subdiagonal $(H_k)_{p+1, p}$ de uma matriz de Hessenberg $H_k$ se torna zero (ou muito pequeno), a matriz pode ser decomposta em blocos, permitindo a aplicação recursiva do algoritmo QR aos blocos menores [^15]. Este processo é conhecido como **deflação** [^16].

#### Deslocamento de Wilkinson
Para matrizes simétricas, o deslocamento de Wilkinson é uma estratégia eficaz [^17]. Este deslocamento escolhe o eigenvalor da submatriz $2 \\times 2$ inferior de $A_k$ que está mais próximo do elemento diagonal inferior $a_{nn}$ [^17].

#### Deslocamento Duplo
Para lidar com pares de eigenvalores complexos conjugados em matrizes reais, o deslocamento duplo é empregado [^2]. Este método consiste em aplicar dois deslocamentos complexos conjugados, $\\sigma_k$ e $\\bar{\\sigma}_k$, de forma a manter as matrizes $A_k$ reais [^18].

#### Iteração de Arnoldi e Subespaços de Krylov
Quando a dimensão da matriz $A$ é muito grande, a iteração de Arnoldi pode ser utilizada para encontrar aproximações de alguns dos eigenvalores de $A$ [^2]. Este método projeta a matriz $A$ em um subespaço de Krylov, gerando uma matriz de Hessenberg menor cujos eigenvalores aproximam os eigenvalores de $A$ [^2].

### Conclusão
A computação de eigenvalores e autovetores é um campo vasto e complexo, com diversas abordagens e algoritmos adaptados a diferentes tipos de matrizes e requisitos de precisão [^1]. Os métodos iterativos, como o algoritmo QR e suas variantes, oferecem ferramentas poderosas para a análise espectral de matrizes, com aplicações que se estendem por diversas disciplinas científicas e de engenharia [^1].

### Referências
[^1]: Capítulo 18 do texto fornecido.
[^2]: Página 646 do texto fornecido.
[^3]: Página 647 do texto fornecido.
[^4]: Página 648 do texto fornecido.
[^5]: Página 649 do texto fornecido.
[^6]: Página 650 do texto fornecido.
[^7]: Página 651 do texto fornecido.
[^8]: Página 652 do texto fornecido.
[^9]: Página 653 do texto fornecido.
[^10]: Página 654 do texto fornecido.
[^11]: Página 655 do texto fornecido.
[^12]: Página 656 do texto fornecido.
[^13]: Página 657 do texto fornecido.
[^14]: Página 658 do texto fornecido.
[^15]: Página 659 do texto fornecido.
[^16]: Página 660 do texto fornecido.
[^17]: Página 661 do texto fornecido.
[^18]: Página 662 do texto fornecido.
[^19]: Página 663 do texto fornecido.
[^20]: Página 664 do texto fornecido.
[^21]: Página 665 do texto fornecido.
[^22]: Página 666 do texto fornecido.
[^23]: Página 667 do texto fornecido.
[^24]: Página 668 do texto fornecido.
[^25]: Página 669 do texto fornecido.
[^26]: Página 670 do texto fornecido.
[^27]: Página 671 do texto fornecido.
[^28]: Página 672 do texto fornecido.

<!-- END -->