## Matrizes de Hessenberg e o Algoritmo QR para Autovalores

### Introdução
Este capítulo explora o uso de **matrizes de Hessenberg** no contexto da computação de autovalores e autovetores, com foco em otimizar o algoritmo QR [^645]. Como vimos anteriormente [^645], o algoritmo QR é um dos métodos mais eficientes para calcular autovalores de matrizes não simétricas. No entanto, sua convergência pode ser lenta para matrizes gerais. A conversão de uma matriz original para uma forma de Hessenberg semelhante, que é quase triangular, acelera significativamente a convergência [^646].

### Conceitos Fundamentais

#### Matrizes de Hessenberg
Uma **matriz de Hessenberg** é uma matriz quadrada *quase triangular*, tendo todos os elementos abaixo da primeira subdiagonal iguais a zero [^646]. Formalmente, uma matriz $H$ é uma matriz de Hessenberg superior se $h_{jk} = 0$ para todo $(j, k)$ tal que $j - k > 1$ [^653].
Exemplo [^653]:
$$
H = \begin{bmatrix}
* & * & * & * & * \\
h_{21} & * & * & * & * \\
0 & h_{32} & * & * & * \\
0 & 0 & h_{43} & * & * \\
0 & 0 & 0 & h_{54} & *
\end{bmatrix}
$$
Uma propriedade importante das matrizes de Hessenberg é que qualquer matriz $A$ é *semelhante* a uma matriz de Hessenberg $H$, ou seja, $A = UHU^*$ para alguma matriz unitária $U$ [^654]. Além disso, $U$ pode ser construída como um produto de matrizes de Householder [^654].

#### Algoritmo QR e Matrizes de Hessenberg
Aplicar o algoritmo QR diretamente a uma matriz geral pode ser computacionalmente caro. No entanto, se a matriz for de Hessenberg, cada iteração do algoritmo QR torna-se muito mais eficiente [^646]. Além disso, as matrizes $H_k$ resultantes de cada iteração do algoritmo QR aplicado a uma matriz de Hessenberg $H$ *permanecem* na forma de Hessenberg superior [^659].

#### Matrizes de Hessenberg Irredutíveis
Uma matriz de Hessenberg $H$ de tamanho $n \times n$ é dita **irredutível** (ou não reduzida) se $h_{i+1,i} \neq 0$ para $i = 1, ..., n-1$ [^656]. Matrizes de Hessenberg irredutíveis têm a propriedade de que seus autovalores são todos distintos [^646].

#### Caso Especial: Matrizes Tridiagonais Simétricas/Hermitianas Positivas Definidas
Um caso particularmente interessante é o das matrizes tridiagonais simétricas (ou Hermitianas) positivas definidas [^646]. Para essas matrizes, o algoritmo QR converge para uma matriz diagonal, cujos elementos diagonais são os autovalores da matriz original [^646, 658].

**Teorema 18.4** [^658]: Seja $H$ uma matriz tridiagonal simétrica (ou Hermitiana) positiva definida. Se $H$ for irredutível, então o algoritmo QR converge para uma matriz diagonal consistindo dos autovalores de $H$.

#### Deslocamentos (Shifts)
Para acelerar ainda mais a convergência do algoritmo QR, a técnica de **deslocamentos (shifts)** é utilizada [^646]. Em cada iteração $k$, um valor $\sigma_k$ (o deslocamento) é escolhido, e o algoritmo QR é aplicado a $A_k - \sigma_k I$, onde $I$ é a matriz identidade [^646]. Após a decomposição QR, o deslocamento é adicionado de volta:
$$
A_k - \sigma_k I = Q_k R_k \\
A_{k+1} = R_k Q_k + \sigma_k I
$$
É fácil verificar que $A_{k+1} = Q_k^* A_k Q_k$, ou seja, $A_{k+1}$ é semelhante a $A_k$ [^646]. A escolha adequada de $\sigma_k$ pode acelerar a convergência consideravelmente [^646].

#### Deslocamentos Implícitos
Uma otimização adicional é realizar as iterações do algoritmo QR com deslocamentos sem calcular explicitamente a fatoração QR de $A_k - \sigma_k I$. Este método é conhecido como **iteração QR com deslocamentos implícitos** [^646].

### Conclusão

A utilização de matrizes de Hessenberg no algoritmo QR é uma técnica fundamental para a computação eficiente de autovalores [^659]. A redução inicial da matriz para a forma de Hessenberg, combinada com o uso de deslocamentos (explícitos ou implícitos), acelera significativamente a convergência do algoritmo [^646]. Casos especiais, como matrizes tridiagonais simétricas/Hermitianas positivas definidas, apresentam convergência ainda mais rápida [^646, 658].

### Referências
[^645]: Capítulo 18: Computing Eigenvalues and Eigenvectors.
[^646]: Capítulo 18: Computing Eigenvalues and Eigenvectors, página 646.
[^653]: Capítulo 18: Computing Eigenvalues and Eigenvectors, página 653.
[^654]: Capítulo 18: Computing Eigenvalues and Eigenvectors, página 654.
[^656]: Capítulo 18: Computing Eigenvalues and Eigenvectors, página 656.
[^658]: Capítulo 18: Computing Eigenvalues and Eigenvectors, página 658.
[^659]: Capítulo 18: Computing Eigenvalues and Eigenvectors, página 659.
<!-- END -->