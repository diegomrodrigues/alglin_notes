## Propriedades da Pseudo-Inversa

### Introdução
Este capítulo explora as propriedades da pseudo-inversa de uma matriz, um conceito fundamental em diversas aplicações, incluindo a solução de problemas de mínimos quadrados [^753]. Como vimos anteriormente, a pseudo-inversa oferece uma forma de generalizar a inversa de uma matriz para casos onde a matriz não é quadrada ou não possui posto completo [^753]. Aqui, vamos nos aprofundar nas características que tornam a pseudo-inversa uma ferramenta tão poderosa.

### Conceitos Fundamentais

A pseudo-inversa, denotada por $A^+$, de uma matriz $A$ (real ou complexa) de dimensão $m \times n$ é a matriz $n \times m$ que satisfaz as quatro condições de Penrose [^765]:

1.  $AA^+A = A$
2.  $A^+AA^+ = A^+$
3.  $(AA^+)^* = AA^+$
4.  $(A^+A)^* = A^+A$

onde $*$ denota o operador adjunto (transposta conjugada). A unicidade de $A^+$ que satisfaz estas condições é garantida.

**Proposição 23.3.** Quando $A$ tem posto completo, a pseudo-inversa $A^+$ pode ser expressa como [^760]:

*   $A^+ = (A^TA)^{-1}A^T$ quando $m \geq n$
*   $A^+ = A^T(AA^T)^{-1}$ quando $n \geq m$

No primeiro caso ($m \geq n$), observe que $A^+A = I$, então $A^+$ é uma *inversa à esquerda* de $A$. No segundo caso ($n \geq m$), temos $AA^+ = I$, então $A^+$ é uma *inversa à direita* de $A$ [^760].

**Demonstração:**
Se $m > n$ e $A$ tem posto completo $n$, então podemos decompor $A$ como [^760]:
$$ A = V \begin{pmatrix} \Lambda \\\\ 0_{m-n,n} \end{pmatrix} U^T $$
onde $\Lambda$ é uma matriz diagonal invertível $n \times n$ (com entradas positivas), então
$$ A^+ = U \begin{pmatrix} \Lambda^{-1} & 0_{n,m-n} \end{pmatrix} V^T $$
Calculamos
$$ A^TA = U \begin{pmatrix} \Lambda & 0_{n,m-n} \end{pmatrix} V^TV \begin{pmatrix} \Lambda \\\\ 0_{m-n,n} \end{pmatrix} U^T = U\Lambda^2U^T $$
que implica
$$ (A^TA)^{-1}A^T = U\Lambda^{-2}U^TU \begin{pmatrix} \Lambda & 0_{n,m-n} \end{pmatrix} V^T = U \begin{pmatrix} \Lambda^{-1} & 0_{n,m-n} \end{pmatrix} V^T = A^+ $$
Portanto, se $m > n$ e $A$ tem posto completo $n$, então $A^+ = (A^TA)^{-1}A^T$. $\blacksquare$

Um argumento similar pode ser aplicado para o caso $n \geq m$ [^760].

**Exemplo:**
Se $A = \begin{pmatrix} 1 & 2 \\\\ 2 & 3 \\\\ 0 & 1 \end{pmatrix}$, então $A$ tem posto 2 e, como $m > n$, $A^+ = (A^TA)^{-1}A^T$ [^761].
$$ A^TA = \begin{pmatrix} 5 & 8 \\\\ 8 & 14 \end{pmatrix} \implies (A^TA)^{-1} = \frac{1}{6} \begin{pmatrix} 14 & -8 \\\\ -8 & 5 \end{pmatrix} $$
$$ A^+ = \frac{1}{6} \begin{pmatrix} 14 & -8 \\\\ -8 & 5 \end{pmatrix} \begin{pmatrix} 1 & 2 & 0 \\\\ 2 & 3 & 1 \end{pmatrix} = \frac{1}{6} \begin{pmatrix} -2 & 4 & -8 \\\\ -3 & -1 & 5 \end{pmatrix} $$

**Proposição 23.4.** A matriz $AA^+$ é a projeção ortogonal no range de $A$, e $A^+A$ é a projeção ortogonal em $Ker(A)^\perp = Im(A^T)$, o range de $A^T$ [^761].

**Demonstração:**
Obviamente, $range(AA^+) \subseteq range(A)$, e para qualquer $y = Ax \in range(A)$, como $AA^+A = A$, temos [^761]
$$ AA^+y = AA^+Ax = Ax = y $$
assim, a imagem de $AA^+$ é de fato o range de $A$. É também claro que $Ker(A) \subseteq Ker(A^+A)$, e como $AA^+A = A$, também temos $Ker(A^+A) \subseteq Ker(A)$, e então
$$ Ker(A^+A) = Ker(A) $$
Como $A^+A$ é simétrica, $range(A^+A) = range((A^+A)^T) = Ker(A^+A)^\perp = Ker(A)^\perp$, como afirmado [^762]. $\blacksquare$

**Teorema 23.1.** Todo sistema linear $Ax = b$, onde $A$ é uma matriz $m \times n$, tem uma única solução de mínimos quadrados $x^+$ de norma mínima [^755].

**Demonstração:**
A geometria oferece uma prova elegante da existência e unicidade de $x^+$. Podemos interpretar $b$ como um ponto no espaço Euclidiano (afim) $\mathbb{R}^m$, e o subespaço imagem de $A$ (também chamado de espaço coluna de $A$) como um subespaço $U$ de $\mathbb{R}^m$ (passando pela origem) [^755]. Então é claro que

$$ \inf_{x \in \mathbb{R}^n} ||Ax - b||_2 = \inf_{y \in U} ||y - b||_2 $$

com $U = Im A$, e afirmamos que $x$ minimiza $||Ax - b||_2$ se e somente se $Ax = p$, onde $p$ é a projeção ortogonal de $b$ no subespaço $U$ [^755].

Assim, o problema foi reduzido a provar que existe um único $x^+$ de norma mínima tal que $Ax^+ = p$, com $p = p_U(b) \in U$, a projeção ortogonal de $b$ em $U$ [^756]. Usamos o fato de que
$$ \mathbb{R}^n = Ker A \oplus (Ker A)^\perp $$
Consequentemente, todo $x \in \mathbb{R}^n$ pode ser escrito unicamente como $x = u + v$, onde $u \in Ker A$ e $v \in (Ker A)^\perp$, e como $u$ e $v$ são ortogonais,
$$ ||x||^2 = ||u||^2 + ||v||^2 $$
Além disso, como $u \in Ker A$, temos $Au = 0$, e assim $Ax = p$ se e somente se $Av = p$, o que mostra que as soluções de $Ax = p$ para as quais $x$ tem norma mínima devem pertencer a $(Ker A)^\perp$ [^756]. No entanto, a restrição de $A$ a $(Ker A)^\perp$ é injetiva. Isso ocorre porque se $Av_1 = Av_2$, onde $v_1, v_2 \in (Ker A)^\perp$, então $A(v_2 - v_1) = 0$, o que implica $v_2 - v_1 \in Ker A$, e como $v_1, v_2 \in (Ker A)^\perp$, também temos $v_2 - v_1 \in (Ker A)^\perp$, e consequentemente, $v_2 - v_1 = 0$ [^756]. Isso mostra que existe um único $x^+$ de norma mínima tal que $Ax^+ = p$, e que $x^+$ deve pertencer a $(Ker A)^\perp$. Pelo nosso raciocínio anterior, $x^+$ é o vetor único de norma mínima que minimiza $||Ax - b||^2$ [^756]. $\blacksquare$

**Definição 23.1.** Dada qualquer matriz não nula $m \times n$ $A$ de posto $r$, se $A = VDU^T$ é uma SVD de $A$ tal que [^757]

$$ D = \begin{pmatrix} \Lambda & 0_{r,n-r} \\\\ 0_{m-r,r} & 0_{m-r,n-r} \end{pmatrix} $$

com $\Lambda = diag(\lambda_1, ..., \lambda_r)$ uma matriz diagonal $r \times r$ consistindo dos valores singulares não nulos de $A$, então, se deixarmos $D^+$ ser a matriz $n \times m$

$$ D^+ = \begin{pmatrix} \Lambda^{-1} & 0_{r,m-r} \\\\ 0_{n-r,r} & 0_{n-r,m-r} \end{pmatrix} $$

com $\Lambda^{-1} = diag(1/\lambda_1, ..., 1/\lambda_r)$, a pseudo-inversa de $A$ é definida por [^757]

$$ A^+ = UD^+V^T $$

Se $A = 0_{m,n}$ é a matriz zero, definimos $A^+ = 0_{n,m}$ [^757]. Observe que $D^+$ é obtido de $D$ invertendo as entradas diagonais não nulas de $D$, deixando todos os zeros no lugar e, em seguida, transpondo a matriz [^757].

**Teorema 23.2.** A solução de mínimos quadrados de menor norma do sistema linear $Ax = b$, onde $A$ é uma matriz $m \times n$, é dada por [^758]
$$ x^+ = A^+b = UD^+V^Tb $$

**Demonstração:**
Primeiro, assuma que $A$ é uma matriz diagonal (retangular) $D$, como acima [^758]. Então, como $x$ minimiza $||Dx - b||_2$ se e somente se $Dx$ é a projeção de $b$ no subespaço imagem $F$ de $D$, é bastante óbvio que $x^+ = D^+b$. Caso contrário, podemos escrever
$$ A = VDU^T $$
onde $U$ e $V$ são ortogonais [^758]. No entanto, como $V$ é uma isometria,
$$ ||Ax - b||_2 = ||VDU^Tx - b||_2 = ||DU^Tx - V^Tb||_2 $$
Deixando $y = U^Tx$, temos $||x||_2 = ||y||_2$, já que $U$ é uma isometria, e como $U$ é sobrejetiva, $||Ax - b||_2$ é minimizado se e somente se $||Dy - V^Tb||_2$ é minimizado, e mostramos que a menor solução é [^758]
$$ y^+ = D^+V^Tb $$
Já que $y = U^Tx$, com $||x||_2 = ||y||_2$, obtemos
$$ x^+ = UD^+V^Tb = A^+b $$
Assim, a pseudo-inversa fornece a solução ideal para o problema de mínimos quadrados. $\blacksquare$

### Conclusão
Neste capítulo, exploramos em profundidade as propriedades da pseudo-inversa, demonstrando sua unicidade e sua importância na solução de problemas de mínimos quadrados [^753, 755, 758]. Vimos como a pseudo-inversa pode ser calculada utilizando a decomposição em valores singulares (SVD) [^757] e como ela se relaciona com as projeções ortogonais nos espaços de imagem e núcleo de uma matriz [^761]. Essas propriedades tornam a pseudo-inversa uma ferramenta indispensável na análise de sistemas lineares e em diversas aplicações em ciência e engenharia.

### Referências
[^753]: Chapter 23. Applications of SVD and Pseudo-Inverses.
[^755]: Theorem 23.1. Every linear system Ax = b, where A is an m × n matrix, has a unique least squares solution x+ of smallest norm.
[^756]: Thus the problem has been reduced to proving that there is a unique x+ of minimum norm such that Ax+ = p, with p = pu(b) ∈ U, the orthogonal projection of b onto U.
[^757]: Definition 23.1. Given any nonzero m × n matrix A of rank r, if A = VDU™ is an SVD of A such that [...], the pseudo-inverse of A is defined by A+ = UD+VT.
[^758]: Theorem 23.2. The least squares solution of smallest norm of the linear system Ax = b, where A is an m × n matrix, is given by x+ = A+b = UD+V®b.
[^760]: Proposition 23.3. When A has full rank, the pseudo-inverse A+ can be expressed as A+ = (ATA)-1AT when m ≥ n, and as A+ = AT(AAT)-1 when n ≥ m.
[^761]: Proposition 23.4. The matrix AA+ is the orthogonal projection onto the range of A and A+ A is the orthogonal projection onto Ker(A)+ = Im(AT), the range of AT.
[^762]: So the image of AA+ is indeed the range of A.
[^765]: Proposition 23.8. Given any m × n matrix A (real or complex), the pseudo-inverse A+ of A is the unique n × m matrix satisfying the following properties: AA+ A = A, A+AA+ = A+, (AA+)* = AA+, (A+A)* = A+A.

<!-- END -->