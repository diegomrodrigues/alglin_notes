## Melhor Aproximação Afim

### Introdução
Este capítulo explora a **melhor aproximação afim** de um conjunto de dados, um problema intimamente ligado à Análise de Componentes Principais (PCA) [^778]. Em continuidade com a discussão sobre aplicações da Decomposição em Valores Singulares (SVD) e pseudo-inversas, focaremos em como encontrar um subespaço afim que melhor se ajusta a um conjunto de pontos no espaço ℝᵈ, utilizando o método dos mínimos quadrados [^778].

### Conceitos Fundamentais

O problema da melhor aproximação afim consiste em aproximar um conjunto de *n* pontos *X₁, ..., Xₙ* em ℝᵈ por um subespaço afim *A* de dimensão *p* em ℝᵈ, onde *1 ≤ p ≤ d - 1* [^778].

**Definição:** Dado um conjunto de *n* pontos *X₁, ..., Xₙ* em ℝᵈ, o objetivo é encontrar um subespaço afim *A* de dimensão *p* que minimize a soma dos quadrados das distâncias de cada ponto *Xᵢ* a *A*.

Consideremos inicialmente o caso em que *p = d - 1*. Neste caso, *A = A₁* é um hiperplano afim em ℝᵈ, definido por uma equação da forma:
$$ a₁x₁ + ... + a_dx_d + c = 0 $$
Onde *a₁, ..., a_d* são os coeficientes e *c* é uma constante [^778]. A condição de melhor aproximação implica que *a₁, ..., a_d, c* devem resolver o sistema linear homogêneo no sentido dos mínimos quadrados:
$$
\begin{bmatrix}
x_{11} & ... & x_{1d} & 1 \\
\vdots & \vdots & \vdots & \vdots \\
x_{n1} & ... & x_{nd} & 1
\end{bmatrix}
\begin{bmatrix}
a_1 \\
\vdots \\
a_d \\
c
\end{bmatrix} =
\begin{bmatrix}
0 \\
\vdots \\
0
\end{bmatrix}
$$
Sujeito à restrição de que o vetor *a = (a₁, ..., a_d)* seja um vetor unitário, ou seja, *aᵀa = 1* [^778].

Para resolver este sistema no sentido dos mínimos quadrados, formamos a matriz simétrica envolvida nas equações normais. Observamos que a última linha (e coluna) dessa matriz é dada por *nμ₁, ..., nμ_d, n*, onde *nμ_j = Σᵢ xᵢⱼ* é *n* vezes a média da coluna *Cⱼ* da matriz *X* [^778].

**Lema:** Se *(a₁, ..., a_d, c)* é uma solução de mínimos quadrados, então:
$$ nμ₁a₁ + ... + nμ_da_d + nc = 0 $$
o que implica:
$$ a₁μ₁ + ... + a_dμ_d + c = 0 $$
Isto significa que o hiperplano *A₁* deve passar pelo centroide *μ* dos pontos de dados *X₁, ..., Xₙ* [^778]. Podemos reescrever o sistema original em relação aos dados centrados *Xᵢ - μ*.

**Teorema:** A melhor aproximação afim *A₁* é dada por *A₁ = μ + U_{d-1}*, onde *U_{d-1}* é o hiperplano linear definido pelo último vetor singular de *X - μ*.

### Generalização para Subespaços Afins de Dimensão Arbitrária

O conceito de melhor aproximação afim pode ser generalizado para subespaços afins *Aₖ* de dimensão *(d - k)*, onde *1 ≤ k ≤ d - 1* [^779]. Um tal subespaço *Aₖ* é definido pela interseção de *k* hiperplanos independentes *Hᵢ*, cada um dado por uma equação da forma:
$$ a_{i1}x_1 + ... + a_{id}x_d + c_i = 0 $$
Onde *1 ≤ i ≤ k*. A independência dos hiperplanos significa que os vetores normais *aᵢ = (a_{i1}, ..., a_{id})* são linearmente independentes. Podemos assumir que *a₁, ..., aₖ* formam um sistema ortonormal.

Encontrar o melhor subespaço afim *Aₖ* equivale a resolver o sistema linear homogêneo no sentido dos mínimos quadrados:
$$
\begin{bmatrix}
X - μ & 0 & ... & 0 \\
0 & X - μ & ... & 0 \\
\vdots & \vdots & \vdots & \vdots \\
0 & 0 & ... & X - μ
\end{bmatrix}
\begin{bmatrix}
a_1 \\
a_2 \\
\vdots \\
a_k
\end{bmatrix} =
\begin{bmatrix}
0 \\
0 \\
\vdots \\
0
\end{bmatrix}
$$
sujeito às condições *aᵢᵀaⱼ = δᵢⱼ*, onde *δᵢⱼ* é o delta de Kronecker [^780].

**Teorema:** A melhor aproximação afim *Aₖ* é dada por *Aₖ = μ + U_{d-k}*, onde *U_{d-k}* é o subespaço linear gerado pelos primeiros *(d - k)* vetores singulares de *X - μ* [^780].

### Conclusão

A melhor aproximação afim fornece uma maneira de aproximar um conjunto de dados por um subespaço de dimensão inferior, minimizando a soma dos quadrados das distâncias. Este método está intimamente relacionado com a PCA, onde os vetores singulares da matriz de dados centrada definem as direções principais ao longo das quais os dados são projetados [^780]. Em resumo, a SVD fornece uma ferramenta poderosa para encontrar a melhor aproximação afim de um conjunto de dados [^780].

### Referências
[^778]: Applications of SVD and Pseudo-Inverses, Chapter 23, page 778.
[^779]: Applications of SVD and Pseudo-Inverses, Chapter 23, page 779.
[^780]: Applications of SVD and Pseudo-Inverses, Chapter 23, page 780.
<!-- END -->