## 23.5 Invariância Rotacional e a Não-Unicidade da SVD na Aproximação Afim

### Introdução
O presente capítulo explora a questão da unicidade da Singular Value Decomposition (SVD) e suas implicações na análise de dados, particularmente no contexto da Principal Component Analysis (PCA) e da Best Affine Approximation. Como veremos, a não-unicidade da SVD pode levar a resultados problemáticos, especialmente em conjuntos de dados com simetrias rotacionais [^778].

### Conceitos Fundamentais
Conforme mencionado anteriormente [^778], a SVD de uma matriz $X$ não é necessariamente única. Isso significa que, embora a matriz $X$ possa ser decomposta em $VDU^T$, onde $V$ e $U$ são matrizes ortogonais e $D$ é uma matriz diagonal com os valores singulares, as matrizes $V$ e $U$, e consequentemente os *principal directions* $u_1, ..., u_d$, não são unicamente definidos.

Essa não-unicidade surge, em particular, quando o conjunto de dados exibe certas **simetrias rotacionais**.  Em termos práticos, isso significa que se rotacionarmos o conjunto de dados, suas propriedades estatísticas (como a matriz de covariância) permanecem inalteradas. Nesses casos, a PCA, que se baseia na SVD da matriz de covariância, pode falhar em identificar *principal directions*  estáveis e significativos [^778].

Para entender melhor o impacto dessa não-unicidade, consideremos o problema da Best Affine Approximation [^778]. O objetivo é aproximar um conjunto de dados $X_1, ..., X_n \\in \\mathbb{R}^d$ por um subespaço afim $A$ de dimensão $p$ (com $1 \\le p \\le d-1$). No caso de um hiperplano afim ($p = d-1$), o problema se resume a encontrar um vetor normal $a = (a_1, ..., a_d)$ e um escalar $c$ tal que a equação $a_1x_1 + ... + a_dx_d + c = 0$ defina o hiperplano que melhor se ajusta aos dados [^778].

A solução para esse problema envolve encontrar o vetor $a$ que minimiza a soma dos quadrados das distâncias dos pontos $X_i$ ao hiperplano. Isso leva a um sistema linear homogêneo [^778]:

$$\
\begin{bmatrix}
x_{11} & \cdots & x_{1d} & 1 \\
\vdots & \ddots & \vdots & \vdots \\
x_{n1} & \cdots & x_{nd} & 1
\end{bmatrix}
\begin{bmatrix}
a_1 \\
\vdots \\
a_d \\
c
\end{bmatrix} =
\begin{bmatrix}
0 \\
\vdots \\
0
\end{bmatrix}
$$

sujeito à restrição $a^Ta = 1$.  A solução de mínimos quadrados para esse sistema implica que o hiperplano deve passar pelo centroide $\\mu$ dos dados [^778].  Assim, o problema se reduz a encontrar o vetor $a$ que minimiza $a^T(X - \\mu)^T(X - \\mu)a$ [^779].

A SVD de $X - \\mu$ (denotada por $VDU^T$) é utilizada para resolver este problema. A solução ótima para $a$ é o último vetor coluna de $U$, que corresponde ao menor valor singular de $(X - \\mu)^T(X - \\mu)$ [^779]. No entanto, se a SVD não for única devido a simetrias rotacionais no conjunto de dados, o vetor $a$ (e, portanto, o hiperplano $A_1$) não será bem definido.

**Exemplo:** Imagine um conjunto de dados uniformemente distribuído em um círculo. A PCA (e, por extensão, a Best Affine Approximation) terá dificuldade em identificar eixos principais estáveis, pois qualquer rotação do círculo mantém as mesmas propriedades estatísticas.

**Lemma 1:** Se um conjunto de dados possui simetria rotacional perfeita em torno de um ponto, então sua matriz de covariância será proporcional à matriz identidade.

*Proof:* Seja $X$ um conjunto de dados com simetria rotacional perfeita em torno da origem. Isso significa que para qualquer rotação $R$, o conjunto de dados $RX$ tem as mesmas propriedades estatísticas que $X$. Em particular, a matriz de covariância de $X$ é dada por $\\Sigma = \\frac{1}{n-1}X^TX$. A matriz de covariância de $RX$ é $\\frac{1}{n-1}(RX)^T(RX) = \\frac{1}{n-1}X^TR^TRX = \\frac{1}{n-1}X^TX = \\Sigma$.  Como isso deve ser verdade para qualquer rotação $R$, a única matriz que satisfaz essa condição é uma matriz proporcional à identidade. $\\blacksquare$

**Corolário 1:** Se a matriz de covariância é proporcional à matriz identidade, então todos os valores singulares são iguais, e qualquer base ortonormal pode ser escolhida como os *principal directions*.

### Conclusão
Em resumo, a não-unicidade da SVD, exacerbada por simetrias rotacionais nos dados, pode levar a instabilidades na PCA e, consequentemente, na Best Affine Approximation. Nesses casos, os *principal directions* e o hiperplano de melhor ajuste não são bem definidos, e a análise dos dados se torna problemática. É crucial estar ciente dessas limitações ao aplicar PCA e Best Affine Approximation, especialmente em conjuntos de dados com simetrias inerentes.  Métodos alternativos, ou pré-processamento dos dados para remover as simetrias, podem ser necessários para obter resultados mais robustos e interpretáveis.

### Referências
[^778]: Chapter 23, Applications of SVD and Pseudo-Inverses, página 778.
[^779]: Chapter 23, Applications of SVD and Pseudo-Inverses, página 779.
<!-- END -->