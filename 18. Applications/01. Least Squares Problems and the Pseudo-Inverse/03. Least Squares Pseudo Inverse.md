## A Solução de Mínima Norma para Problemas de Mínimos Quadrados via Pseudo-Inversa

### Introdução
Este capítulo explora a solução de **mínima norma** para problemas de mínimos quadrados usando a **pseudo-inversa**, um conceito derivado da **decomposição em valores singulares (SVD)** de uma matriz [^753]. A relevância deste tópico reside na sua capacidade de resolver sistemas lineares *superdeterminados* e *inconsistentes*, que surgem frequentemente em problemas de estimação e otimização [^754]. A pseudo-inversa permite encontrar uma solução que minimize o erro quadrático médio, ao mesmo tempo que possui a menor norma euclidiana possível [^755].

### Conceitos Fundamentais

A **pseudo-inversa** de uma matriz $A$, denotada por $A^+$, generaliza a noção de inversa para matrizes não quadradas ou singulares [^757]. Dada uma matriz $A \in \mathbb{R}^{m \times n}$ de rank $r$, sua SVD é dada por $A = VDU^T$, onde $V$ e $U$ são matrizes ortogonais $m \times m$ e $n \times n$, respectivamente, e $D$ é uma matriz $m \times n$ com elementos diagonais não negativos, chamados valores singulares [^757]. A matriz $D$ tem a forma:

$$
D = \begin{pmatrix}
\Lambda & O_{r,n-r} \\
O_{m-r,r} & O_{m-r,n-r}
\end{pmatrix}
$$

onde $\Lambda = \text{diag}(\lambda_1, \dots, \lambda_r)$ é uma matriz diagonal $r \times r$ contendo os valores singulares não nulos de $A$ [^757].

A **pseudo-inversa** $A^+$ é então definida como:

$$
A^+ = UD^+V^T
$$

onde $D^+$ é obtida invertendo os elementos diagonais não nulos de $D$ e transpondo a matriz [^757]. Portanto,

$$
D^+ = \begin{pmatrix}
\Lambda^{-1} & O_{r,m-r} \\
O_{n-r,r} & O_{n-r,m-r}
\end{pmatrix}
$$

com $\Lambda^{-1} = \text{diag}(1/\lambda_1, \dots, 1/\lambda_r)$ [^757].

O **Teorema 23.2** [^758] estabelece que a solução de mínimos quadrados de menor norma para o sistema linear $Ax = b$ é dada por:

$$
x^+ = A^+b = UD^+V^Tb
$$

*Prova:*
Inicialmente, considere que $A$ seja uma matriz diagonal retangular $D$. Minimizar $||Dx - b||_2$ equivale a projetar $b$ no espaço imagem de $D$. Portanto, $x^+ = D^+b$ [^758].
Agora, para uma matriz geral $A = VDU^T$, onde $U$ e $V$ são ortogonais, temos:

$$
||Ax - b||_2 = ||VDU^Tx - b||_2 = ||DU^Tx - V^Tb||_2
$$

Definindo $y = U^Tx$, temos que $||x||_2 = ||y||_2$ já que $U$ é uma isometria [^758]. Assim, minimizar $||Ax - b||_2$ é equivalente a minimizar $||Dy - V^Tb||_2$. A solução de menor norma é então $y^+ = D^+V^Tb$. Como $y = U^Tx$, obtemos $x^+ = UD^+V^Tb = A^+b$ [^758]. $\blacksquare$

**Lema:** A pseudo-inversa $A^+$ é única e depende apenas de $A$ [^758].

*Prova:*
Pelo **Teorema 23.2** e **Teorema 23.1**, $A^+b$ é definido unicamente para cada $b$. Portanto, $A^+$ depende apenas de $A$ [^758]. $\blacksquare$

### Conclusão

A **pseudo-inversa** oferece uma ferramenta poderosa para resolver problemas de mínimos quadrados, especialmente quando o sistema é *superdeterminado* ou a matriz não é invertível [^757]. A solução de mínima norma $x^+ = A^+b$ garante que, entre todas as soluções que minimizam o erro quadrático médio, escolhemos aquela com a menor norma euclidiana [^758]. Este conceito é fundamental em diversas aplicações, incluindo *regressão linear*, *filtragem*, e *reconstrução de sinais* [^753]. Além disso, a SVD fornece uma maneira estável e eficiente de calcular a pseudo-inversa, tornando-a uma ferramenta indispensável na análise de dados e otimização [^757].

### Referências
[^753]: Legendre, 1805, Nouvelles Méthodes pour la détermination des Orbites des Comètes
[^754]: Example 23.1
[^755]: Theorem 23.1
[^757]: Definition 23.1
[^758]: Theorem 23.2
<!-- END -->