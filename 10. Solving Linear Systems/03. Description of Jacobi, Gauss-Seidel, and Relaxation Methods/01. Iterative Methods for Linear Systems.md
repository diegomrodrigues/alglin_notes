## Métodos Iterativos para a Solução de Sistemas Lineares: Uma Análise Detalhada

### Introdução
Este capítulo explora os métodos iterativos para a solução de sistemas lineares. Em contraste com os métodos diretos, que fornecem soluções exatas em um número finito de passos (assumindo precisão infinita) [^1], os métodos iterativos aproximam a solução através de uma sequência de iterações [^1]. O foco principal será na descrição detalhada dos métodos de Jacobi, Gauss-Seidel e Relaxamento, e na análise de suas propriedades de convergência.

### Conceitos Fundamentais
Os métodos iterativos para resolver um sistema linear $Ax = b$ podem ser expressos como $A = M - N$, onde $M$ é invertível e "fácil de inverter" [^6]. Esta decomposição leva ao esquema iterativo $u = M^{-1}Nu + M^{-1}b$, onde $M$ e $N$ são escolhidos para garantir a convergência e eficiência computacional [^6].

**Decomposição da Matriz A:** A escolha de $M$ e $N$ é fundamental e define o método iterativo específico [^6]. Os métodos de Jacobi e Gauss-Seidel utilizam $M$ e $N$ como submatrizes disjuntas de $A$, enquanto o método de relaxamento permite alguma sobreposição [^6]. Para descrever as diferentes escolhas de $M$ e $N$, é conveniente escrever $A$ em termos de três submatrizes $D$, $E$ e $F$, como $A = D - E - F$ [^7], onde:
*   $D$ contém apenas as entradas diagonais de $A$ [^7]
*   $E$ contém os negativos das entradas não nulas de $A$ abaixo da diagonal [^7]
*   $F$ contém os negativos das entradas não nulas de $A$ acima da diagonal [^7]

**Método de Jacobi:** No método de Jacobi, assume-se que todas as entradas diagonais de $A$ são não nulas [^8]. Escolhe-se $M = D$ e $N = E + F$ [^8]. Assim, o esquema iterativo é dado por $u_{k+1} = D^{-1}(E + F)u_k + D^{-1}b$ [^8]. A matriz de Jacobi é definida como $J = I - D^{-1}A = D^{-1}(E + F)$ [^8].

**Método de Gauss-Seidel:** O método de Gauss-Seidel procura "acelerar" o processo iterativo, utilizando os valores mais recentes das componentes da solução $u$ assim que estão disponíveis [^10]. Isso leva a uma escolha de $M = D - E$ e $N = F$ [^10]. O esquema iterativo resultante é $u_{k+1} = (D - E)^{-1}Fu_k + (D - E)^{-1}b$ [^10]. A matriz de Gauss-Seidel é definida como $L_1 = (D - E)^{-1}F$ [^10].

**Método de Relaxamento (SOR - Successive Overrelaxation):** O método de relaxamento introduz um parâmetro $\\omega$ para controlar a correção aplicada em cada iteração [^12]. Define-se $M = \\frac{D}{\\omega} - E$ e $N = \\frac{1-\\omega}{\\omega}D + F$ [^12]. O esquema iterativo é dado por $u_{k+1} = (\\frac{D}{\\omega} - E)^{-1}(\\frac{1-\\omega}{\\omega}D + F)u_k + (\\frac{D}{\\omega} - E)^{-1}b$ [^12]. A matriz de relaxamento é definida como $L_{\\omega} = (D - \\omega E)^{-1}((1 - \\omega)D + \\omega F)$ [^12]. Para a convergência do método de relaxamento, $\\omega$ deve estar no intervalo $(0, 2)$ [^12]. O caso $\\omega = 1$ corresponde ao método de Gauss-Seidel [^12].

**Convergência dos Métodos Iterativos:** Um critério fundamental para a convergência de qualquer método iterativo baseado em uma matriz $B$ é que o raio espectral de $B$ seja menor que 1, ou seja, $\\rho(B) < 1$ [^4]. Equivalentemente, existe uma norma matricial subordinada tal que $||B|| < 1$ [^4].

**Teorema 10.3:** Dado um sistema $u = Bu + c$, onde $I - B$ é invertível, as seguintes afirmações são equivalentes [^4]:
1.  O método iterativo é convergente [^4]
2.  $\\rho(B) < 1$ [^4]
3.  $||B|| < 1$ para alguma norma matricial subordinada [^4]

**Taxa de Convergência:** A Proposição 10.4 fornece uma ferramenta para comparar a taxa de convergência de diferentes métodos iterativos [^5]. Assintoticamente, o vetor erro $e_k = B^ke_0$ se comporta como $(\\rho(B))^k$ [^5]. Se $\\rho(B_1) < \\rho(B_2)$, então o método iterativo com a matriz $B_1$ converge mais rapidamente [^5].

**Teorema de Ostrowski-Reich:** Se $A = D - E - F$ é hermitiana definida positiva, então o método de relaxamento converge para $0 < \\omega < 2$ [^16].

**Métodos para Matrizes Tridiagonais:** No caso de matrizes tridiagonais, é possível obter resultados mais precisos sobre o raio espectral de $J$ e $L_{\\omega}$ [^17]. A Proposição 10.8 estabelece que para uma matriz tridiagonal, $\\rho(L_1) = (\\rho(J))^2$ [^17]. Consequentemente, os métodos de Jacobi e Gauss-Seidel convergem ou divergem simultaneamente, e quando convergem, o método de Gauss-Seidel converge mais rapidamente [^17].

### Conclusão
Este capítulo detalhou os métodos iterativos de Jacobi, Gauss-Seidel e Relaxamento para a solução de sistemas lineares. A decomposição da matriz $A$ em $M - N$ é a base para a construção dos esquemas iterativos, e a escolha adequada de $M$ e $N$ é crucial para garantir a convergência e eficiência computacional. A análise do raio espectral da matriz de iteração $B$ fornece um critério fundamental para a convergência, e resultados específicos para matrizes tridiagonais permitem comparar a taxa de convergência dos diferentes métodos. O método de relaxamento, com a introdução do parâmetro $\\omega$, oferece a possibilidade de otimizar a convergência, e o Teorema de Ostrowski-Reich fornece condições suficientes para a convergência em casos específicos.

### Referências
[^1]: Capítulo 8 mencionado na página 373.
[^2]: Seção 9.7 mencionada na página 374.
[^3]: Teorema 9.5 mencionado na página 374.
[^4]: Teorema 10.1 e 10.3, páginas 374 e 376.
[^5]: Proposição 10.4, página 377.
[^6]: Página 378.
[^7]: Página 379.
[^8]: Página 380.
[^9]: Proposição 9.11 mencionada na página 378.
[^10]: Página 382.
[^11]: Problema 10.6 mencionado na página 381.
[^12]: Página 384.
[^13]: Seção 10.4 mencionada na página 384.
[^14]: Proposição 9.12 mencionada na página 374.
[^15]: Página 373.
[^16]: Página 388.
[^17]: Página 389.

<!-- END -->