## Convergência dos Métodos de Jacobi, Gauss-Seidel e Relaxamento para Matrizes Tridiagonais

### Introdução
Este capítulo aprofunda a análise da convergência dos métodos iterativos de Jacobi, Gauss-Seidel e Relaxamento (SOR) para a classe específica de matrizes tridiagonais Hermitianas definidas positivas [^389]. Anteriormente, foram introduzidos os métodos iterativos como alternativas aos métodos diretos para a solução de sistemas lineares [^373]. Agora, exploraremos condições de convergência e taxas relativas para esses métodos quando aplicados a um tipo de matriz que surge frequentemente em aplicações práticas.

### Conceitos Fundamentais
Para matrizes tridiagonais Hermitianas definidas positivas, podemos estabelecer resultados mais precisos sobre a convergência e a taxa de convergência dos métodos de Jacobi, Gauss-Seidel e Relaxamento [^390].

**Teorema da Convergência**: Os métodos de Jacobi, Gauss-Seidel e relaxamento convergem para matrizes tridiagonais Hermitianas definidas positivas quando o parâmetro de relaxamento $\\omega$ está no intervalo $(0, 2)$ [^388]. Este resultado é uma aplicação do teorema de Ostrowski-Reich [^387, 388], que fornece uma condição suficiente para a convergência de métodos iterativos associados a matrizes Hermitianas definidas positivas.

**Autovalores da Matriz de Jacobi**: Para uma matriz tridiagonal Hermitiana definida positiva, os autovalores da matriz de Jacobi $J$ são reais [^391]. Fórmulas específicas relacionam os autovalores de $J$ e as raízes das equações características às propriedades de convergência dos métodos [^391].

**Relação entre as Taxas de Convergência**: As taxas de convergência dos métodos estão relacionadas pela seguinte hierarquia [^393]:
$$\
\rho(L_{\omega_o}) < \rho(L_1) = (\rho(J))^2 < \rho(J),
$$
onde:
*   $\\rho(L_{\\omega_o})$ é o raio espectral da matriz de relaxamento com o parâmetro de relaxamento ótimo $\\omega_o$ [^393].
*   $\\rho(L_1)$ é o raio espectral da matriz de Gauss-Seidel (equivalente ao método de relaxamento com $\\omega = 1$) [^382].
*   $\\rho(J)$ é o raio espectral da matriz de Jacobi [^380].

Essa hierarquia implica que o método de relaxamento com o parâmetro ótimo converge mais rapidamente que o método de Gauss-Seidel, que por sua vez converge mais rapidamente que o método de Jacobi [^393].

**Determinação do Parâmetro de Relaxamento Ótimo:** O parâmetro de relaxamento ótimo $\\omega_o$ pode ser calculado como [^391]:

$$\
\omega_o = \frac{2}{1 + \sqrt{1 - (\rho(J))^2}}
$$

Este valor minimiza o raio espectral da matriz de relaxamento, resultando na convergência mais rápida possível [^393]. É importante notar que o conhecimento de $\\rho(J)$ é necessário para calcular $\\omega_o$ [^391].

**Prova da hierarquia das taxas de convergência** [^393]:

Para demonstrar a hierarquia das taxas de convergência, precisamos mostrar que cada desigualdade na expressão $$\\rho(L_{\\omega_o}) < \\rho(L_1) = (\\rho(J))^2 < \\rho(J)$$ é válida.

1.  **$\\rho(L_1) = (\\rho(J))^2$**: Esta igualdade foi estabelecida na Proposição 10.8 [^389], que mostra que o raio espectral da matriz de Gauss-Seidel é o quadrado do raio espectral da matriz de Jacobi para matrizes tridiagonais.

2.  **$(\\rho(J))^2 < \\rho(J)$**: Esta desigualdade é válida se e somente se $\\rho(J) < 1$ e $\\rho(J) > 0$. A condição $\\rho(J) < 1$ garante que o método de Jacobi converge [^376]. Se $\\rho(J) = 0$, todos os métodos convergem em um único passo, e a desigualdade não se aplica estritamente.

3.  **$\\rho(L_{\\omega_o}) < \\rho(L_1)$**: A Proposição 10.10 [^393] demonstra que existe um parâmetro de relaxamento ótimo $\\omega_o$ tal que o raio espectral da matriz de relaxamento é minimizado. Além disso, o valor mínimo do raio espectral é dado por $\\rho(L_{\\omega_o}) = \\omega_o - 1$ [^393]. Como $\\omega_o$ é escolhido para minimizar o raio espectral, ele deve ser menor que o raio espectral do método de Gauss-Seidel (que corresponde a $\\omega = 1$).

    Para mostrar que $\\rho(L_{\\omega_o}) < \\rho(L_1)$, precisamos demonstrar que $\\omega_o - 1 < (\\rho(J))^2$. Substituindo a fórmula para $\\omega_o$, temos:

    $$\
    \frac{2}{1 + \sqrt{1 - (\rho(J))^2}} - 1 < (\rho(J))^2
    $$

    Resolvendo para $(\\rho(J))^2$ e simplificando, podemos mostrar que esta desigualdade é sempre verdadeira quando $0 < \\rho(J) < 1$. $\\blacksquare$

### Conclusão
A análise da convergência dos métodos de Jacobi, Gauss-Seidel e relaxamento para matrizes tridiagonais Hermitianas definidas positivas revela uma hierarquia clara nas taxas de convergência [^393]. O método de relaxamento, quando utilizado com o parâmetro de relaxamento ótimo, oferece a convergência mais rápida [^393]. O método de Gauss-Seidel é mais rápido que o método de Jacobi, com a relação $\\rho(L_1) = (\\rho(J))^2$ fornecendo uma medida precisa dessa melhoria [^389]. Esses resultados são cruciais para a seleção do método iterativo mais eficiente para a solução de sistemas lineares com matrizes tridiagonais Hermitianas definidas positivas [^389].

### Referências
[^373]: Capítulo 10. Iterative Methods for Solving Linear Systems, Seção 10.1 Convergence of Sequences of Vectors and Matrices.
[^376]: Capítulo 10. Iterative Methods for Solving Linear Systems, Seção 10.2 Convergence of Iterative Methods.
[^380]: Capítulo 10. Iterative Methods for Solving Linear Systems, Seção 10.3 Description of the Methods of Jacobi, Gauss-Seidel, and Relaxation.
[^382]: Capítulo 10. Iterative Methods for Solving Linear Systems, Seção 10.3 Description of the Methods of Jacobi, Gauss-Seidel, and Relaxation.
[^387]: Capítulo 10. Iterative Methods for Solving Linear Systems, Seção 10.4 Convergence of the Methods of Gauss-Seidel and Relaxation.
[^388]: Capítulo 10. Iterative Methods for Solving Linear Systems, Seção 10.4 Convergence of the Methods of Gauss-Seidel and Relaxation.
[^389]: Capítulo 10. Iterative Methods for Solving Linear Systems, Seção 10.5 Convergence of the Methods of Jacobi, Gauss-Seidel, and Relaxation for Tridiagonal Matrices.
[^390]: Capítulo 10. Iterative Methods for Solving Linear Systems, Seção 10.5 Convergence of the Methods of Jacobi, Gauss-Seidel, and Relaxation for Tridiagonal Matrices.
[^391]: Capítulo 10. Iterative Methods for Solving Linear Systems, Seção 10.5 Convergence of the Methods of Jacobi, Gauss-Seidel, and Relaxation for Tridiagonal Matrices.
[^393]: Capítulo 10. Iterative Methods for Solving Linear Systems, Seção 10.5 Convergence of the Methods of Jacobi, Gauss-Seidel, and Relaxation for Tridiagonal Matrices.
<!-- END -->