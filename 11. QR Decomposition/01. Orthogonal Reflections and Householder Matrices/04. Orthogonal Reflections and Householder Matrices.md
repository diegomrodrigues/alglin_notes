## Reflexões Hiperplanares e Matrizes de Householder

### Introdução
Este capítulo aprofunda o conceito de **reflexões hiperplanares**, representadas pelas **matrizes de Householder**, e sua importância fundamental na análise numérica de matrizes [^1]. Como mencionado em [^1], essas reflexões desempenham um papel crucial na solução de sistemas de equações lineares, problemas de mínimos quadrados, computação de autovalores e transformação de matrizes simétricas em formas tridiagonais. Expandindo o conceito de simetrias ortogonais, exploraremos a formulação matemática detalhada das reflexões hiperplanares e sua conexão com as matrizes de Householder.

### Conceitos Fundamentais
Uma **reflexão** *s* sobre um **hiperplano** *H*, dado um vetor não nulo *w* ortogonal a *H*, transforma qualquer vetor *u* em *E* da seguinte forma [^1]:
$$s(u) = u - 2\frac{(u \cdot w)}{||w||^2}w$$
onde:
*   *u* é o vetor a ser refletido.
*   *w* é o vetor não nulo ortogonal ao hiperplano *H*.
*   $u \cdot w$ representa o produto escalar de *u* e *w*.
*   $||w||^2$ é o quadrado da norma euclidiana de *w*.

Essa transformação preserva as normas dos vetores e atua como uma isometria [^1], ou seja, preserva as distâncias entre os pontos. A fórmula acima [^1] define a reflexão de *u* em relação ao hiperplano *H* através da subtração de um múltiplo do vetor ortogonal *w*. O fator $2\frac{(u \cdot w)}{||w||^2}$ determina a magnitude da correção aplicada a *u* para obter a reflexão.

**Proposição:** Seja *E* um espaço euclidiano de dimensão finita e seja *H* um hiperplano em *E*. Para qualquer vetor não nulo *w* ortogonal a *H*, a reflexão hiperplanar *s* sobre *H* é dada por [^1]:
$$s(u) = u - 2\frac{(u \cdot w)}{||w||^2}w, \forall u \in E$$

*Prova:* Seja *u* um vetor em *E*. Podemos decompor *u* em duas componentes: uma componente $p_H(u)$ que está no hiperplano *H* e uma componente $p_G(u)$ que é ortogonal a *H* [^3].  Como *w* é ortogonal a *H*, $p_G(u)$ é um múltiplo de *w*.  Portanto, podemos escrever:
$$u = p_H(u) + p_G(u)$$
onde $p_G(u) = \lambda w$ para algum escalar $\lambda$.  O objetivo da reflexão é manter $p_H(u)$ inalterado e inverter a direção de $p_G(u)$.  Assim,
$$s(u) = p_H(u) - p_G(u) = p_H(u) - \lambda w$$
Sabemos que [^3]
$$u = p_H(u) + p_G(u)$$
e [^3]
$$s(u) = p_F(u) - p_G(u)$$
onde F é o hiperplano e G é o espaço ortogonal a F.
Também sabemos que [^3]
$$u = p_H(u) + p_G(u)$$
$$p_G(u) = \lambda w$$
e $u \cdot w = \lambda ||w||^2$, então $\lambda = \frac{u \cdot w}{||w||^2}$. Substituindo $\lambda$ na expressão para *s(u)*, obtemos:
$$s(u) = u - 2p_G(u) = u - 2\lambda w = u - 2\frac{(u \cdot w)}{||w||^2}w$$
$\blacksquare$

**Matrizes de Householder:** As reflexões hiperplanares são representadas por matrizes chamadas **matrizes de Householder** [^1]. Uma matriz de Householder tem a forma [^4]:
$$H = I_n - 2\frac{ww^T}{||w||^2}$$
onde:
*   $I_n$ é a matriz identidade de tamanho *n x n*.
*   *w* é um vetor não nulo em $R^n$.
*   $w^T$ é a transposta de *w*.

As matrizes de Householder são simétricas e ortogonais [^5]. Isso significa que $H = H^T$ e $H^T H = I_n$. A propriedade de simetria decorre diretamente da construção da matriz, enquanto a ortogonalidade pode ser verificada calculando $H^T H$:
$$H^T H = \left(I - 2\frac{ww^T}{||w||^2}\right)^T \left(I - 2\frac{ww^T}{||w||^2}\right) = \left(I - 2\frac{ww^T}{||w||^2}\right) \left(I - 2\frac{ww^T}{||w||^2}\right)$$
$$= I - 4\frac{ww^T}{||w||^2} + 4\frac{ww^Tww^T}{||w||^4} = I - 4\frac{ww^T}{||w||^2} + 4\frac{w(w^Tw)w^T}{||w||^4} = I - 4\frac{ww^T}{||w||^2} + 4\frac{w||w||^2w^T}{||w||^4}$$
$$= I - 4\frac{ww^T}{||w||^2} + 4\frac{ww^T}{||w||^2} = I$$

A ortogonalidade das matrizes de Householder garante que a transformação representada por *H* preserva as normas dos vetores, o que é fundamental em muitas aplicações numéricas.

### Aplicações
As reflexões hiperplanares e as matrizes de Householder têm diversas aplicações na análise numérica de matrizes [^1]:

*   **Solução de sistemas de equações lineares:** As matrizes de Householder podem ser usadas para transformar um sistema de equações lineares em uma forma triangular superior, que pode ser facilmente resolvida por substituição retroativa.
*   **Problemas de mínimos quadrados:** As matrizes de Householder podem ser usadas para resolver problemas de mínimos quadrados transformando a matriz do sistema em uma forma triangular superior.
*   **Computação de autovalores:** As matrizes de Householder podem ser usadas para transformar uma matriz em uma forma de Hessenberg (quase triangular), o que simplifica o cálculo de autovalores.
*   **Transformação de matrizes simétricas em formas tridiagonais:** As matrizes de Householder podem ser usadas para transformar uma matriz simétrica em uma forma tridiagonal, o que é útil para o cálculo de autovalores e autovetores.
*   **Decomposição QR:** Como mencionado em [^1], as reflexões de Householder são utilizadas na decomposição QR de matrizes arbitrárias. A decomposição QR é uma ferramenta fundamental para resolver sistemas lineares e problemas de mínimos quadrados.

### Conclusão
As reflexões hiperplanares, representadas pelas matrizes de Householder, são ferramentas poderosas na análise numérica de matrizes. Sua capacidade de preservar normas e atuar como isometrias as torna ideais para uma variedade de aplicações, incluindo a solução de sistemas de equações lineares, problemas de mínimos quadrados e computação de autovalores [^1]. A estrutura matemática bem definida das reflexões hiperplanares e das matrizes de Householder permite uma implementação eficiente e robusta em algoritmos numéricos.

### Referências
[^1]: Capítulo 13, QR-Decomposition for Arbitrary Matrices, Seção 13.1 Orthogonal Reflections.
[^2]: Capítulo 13, QR-Decomposition for Arbitrary Matrices, Definition 13.1.
[^3]: Capítulo 13, QR-Decomposition for Arbitrary Matrices, página 491.
[^4]: Capítulo 13, QR-Decomposition for Arbitrary Matrices, Definition 13.3.
[^5]: Capítulo 13, QR-Decomposition for Arbitrary Matrices, Seção 13.1 Orthogonal Reflections, página 495.
<!-- END -->