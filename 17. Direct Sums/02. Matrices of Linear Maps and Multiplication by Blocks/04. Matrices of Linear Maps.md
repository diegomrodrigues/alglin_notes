## Matrizes de Aplicações Lineares e Multiplicação por Blocos

### Introdução
Este capítulo aprofunda o conceito de representação de aplicações lineares através de matrizes, expandindo a ideia para o caso em que os espaços vetoriais são decompostos em somas diretas. Exploraremos como a multiplicação de matrizes se estende naturalmente para matrizes cujos elementos são aplicações lineares, e como essa extensão se relaciona com a composição de funções. Este tópico se baseia nos conceitos de somas diretas apresentados anteriormente no Capítulo 6 [^1, ^2, ^3, ^4, ^5, ^6, ^7, ^8, ^9, ^10], e fornece uma ferramenta poderosa para simplificar e analisar aplicações lineares complexas.

### Conceitos Fundamentais
A representação de uma aplicação linear $f: E \rightarrow F$ sobre uma base $(u_1, ..., u_n)$ de $E$ e uma base $(v_1, ..., v_m)$ de $F$ por uma matriz $A = (a_{ij})$ pode ser generalizada. Considere as decomposições em soma direta $E = E_1 \oplus ... \oplus E_n$ e $F = F_1 \oplus ... \oplus F_m$ [^11]. Uma aplicação linear $f: E \rightarrow F$ pode ser representada por uma matriz $(f_{ij})$, onde cada $f_{ij}: E_j \rightarrow F_i$ é uma aplicação linear.

**Definição 6.6** [^11]: Dada uma aplicação linear $f: E \rightarrow F$, definimos as aplicações lineares $f_{ij}: E_j \rightarrow F_i$ da seguinte forma: Seja $pr_i: F \rightarrow F_i$ a projeção de $F = F_1 \oplus ... \oplus F_m$ em $F_i$. Se $f_j: E_j \rightarrow F$ é a restrição de $f$ a $E_j$, ou seja, para todo vetor $x_j \in E_j$, $f_j(x_j) = f(x_j)$, então definimos a aplicação $f_{ij}: E_j \rightarrow F_i$ por $f_{ij} = pr_i \circ f_j$.

Se $x_j \in E_j$, então $f(x_j) = f_j(x_j) = \sum_{i=1}^{m} f_{ij}(x_j)$, onde $f_{ij}(x_j) \in F_i$ [^12]. Assim, para cada vetor $x = x_1 + ... + x_n \in E$, com $x_j \in E_j$, temos $f(x) = \sum_{j=1}^{n} f(x_j) = \sum_{j=1}^{n} \sum_{i=1}^{m} f_{ij}(x_j)$ [^12].

Inversamente, dada uma família $(f_{ij})_{1 \leq i \leq m, 1 \leq j \leq n}$ de aplicações lineares $f_{ij}: E_j \rightarrow F_i$, podemos obter a aplicação linear $f: E \rightarrow F$ definida como $f(x) = \sum_{i=1}^{m} \sum_{j=1}^{n} f_{ij}(x_j)$ para todo $x = x_1 + ... + x_n \in E$, com $x_j \in E_j$ [^12].

Existe um isomorfismo entre os espaços vetoriais $Hom(E, F)$ e $\prod_{\substack{1 \leq i \leq m \\\\ 1 \leq j \leq n}} Hom(E_j, F_i)$ [^12].

A representação matricial $M(f)$ de $f$ com respeito às decomposições em soma direta é dada por:

$$\nM(f) =\n\begin{pmatrix}\nf_{11} & \cdots & f_{1n} \\\\n\vdots & \ddots & \vdots \\\\nf_{m1} & \cdots & f_{mn}\n\end{pmatrix}\n$$

Esta é uma matriz $m \times n$ cujos elementos são aplicações lineares $f_{ij}: E_j \rightarrow F_i$ [^14].

**Multiplicação de Matrizes de Aplicações Lineares:**

A multiplicação de matrizes de escalares se estende naturalmente para matrizes de aplicações lineares, substituindo a multiplicação de escalares pela composição de aplicações lineares [^11]. Sejam $E$, $F$ e $G$ três espaços vetoriais com as seguintes decomposições em soma direta:

$$E = \bigoplus_{k=1}^{p} E_k, \quad F = \bigoplus_{j=1}^{n} F_j, \quad G = \bigoplus_{i=1}^{m} G_i$$

Considere duas aplicações lineares $f: E \rightarrow F$ e $g: F \rightarrow G$. Sejam $B = (f_{jk})$ a matriz $n \times p$ de aplicações lineares associada a $f$ e $A = (g_{ij})$ a matriz $m \times n$ de aplicações lineares associada a $g$ [^14]. Queremos encontrar a matriz $C = (h_{ik})$ associada à composição $h = g \circ f$ [^15].

Para $x_k \in E_k$, temos $f_k(x_k) = f(x_k) = \sum_{j=1}^{n} f_{jk}(x_k)$, com $f_{jk}(x_k) \in F_j$ [^14]. Similarmente, para $y_j \in F_j$, temos $g_j(y_j) = g(y_j) = \sum_{i=1}^{m} g_{ij}(y_j)$, com $g_{ij}(y_j) \in G_i$ [^14].

Então, $h_k(x_k) = (g \circ f)(x_k) = g(f(x_k)) = g(f_k(x_k)) = g(\sum_{j=1}^{n} f_{jk}(x_k)) = \sum_{j=1}^{n} g(f_{jk}(x_k)) = \sum_{j=1}^{n} g_j(f_{jk}(x_k)) =  \sum_{j=1}^{n} \sum_{i=1}^{m} g_{ij}(f_{jk}(x_k))$ [^15].

Portanto, $h_{ik} = pr_i \circ h_k = \sum_{j=1}^{n} g_{ij} \circ f_{jk}$ [^15]. Assim, a matriz $C = (h_{ik})$ é dada por $C = AB$, onde a multiplicação é definida como $h_{ik} = \sum_{j=1}^{n} g_{ij} \circ f_{jk}$ [^15].

**Proposição 6.12** [^15]: Sejam $E$, $F$ e $G$ três espaços vetoriais expressos como somas diretas:

$$E = \bigoplus_{k=1}^{p} E_k, \quad F = \bigoplus_{j=1}^{n} F_j, \quad G = \bigoplus_{i=1}^{m} G_i$$

Para quaisquer aplicações lineares $f: E \rightarrow F$ e $g: F \rightarrow G$, seja $B = (f_{jk})$ a matriz $n \times p$ de aplicações lineares associada a $f$ (com respeito à decomposição de $E$ e $F$ como somas diretas) e seja $A = (g_{ij})$ a matriz $m \times n$ de aplicações lineares associada a $g$ (com respeito à decomposição de $F$ e $G$ como somas diretas). Então, a matriz $m \times p$ $C = (h_{ik})$ de aplicações lineares associada a $g \circ f$ (com respeito à decomposição de $E$ e $G$ como somas diretas) é dada por $C = AB$, com $h_{ik} = \sum_{j=1}^{n} g_{ij} \circ f_{jk}$.

### Conclusão
Este capítulo demonstrou como a representação matricial de aplicações lineares pode ser estendida para o caso em que os espaços vetoriais são decompostos em somas diretas. A multiplicação de matrizes, neste contexto, corresponde à composição de aplicações lineares, fornecendo uma ferramenta poderosa para a análise e simplificação de problemas complexos. Essa abordagem permite decompor uma aplicação linear em componentes menores e mais gerenciáveis, facilitando o estudo de suas propriedades e a resolução de equações lineares.

### Referências
[^1]: Capítulo 6, página 167
[^2]: Capítulo 6, página 168
[^3]: Capítulo 6, página 169
[^4]: Capítulo 6, página 170
[^5]: Capítulo 6, página 171
[^6]: Capítulo 6, página 172
[^7]: Capítulo 6, página 173
[^8]: Capítulo 6, página 174
[^9]: Capítulo 6, página 175
[^10]: Capítulo 6, página 176
[^11]: Capítulo 6, página 177
[^12]: Capítulo 6, página 178
[^13]: Capítulo 6, página 179
[^14]: Capítulo 6, página 180
[^15]: Capítulo 6, página 181
<!-- END -->