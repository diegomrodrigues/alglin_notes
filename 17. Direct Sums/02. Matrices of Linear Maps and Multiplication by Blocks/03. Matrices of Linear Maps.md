## Matrizes de Aplicações Lineares e Multiplicação por Blocos

### Introdução
Este capítulo explora a representação de aplicações lineares através de matrizes, estendendo o conceito de matrizes de escalares para matrizes cujos elementos são, eles próprios, aplicações lineares. Essa generalização permite a aplicação da multiplicação por blocos, uma técnica poderosa na análise e manipulação de transformações lineares. O conceito de soma direta, apresentado anteriormente [^1, ^2, ^3, ^4, ^5, ^6, ^7, ^8, ^9, ^10], é fundamental para decompor espaços vetoriais e simplificar a representação matricial de aplicações lineares.

### Conceitos Fundamentais

A representação de uma aplicação linear $f: E \\rightarrow F$ sobre uma base $(u_1, ..., u_n)$ de $E$ e uma base $(v_1, ..., v_m)$ de $F$ por uma matriz $A = (a_{ij})$ de escalares pode ser generalizada para o caso em que $E$ e $F$ são expressos como somas diretas [^11]:
$$E = E_1 \\oplus ... \\oplus E_n, \\quad F = F_1 \\oplus ... \\oplus F_m.$$
Neste contexto, a aplicação linear $f$ é representada por uma matriz $(f_{ij})$, onde cada $f_{ij}: E_j \\rightarrow F_i$ é uma aplicação linear [^11]. A ação de $f$ sobre um vetor $x = x_1 + ... + x_n$, com $x_j \\in E_j$, é dada por [^11]:
$$y_i = \\sum_{j=1}^{n} f_{ij}(x_j),$$
onde $y = y_1 + ... + y_m$, com $y_i \\in F_i$.  Esta equação generaliza a multiplicação de matrizes de escalares, onde cada entrada da matriz é substituída por uma aplicação linear.

A **interpretação** da multiplicação de uma matriz $m \\times n$ de aplicações lineares $f_{ij}$ por um vetor coluna de $n$ vetores $x_j \\in E_j$ envolve aplicar cada $f_{ij}$ a $x_j$ para obter $f_{ij}(x_j)$ e somar sobre o índice $j$ para obter o *i*-ésimo vetor de saída [^13].  Esta é uma generalização da multiplicação de matrizes escalares.

Dada uma aplicação linear $f: E \\rightarrow F$, e as decomposições em soma direta de $E$ e $F$ [^11]:
$$E = \\bigoplus_{j=1}^{n} E_j, \\quad F = \\bigoplus_{i=1}^{m} F_i,$$
definimos as aplicações lineares $f_{ij}: E_j \\rightarrow F_i$ como [^11]:
$$f_{ij} = pr_i \\circ f_j,$$
onde $f_j: E_j \\rightarrow F$ é a restrição de $f$ a $E_j$, e $pr_i: F \\rightarrow F_i$ é a projeção de $F$ em $F_i$.  Para cada $x_j \\in E_j$, temos $f(x_j) = \\sum_{i=1}^{m} f_{ij}(x_j)$, onde $f_{ij}(x_j) \\in F_i$ [^12].

Para qualquer vetor $x = x_1 + ... + x_n \\in E$, com $x_j \\in E_j$, temos [^12]:
$$f(x) = \\sum_{j=1}^{n} f(x_j) = \\sum_{j=1}^{n} \\sum_{i=1}^{m} f_{ij}(x_j) = \\sum_{i=1}^{m} \\sum_{j=1}^{n} f_{ij}(x_j).$$
Isto mostra como a aplicação $f$ age sobre um vetor $x$ em termos das aplicações $f_{ij}$.

A **matriz** $M(f)$ de $f$ com respeito às decomposições em soma direta de $E$ e $F$ é a matriz $m \\times n$ de aplicações lineares $f_{ij}$ [^14]:
$$M(f) = \\begin{pmatrix} f_{11} & ... & f_{1n} \\\\ \\vdots & & \\vdots \\\\ f_{m1} & ... & f_{mn} \\end{pmatrix}.$$
Para qualquer $x = x_1 + ... + x_n \\in E$ com $x_j \\in E_j$ e $y = y_1 + ... + y_m \\in F$ com $y_i \\in F_i$, temos $y = f(x)$ se e somente se [^14]:
$$\\begin{pmatrix} y_1 \\\\ \\vdots \\\\ y_m \\end{pmatrix} = \\begin{pmatrix} f_{11} & ... & f_{1n} \\\\ \\vdots & & \\vdots \\\\ f_{m1} & ... & f_{mn} \\end{pmatrix} \\begin{pmatrix} x_1 \\\\ \\vdots \\\\ x_n \\end{pmatrix},$$
onde a equação matricial acima significa o sistema de $m$ equações [^14]:
$$y_i = \\sum_{j=1}^{n} f_{ij}(x_j), \\quad i = 1, ..., m.$$

**Multiplicação de Matrizes**
Seja $E = \\bigoplus_{k=1}^{p} E_k$, $F = \\bigoplus_{j=1}^{n} F_j$ e $G = \\bigoplus_{i=1}^{m} G_i$ três espaços vetoriais expressos como somas diretas [^14]. Assuma que temos duas aplicações lineares $f: E \\rightarrow F$ e $g: F \\rightarrow G$. Seja $B = (f_{jk})$ a matriz $n \\times p$ de aplicações lineares associada a $f$, e seja $A = (g_{ij})$ a matriz $m \\times n$ de aplicações lineares associada a $g$ [^14].  Seja $h = g \\circ f$, então a matriz $C = (h_{ik})$ associada a $h$ é dada por [^15, ^16, ^17, ^18]:
$$C = AB,$$
onde para todo $i \\in I$ e $k \\in K$,
$$h_{ik} = \\sum_{j \\in J} g_{ij} f_{jk}.$$

### Conclusão

Este capítulo demonstrou como a representação de aplicações lineares por matrizes pode ser estendida para matrizes de aplicações lineares, utilizando o conceito de soma direta. Essa generalização permite a aplicação da técnica de multiplicação por blocos, simplificando a análise e manipulação de transformações lineares. A equação $y_i = \\sum_{j=1}^{n} f_{ij}(x_j)$ resume a ação de $f$ sobre um vetor $x$, mostrando como as aplicações $f_{ij}$ se combinam para produzir a transformação geral.

### Referências
[^1]: Definition 6.1
[^2]: Proposition 6.1
[^3]: Proposition 6.2
[^4]: Definition 6.2
[^5]: Definition 6.3
[^6]: Proposition 6.3
[^7]: Proposition 6.4
[^8]: Definition 6.4
[^9]: Proposition 6.5
[^10]: Proposition 6.6
[^11]: Section 6.2
[^12]: Page 178
[^13]: Page 179
[^14]: Page 180
[^15]: Page 181
[^16]: Page 182
[^17]: Page 183
[^18]: Page 184
<!-- END -->