## Matrizes de Aplicações Lineares e Multiplicação por Blocos: Decomposições em Somas Diretas

### Introdução
Este capítulo explora a representação de aplicações lineares através de matrizes, especialmente quando os espaços vetoriais de domínio e contradomínio são expressos como somas diretas. Expandindo o conceito de somas diretas [^1], [^2], [^3], [^4], examinaremos como uma aplicação linear $f: E \rightarrow F$ pode ser decomposta em componentes menores, facilitando a análise e o cálculo. A representação matricial de $f$ será expressa em termos de sub-aplicações $f_{ij}$, que mapeiam componentes de $E$ para componentes de $F$, e demonstraremos como essa representação matricial se relaciona intrinsecamente com as decomposições em somas diretas de $E$ e $F$.

### Conceitos Fundamentais
Sejam $E$ e $F$ espaços vetoriais sobre um corpo $K$. Suponha que $E$ e $F$ sejam expressos como somas diretas [^11]:
$$E = \bigoplus_{j=1}^{n} E_j, \quad F = \bigoplus_{i=1}^{m} F_i$$
onde $E_j$ e $F_i$ são subespaços de $E$ e $F$, respectivamente.

**Definição da Aplicação Linear Componente:**
Dada uma aplicação linear $f: E \rightarrow F$, definimos as aplicações lineares $f_{ij}: E_j \rightarrow F_i$ como [^11]:
$$f_{ij} = \text{pr}_i \circ f|_{E_j}$$
onde $\text{pr}_i: F \rightarrow F_i$ é a projeção de $F$ no subespaço $F_i$ [^14], [^15] e $f|_{E_j}$ é a restrição de $f$ ao subespaço $E_j$. Em outras palavras, $f_{ij}$ é a composição da restrição de $f$ a $E_j$ seguida pela projeção em $F_i$.

**Representação Matricial:**
A aplicação linear $f$ pode ser representada por uma matriz $M(f) = (f_{ij})$, onde cada entrada $f_{ij}$ é uma aplicação linear $E_j \rightarrow F_i$. Portanto, $M(f)$ é uma matriz de aplicações lineares, e não uma matriz de escalares como nas representações matriciais tradicionais [^14].

**Ação da Matriz:**
Para um vetor $x \in E$, podemos escrevê-lo como $x = x_1 + \dots + x_n$, onde $x_j \in E_j$. Então, a ação de $f$ em $x$ é dada por:
$$f(x) = f(x_1 + \dots + x_n) = \sum_{j=1}^{n} f(x_j)$$
Como $f(x_j) \in F$, podemos decompor $f(x_j)$ em suas componentes em $F_i$:
$$f(x_j) = \sum_{i=1}^{m} f_{ij}(x_j)$$
Portanto,
$$f(x) = \sum_{i=1}^{m} \sum_{j=1}^{n} f_{ij}(x_j)$$
Se $y = f(x)$, então $y = y_1 + \dots + y_m$, onde $y_i \in F_i$, e
$$y_i = \sum_{j=1}^{n} f_{ij}(x_j)$$
Esta equação mostra como a matriz $M(f) = (f_{ij})$ atua nos componentes $x_j$ de $x$ para produzir os componentes $y_i$ de $y$.

**Multiplicação por Blocos:**
A representação matricial de aplicações lineares em somas diretas facilita a multiplicação por blocos [^11]. Sejam $E$, $F$ e $G$ espaços vetoriais com as seguintes decomposições em soma direta:
$$E = \bigoplus_{k=1}^{p} E_k, \quad F = \bigoplus_{j=1}^{n} F_j, \quad G = \bigoplus_{i=1}^{m} G_i$$
Sejam $f: E \rightarrow F$ e $g: F \rightarrow G$ aplicações lineares com representações matriciais $M(f) = (f_{jk})$ e $M(g) = (g_{ij})$, respectivamente. Então, a aplicação composta $h = g \circ f: E \rightarrow G$ tem uma representação matricial $M(h) = (h_{ik})$, onde
$$h_{ik} = \sum_{j=1}^{n} g_{ij} \circ f_{jk}$$
Esta é a fórmula da multiplicação de matrizes, onde a multiplicação de escalares é substituída pela composição de aplicações lineares [^11], [^15].

**Exemplo:**
Considere $E = \mathbb{R}^2$ e $F = \mathbb{R}^3$, com as seguintes decomposições:
$$E = E_1 \oplus E_2, \quad F = F_1 \oplus F_2 \oplus F_3$$
onde $E_1 = \text{span}\\{(1, 0)\\}$, $E_2 = \text{span}\\{(0, 1)\\}$, $F_1 = \text{span}\\{(1, 0, 0)\\}$, $F_2 = \text{span}\\{(0, 1, 0)\\}$, e $F_3 = \text{span}\\{(0, 0, 1)\\}$. Seja $f: E \rightarrow F$ definida por $f(x, y) = (x + y, x - y, 2x)$.
Então, podemos encontrar as aplicações lineares $f_{ij}$:
$$f_{11}(x) = x, \quad f_{12}(y) = y$$
$$f_{21}(x) = x, \quad f_{22}(y) = -y$$
$$f_{31}(x) = 2x, \quad f_{32}(y) = 0$$
A matriz $M(f)$ é então dada por:
$$M(f) = \begin{pmatrix} f_{11} & f_{12} \\\\ f_{21} & f_{22} \\\\ f_{31} & f_{32} \end{pmatrix}$$

### Conclusão
A representação matricial de aplicações lineares em espaços vetoriais decompostos em somas diretas fornece uma ferramenta poderosa para simplificar e analisar transformações lineares. Ao decompor os espaços vetoriais em subespaços menores e mais gerenciáveis, podemos representar a aplicação linear original como uma matriz de aplicações lineares menores, facilitando a computação e a compreensão de suas propriedades. Além disso, a propriedade de multiplicação por blocos permite simplificar cálculos complexos envolvendo a composição de aplicações lineares, o que é particularmente útil em aplicações avançadas em álgebra linear e análise funcional.

### Referências
[^1]: Definition 6.1
[^2]: Proposition 6.1
[^3]: Proposition 6.2
[^4]: Definition 6.2
[^11]: Section 6.2
[^14]: Definition 6.7
[^15]: Proposition 6.12
<!-- END -->