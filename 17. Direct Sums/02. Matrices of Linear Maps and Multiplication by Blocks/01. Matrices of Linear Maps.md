## Matrizes de Aplicações Lineares e Multiplicação por Blocos: Decomposições em Soma Direta e Aplicações Lineares Induzidas

### Introdução
Este capítulo explora a representação de aplicações lineares através de matrizes, com um foco especial na técnica de multiplicação por blocos. A representação matricial de uma transformação linear é intrinsecamente ligada à escolha de bases para os espaços vetoriais envolvidos. Quando esses espaços admitem decomposições em soma direta, a matriz que representa a transformação linear pode ser convenientemente expressa em termos de blocos, cada bloco correspondendo a uma aplicação linear entre os subespaços da soma direta. Como veremos, a multiplicação de matrizes em blocos estende a multiplicação de matrizes escalares, fornecendo uma ferramenta poderosa para simplificar cálculos e revelar a estrutura subjacente das transformações lineares. Este capítulo se baseia nos conceitos de somas diretas introduzidos anteriormente [^1, ^2, ^3, ^4, ^5, ^6, ^7, ^8, ^9, ^10], estendendo-os para a representação matricial de transformações lineares.

### Conceitos Fundamentais

Considere uma aplicação linear $f: E \\rightarrow F$, onde $E$ e $F$ são espaços vetoriais sobre um corpo $\\mathbb{K}$. Suponha que $E$ e $F$ admitem as seguintes decomposições em soma direta:

$$E = E_1 \\oplus \\dots \\oplus E_n$$
$$F = F_1 \\oplus \\dots \\oplus F_m$$

Estas decomposições permitem-nos definir aplicações lineares $f_{ij}: E_j \\rightarrow F_i$ que atuam como os blocos de construção para a representação matricial de $f$ [^11].

**Definição das Aplicações Lineares $f_{ij}$**
Seja $f_j: E_j \\rightarrow F$ a restrição de $f$ ao subespaço $E_j$, ou seja, $f_j(x_j) = f(x_j)$ para todo $x_j \\in E_j$ [^11]. Seja $pr_i: F \\rightarrow F_i$ a projeção de $F$ sobre o subespaço $F_i$, correspondente à decomposição em soma direta de $F$ [^8]. Definimos a aplicação linear $f_{ij}$ como a composição:

$$f_{ij} = pr_i \\circ f_j$$

Em outras palavras, $f_{ij}: E_j \\rightarrow F_i$ é a aplicação linear que leva um vetor $x_j \\in E_j$ para sua imagem sob $f$, e então projeta essa imagem no subespaço $F_i$ [^11].

**Representação Matricial em Blocos**

A aplicação linear $f$ pode ser representada por uma matriz em blocos $M(f)$ de dimensão $m \\times n$, onde cada bloco é uma aplicação linear $f_{ij}: E_j \\rightarrow F_i$ [^14]. Portanto,
$$\nM(f) = \\begin{bmatrix}\nf_{11} & f_{12} & \\cdots & f_{1n} \\\\\nf_{21} & f_{22} & \\cdots & f_{2n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nf_{m1} & f_{m2} & \\cdots & f_{mn}\n\\end{bmatrix}\n$$

Se $x = x_1 + \\dots + x_n \\in E$ com $x_j \\in E_j$, então $f(x)$ pode ser expresso como:

$$f(x) = \\sum_{j=1}^{n} f(x_j) = \\sum_{j=1}^{n} \\sum_{i=1}^{m} f_{ij}(x_j)$$

Este resultado mostra como os blocos $f_{ij}$ decompõem a ação de $f$ em componentes que se encaixam naturalmente na estrutura de soma direta de $F$.

**Multiplicação por Blocos**

A representação em blocos facilita a extensão da multiplicação de matrizes escalares para matrizes cujas entradas são aplicações lineares [^11]. Sejam $E$, $F$ e $G$ espaços vetoriais com as seguintes decomposições em soma direta:

$$E = \\bigoplus_{k=1}^{p} E_k, \\quad F = \\bigoplus_{j=1}^{n} F_j, \\quad G = \\bigoplus_{i=1}^{m} G_i$$

Considere as aplicações lineares $f: E \\rightarrow F$ e $g: F \\rightarrow G$. Sejam $B = (f_{jk})$ a matriz $n \\times p$ de aplicações lineares associada a $f$ e $A = (g_{ij})$ a matriz $m \\times n$ associada a $g$. A aplicação composta $h = g \\circ f: E \\rightarrow G$ é representada por uma matriz $C = (h_{ik})$ de dimensão $m \\times p$, onde cada elemento $h_{ik}: E_k \\rightarrow G_i$ é dado por [^15]:

$$h_{ik} = \\sum_{j=1}^{n} g_{ij} \\circ f_{jk}$$

Esta fórmula é a generalização da multiplicação de matrizes escalares, onde a multiplicação de escalares é substituída pela composição de aplicações lineares [^15].

**Exemplo**

Considere $E = E_1 \\oplus E_2$ e $F = F_1 \\oplus F_2 \\oplus F_3$. Seja $f: E \\rightarrow F$ uma aplicação linear. Então, para $x = x_1 + x_2$ com $x_1 \\in E_1$ e $x_2 \\in E_2$, temos [^12]:

$$f(x) = f_{11}(x_1) + f_{12}(x_2) + f_{21}(x_1) + f_{22}(x_2) + f_{31}(x_1) + f_{32}(x_2)$$

onde $f_{ij}: E_j \\rightarrow F_i$. Em notação matricial, isto pode ser escrito como [^12]:

$$\n\\begin{bmatrix} y_1 \\\\ y_2 \\\\ y_3 \\end{bmatrix} =\n\\begin{bmatrix} f_{11} & f_{12} \\\\ f_{21} & f_{22} \\\\ f_{31} & f_{32} \\end{bmatrix}\n\\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix}\n$$

### Conclusão

A representação de aplicações lineares por matrizes em blocos, quando os espaços vetoriais admitem decomposições em soma direta, oferece uma perspectiva valiosa e uma ferramenta computacional eficaz. A multiplicação por blocos generaliza a multiplicação de matrizes escalares, permitindo simplificar cálculos e analisar a estrutura subjacente das aplicações lineares. Este formalismo é particularmente útil em contextos onde as decomposições em soma direta refletem propriedades estruturais importantes dos espaços vetoriais e das transformações lineares em questão. A capacidade de manipular matrizes de aplicações lineares como entidades algébricas facilita a análise e a resolução de problemas em diversas áreas da matemática e da física, incluindo a álgebra linear numérica, a teoria das representações e a mecânica quântica.

### Referências
[^1]: Definition 6.1.
[^2]: Proposition 6.1.
[^3]: Proposition 6.2.
[^4]: Definition 6.2.
[^5]: Definition 6.3.
[^6]: Proposition 6.3.
[^7]: Proposition 6.4.
[^8]: Proposition 6.7.
[^9]: Proposition 6.8.
[^10]: Proposition 6.9.
[^11]: Definition 6.6.
[^12]: Example 6.1.
[^13]: Example 6.2.
[^14]: Definition 6.7.
[^15]: Proposition 6.12.
[^16]: Proposition 6.13.
[^17]: Proposition 6.14.

<!-- END -->