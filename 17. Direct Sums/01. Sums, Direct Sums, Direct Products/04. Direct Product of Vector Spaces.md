## Produto Direto de Espaços Vetoriais

### Introdução
Este capítulo aprofunda o estudo de construções de novos espaços vetoriais a partir de espaços vetoriais existentes, focando no **produto direto**. Em continuidade ao conceito de soma direta explorado anteriormente, o produto direto oferece uma perspectiva complementar na construção e análise de espaços vetoriais. O produto direto, ao contrário da soma direta externa, que envolve conjuntos específicos, utiliza o conceito de pares ordenados, permitindo uma construção mais direta e intuitiva [^1].

### Conceitos Fundamentais

O **produto direto** de espaços vetoriais $E_1, ..., E_p$ sobre um corpo $K$ é definido como o conjunto de *p*-uplas ordenadas $(u_1, ..., u_p)$, onde $u_i \in E_i$ para cada $i$. Este conjunto, denotado por $E_1 \times ... \times E_p$, torna-se um espaço vetorial quando equipado com operações de adição e multiplicação escalar definidas componente a componente [^3].

**Definição:** Dado um conjunto de espaços vetoriais $E_1, ..., E_p$, seu produto direto $F = E_1 \times ... \times E_p$ é o espaço vetorial com as seguintes operações [^1]:
*   **Adição:** $(u_1, ..., u_p) + (v_1, ..., v_p) = (u_1 + v_1, ..., u_p + v_p)$
*   **Multiplicação escalar:** $\lambda(u_1, ..., u_p) = (\lambda u_1, ..., \lambda u_p)$, onde $\lambda \in K$

O vetor zero neste espaço é dado por $(0, ..., 0)$, onde cada $0$ é o vetor zero do espaço vetorial correspondente $E_i$ [^1].

**Proposição:** O produto direto $E_1 \times ... \times E_p$ com as operações definidas acima satisfaz os axiomas de um espaço vetorial.

*Prova:* Para demonstrar que $E_1 \times ... \times E_p$ é um espaço vetorial, é necessário verificar os seguintes axiomas:

1.  **Comutatividade da adição:** $(u + v) = (v + u)$
2.  **Associatividade da adição:** $(u + v) + w = u + (v + w)$
3.  **Existência do elemento neutro:** Existe um vetor $0 = (0, ..., 0)$ tal que $u + 0 = u$
4.  **Existência do elemento inverso:** Para cada $u$, existe um $-u$ tal que $u + (-u) = 0$
5.  **Compatibilidade da multiplicação escalar com a multiplicação do corpo:** $\lambda(\mu u) = (\lambda \mu) u$
6.  **Distributividade da multiplicação escalar em relação à adição vetorial:** $\lambda(u + v) = \lambda u + \lambda v$
7.  **Distributividade da multiplicação escalar em relação à adição no corpo:** $(\lambda + \mu)u = \lambda u + \mu u$
8.  **Existência do elemento identidade multiplicativa:** $1u = u$

Cada um destes axiomas pode ser facilmente verificado utilizando as definições de adição e multiplicação escalar componente a componente. Por exemplo, para a comutatividade:
$$(u_1, ..., u_p) + (v_1, ..., v_p) = (u_1 + v_1, ..., u_p + v_p) = (v_1 + u_1, ..., v_p + u_p) = (v_1, ..., v_p) + (u_1, ..., u_p)$$
onde a comutatividade em cada $E_i$ é utilizada. Os outros axiomas são verificados de maneira análoga. $\blacksquare$

**Observação:** No caso especial em que cada $E_i = \mathbb{R}$, o produto direto $E_1 \times ... \times E_p$ se torna $\mathbb{R}^p$, o espaço vetorial *p*-dimensional familiar [^3].

**Definição:** As **projeções** $\text{pr}_i: E_1 \times ... \times E_p \rightarrow E_i$ são definidas por $\text{pr}_i(u_1, ..., u_p) = u_i$ [^3]. Estas projeções são transformações lineares.

**Proposição:** As projeções $\text{pr}_i$ são lineares.

*Prova:* Para mostrar que $\text{pr}_i$ é linear, devemos verificar que $\text{pr}_i(u + v) = \text{pr}_i(u) + \text{pr}_i(v)$ e $\text{pr}_i(\lambda u) = \lambda \text{pr}_i(u)$ para todos os vetores $u, v \in E_1 \times ... \times E_p$ e escalar $\lambda \in K$. Sejam $u = (u_1, ..., u_p)$ e $v = (v_1, ..., v_p)$. Então:
$$\text{pr}_i(u + v) = \text{pr}_i((u_1 + v_1, ..., u_p + v_p)) = u_i + v_i = \text{pr}_i(u) + \text{pr}_i(v)$$
$$\text{pr}_i(\lambda u) = \text{pr}_i((\lambda u_1, ..., \lambda u_p)) = \lambda u_i = \lambda \text{pr}_i(u)$$
Portanto, $\text{pr}_i$ é uma transformação linear. $\blacksquare$

**Definição:** As **injeções** $in_i: E_i \rightarrow E_1 \times ... \times E_p$ são definidas por $in_i(u_i) = (0, ..., 0, u_i, 0, ..., 0)$, onde $u_i$ está na *i*-ésima posição [^4]. Estas injeções também são transformações lineares.

**Proposição:** As injeções $in_i$ são lineares.

*Prova:* Para mostrar que $in_i$ é linear, devemos verificar que $in_i(u + v) = in_i(u) + in_i(v)$ e $in_i(\lambda u) = \lambda in_i(u)$ para todos os vetores $u, v \in E_i$ e escalar $\lambda \in K$. Então:
$$in_i(u + v) = (0, ..., 0, u + v, 0, ..., 0) = (0, ..., 0, u, 0, ..., 0) + (0, ..., 0, v, 0, ..., 0) = in_i(u) + in_i(v)$$
$$in_i(\lambda u) = (0, ..., 0, \lambda u, 0, ..., 0) = \lambda (0, ..., 0, u, 0, ..., 0) = \lambda in_i(u)$$
Portanto, $in_i$ é uma transformação linear. $\blacksquare$

**Proposição:** Se $dim(E_i) = n_i$, então $dim(E_1 \times ... \times E_p) = n_1 + ... + n_p$ [^4].

*Prova:* Seja $B_i = \{e_{i1}, ..., e_{in_i}\}$ uma base para $E_i$. Então, uma base para $E_1 \times ... \times E_p$ é dada por o conjunto de vetores da forma $(0, ..., 0, e_{ij}, 0, ..., 0)$, onde $e_{ij}$ varia sobre todos os elementos de $B_i$ e $i$ varia de $1$ a $p$ [^4]. O número total de tais vetores é $n_1 + ... + n_p$. Portanto, a dimensão de $E_1 \times ... \times E_p$ é $n_1 + ... + n_p$. $\blacksquare$

### Conclusão

O produto direto oferece uma maneira fundamental de construir espaços vetoriais maiores a partir de espaços vetoriais menores. Este conceito, juntamente com a soma direta, fornece ferramentas essenciais para a decomposição e análise de espaços vetoriais complexos. O estudo das projeções e injeções associadas ao produto direto aprofunda a compreensão das relações entre os espaços vetoriais componentes e o espaço vetorial resultante.

### Referências
[^1]: Página 1, Capítulo 6
[^3]: Página 3, Capítulo 6
[^4]: Página 4, Capítulo 6
<!-- END -->