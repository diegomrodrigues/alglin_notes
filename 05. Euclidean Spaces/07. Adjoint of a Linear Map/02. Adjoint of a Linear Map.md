## Representação Matricial do Adjunto de uma Transformação Linear

### Introdução
Este capítulo visa explorar em detalhes a representação matricial do adjunto de uma transformação linear. Como vimos anteriormente [^453], o conceito de adjunto é crucial na análise de transformações lineares em espaços euclidianos, especialmente em contextos onde auto-adjuntos e diagonalização desempenham papéis fundamentais. Este capítulo se concentrará em demonstrar que a matriz que representa o adjunto $f^*$ de uma transformação linear $f$ é a transposta da matriz que representa $f$.

### Conceitos Fundamentais
Seja $E$ um espaço euclidiano de dimensão finita e $f: E \rightarrow E$ uma transformação linear [^453]. O adjunto de $f$, denotado por $f^*$, é a única transformação linear $f^*: E \rightarrow E$ que satisfaz a seguinte relação:
$$\
\langle f(u), v \rangle = \langle u, f^*(v) \rangle, \quad \forall u, v \in E
$$\
onde $\langle \cdot, \cdot \rangle$ denota o produto interno em $E$ [^438].

Para representar matricialmente $f$ e $f^*$, escolhemos uma base ortonormal $\mathcal{B} = \\{e_1, \dots, e_n\\}$ para $E$ [^439]. Seja $A$ a matriz que representa $f$ em relação a $\mathcal{B}$, ou seja, $A = (a_{ij})$ onde $f(e_j) = \sum_{i=1}^n a_{ij}e_i$. Similarmente, seja $B = (b_{ij})$ a matriz que representa $f^*$ em relação a $\mathcal{B}$, ou seja, $f^*(e_j) = \sum_{i=1}^n b_{ij}e_i$ [^440].

Agora, vamos demonstrar que $B = A^T$, ou seja, $b_{ij} = a_{ji}$ para todos $i, j$. Usando a definição do adjunto, temos:
$$\
\langle f(e_j), e_i \rangle = \langle e_j, f^*(e_i) \rangle
$$\
Substituindo as representações matriciais de $f(e_j)$ e $f^*(e_i)$, obtemos:
$$\
\left\langle \sum_{k=1}^n a_{kj} e_k, e_i \right\rangle = \left\langle e_j, \sum_{k=1}^n b_{ki} e_k \right\rangle
$$\
Como $\mathcal{B}$ é uma base ortonormal, temos $\langle e_k, e_i \rangle = \delta_{ki}$, onde $\delta_{ki}$ é o delta de Kronecker [^447]. Portanto,
$$\
\sum_{k=1}^n a_{kj} \langle e_k, e_i \rangle = \sum_{k=1}^n b_{ki} \langle e_j, e_k \rangle
$$\
$$\
\sum_{k=1}^n a_{kj} \delta_{ki} = \sum_{k=1}^n b_{ki} \delta_{jk}
$$\
$$\
a_{ij} = b_{ji}
$$\
Esta igualdade mostra que a entrada $(i, j)$ da matriz $A$ é igual à entrada $(j, i)$ da matriz $B$. Portanto, $B = A^T$, ou seja, a matriz que representa o adjunto $f^*$ é a transposta da matriz que representa $f$ [^441].

**Lema 1:** Se $f: E \rightarrow E$ é uma transformação linear e $A$ é a matriz que representa $f$ em relação a uma base ortonormal, então a matriz que representa $f^*$ é $A^T$.

*Prova:* Já demonstrada acima. $\blacksquare$

**Corolário 1:** Se $f$ é auto-adjunta (i.e., $f = f^*$), então a matriz $A$ que representa $f$ em relação a uma base ortonormal é simétrica (i.e., $A = A^T$).

*Prova:* Se $f = f^*$, então $A = A^T$ pela demonstração acima. Portanto, $A$ é simétrica. $\blacksquare$

**Exemplo:**
Considere a transformação linear $f: \mathbb{R}^2 \rightarrow \mathbb{R}^2$ definida por $f(x, y) = (2x + y, x - 3y)$. A matriz que representa $f$ na base canônica é:
$$\
A = \begin{pmatrix} 2 & 1 \\\\ 1 & -3 \end{pmatrix}
$$\
Como a base canônica é ortonormal, a matriz que representa o adjunto $f^*$ é simplesmente a transposta de $A$:
$$\
A^T = \begin{pmatrix} 2 & 1 \\\\ 1 & -3 \end{pmatrix}
$$\
Neste caso, $A = A^T$, o que significa que $f$ é auto-adjunta.

### Conclusão
Neste capítulo, demonstramos rigorosamente que a matriz que representa o adjunto de uma transformação linear em relação a uma base ortonormal é a transposta da matriz que representa a transformação original [^454]. Este resultado é fundamental para a compreensão e manipulação de transformações lineares em espaços euclidianos [^455], e tem implicações importantes em diversas áreas, como a solução de problemas em mecânica e engenharia [^453], e na diagonalização de operadores auto-adjuntos [^455]. A representação matricial do adjunto simplifica muitos cálculos e fornece uma ferramenta poderosa para a análise de transformações lineares [^456].

### Referências
[^438]: Definition 12.1. A Euclidean space is a real vector space E equipped with a symmetric bilinear formy: E × E → R that is positive definite.
[^439]: Example 12.2. For instance, let E be a vector space of dimension 2, and let (e1,62) be a basis of E.
[^440]: If E is finite-dimensional and if 6: E × E → R is a bilinear form on E, given any basis (e1,..., en) of E, we can write x = ∑i=1xiei and y = ∑j=1 Yjej, and we have φ(x, y) = φ(Σi=1Xili, Σj=1Yjej ) = ∑i,j=1 xiyjφ(ei, ej).
[^441]: Proposition 12.2. Let E be a finite-dimensional vector space, and let (e1, . . ., en) be a basis of E.
[^453]: The existence of the isomorphism b: E → E* is crucial to the existence of adjoint maps. The importance of adjoint maps stems from the fact that the linear maps arising in physical problems are often self-adjoint, which means that f = f*.
[^454]: Definition 12.4. Given a Euclidean space E of finite dimension, for every linear map f: E → E, the unique linear map f*: E → E such that f*(u) · v = u · f(v), for all u, v ∈ Ε given by Proposition 12.8 is called the adjoint of f (w.r.t. to the inner product).
[^455]: Linear maps such that f-1 = f*, or equivalently f* o f = f 0 f* = id, also play an important role. They are linear isometries, or isometries. Rotations are special kinds of isometries.
[^456]: Proposition 12.9. Given any nontrivial Euclidean space E of finite dimension n ≥ 1, there is an orthonormal basis (u1,..., Un) for E.
[^447]: Definition 12.2. Given a Euclidean space E, any two vectors u, v ∈ E are orthogonal, or perpendicular, if u · v = 0. Given a family (ui)ier of vectors in E, we say that (ui)iel is orthogonal if Uz · Uj = 0 for all i, j ∈ I, where i ≠ j.

<!-- END -->