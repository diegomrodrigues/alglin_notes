## Capítulo 3.6: Multiplicação de Matrizes e suas Propriedades Algébricas

### Introdução

Em continuidade à nossa exploração de espaços vetoriais, bases e mapas lineares iniciada no Capítulo 3 [^2, ^3, ^12], este capítulo foca em uma operação fundamental: a **multiplicação de matrizes**. Como vimos na Seção 3.1, matrizes surgem naturalmente na representação de sistemas de equações lineares [^4, ^5] e, crucialmente, como forma de expressar **mapas lineares** entre espaços vetoriais [^6]. A operação de multiplicação de matrizes, embora talvez não intuitiva à primeira vista, é definida precisamente para capturar a composição desses mapas lineares, uma conexão que será explorada mais profundamente em capítulos subsequentes.

Este capítulo detalhará a definição formal da multiplicação de matrizes, suas interpretações e suas propriedades algébricas fundamentais, baseando-se exclusivamente nas definições e conceitos introduzidos anteriormente no contexto de espaços vetoriais, como combinações lineares [^2, ^3, ^15], o produto interno [^6, ^7] e a estrutura de M<sub>m,n</sub>(K) como um espaço vetorial [^29].

### Conceitos Fundamentais

#### Definição Formal de Multiplicação de Matrizes

Conforme introduzido na Seção 3.1 [^7] e formalizado na Definição 3.13 [^25] e subsequente [^26], a multiplicação de matrizes é definida da seguinte maneira:

> Dado uma matriz $A = (a_{ik})$ de dimensões $m \times n$ e uma matriz $B = (b_{kj})$ de dimensões $n \times p$, seu produto $AB$ é a matriz $C = (c_{ij})$ de dimensões $m \times p$ tal que a entrada na linha $i$ e coluna $j$ é dada por:
> $$ c_{ij} = \sum_{k=1}^{n} a_{ik} b_{kj} $$
> para $1 \leq i \leq m$ e $1 \leq j \leq p$ [^1, ^7, ^26].

É crucial notar que para o produto $AB$ ser definido, o número de colunas da matriz $A$ deve ser igual ao número de linhas da matriz $B$. O resultado é uma matriz com o número de linhas de $A$ e o número de colunas de $B$.

#### Interpretações da Multiplicação de Matrizes

O contexto nos fornece múltiplas maneiras de interpretar o produto matricial:

1.  **Interpretação via Colunas:** Se $A$ é uma matriz $m \times n$ e $B$ é uma matriz $n \times p$ com colunas $B^1, B^2, \dots, B^p$ (vetores em $\mathbb{R}^n$), então o produto $AB$ é a matriz $m \times p$ cuja $j$-ésima coluna é o resultado da aplicação da transformação representada por $A$ à $j$-ésima coluna de $B$, ou seja, a $j$-ésima coluna de $AB$ é o vetor $AB^j$ (um vetor em $\mathbb{R}^m$) [^7].

2.  **Interpretação via Linha-Coluna (Produto Interno):** A definição $c_{ij} = \sum_{k=1}^{n} a_{ik} b_{kj}$ pode ser vista como o **produto interno** (inner product), conforme definido em [^6, ^7], da $i$-ésima linha da matriz $A$ (vista como um vetor linha) pela $j$-ésima coluna da matriz $B$ (vista como um vetor coluna) [^6, ^7, ^26].

3.  **Multiplicação Matriz-Vetor como Combinação Linear:** Um caso especial importante é a multiplicação de uma matriz $A$ ($m \times n$) por um vetor coluna $x$ ($n \times 1$). Como visto em [^5, ^6], o produto $Ax$ pode ser interpretado como uma **combinação linear** das colunas de $A$, $A^1, \dots, A^n$, com os coeficientes dados pelas entradas do vetor $x$:\
    $$ Ax = x_1 A^1 + x_2 A^2 + \dots + x_n A^n $$
    onde $x = (x_1, \dots, x_n)^T$ [^6]. A $i$-ésima coordenada de $Ax$ é dada pelo produto interno da $i$-ésima linha de $A$ com o vetor $x$ [^6].

#### Propriedades Algébricas da Multiplicação de Matrizes

A multiplicação de matrizes possui propriedades algébricas cruciais, detalhadas na Proposição 3.16 [^30]:

1.  **Associatividade:** Para matrizes $A \in M_{m,n}(K)$, $B \in M_{n,p}(K)$, e $C \in M_{p,q}(K)$, a propriedade associativa se mantém:
    $$ (AB)C = A(BC) $$
    Esta propriedade é fundamental, pois garante que a ordem de multiplicação em produtos mais longos não afeta o resultado final [^30].

2.  **Bilinearidade:** A multiplicação de matrizes é bilinear. Isso significa que ela distribui sobre a adição de matrizes e comuta com a multiplicação escalar:
    *   $(A + B)C = AC + BC$
    *   $A(C + D) = AC + AD$
    *   $(\lambda A)C = \lambda(AC) = A(\lambda C)$
    para matrizes $A, B \in M_{m,n}(K)$, $C, D \in M_{n,p}(K)$ e escalar $\lambda \in K$ [^30]. Juntamente com a adição de matrizes e multiplicação por escalar [^25, ^26], essas propriedades confirmam que a multiplicação de matrizes interage de forma consistente com a estrutura de espaço vetorial de $M_{m,n}(K)$ [^29].

3.  **Não Comutatividade:** Uma das propriedades mais distintas da multiplicação de matrizes é que ela, em geral, **não é comutativa** [^1]. Ou seja, para matrizes quadradas $A, B \in M_n(K)$, geralmente temos $AB \neq BA$ [^7, ^30]. O Exemplo 3.5 [^30] ilustra isso com:
    $A = \begin{pmatrix} 1 & 0 \\\\ 0 & 0 \end{pmatrix}$, $B = \begin{pmatrix} 0 & 0 \\\\ 1 & 0 \end{pmatrix}$.
    Neste caso, $AB = \begin{pmatrix} 0 & 0 \\\\ 0 & 0 \end{pmatrix}$, enquanto $BA = \begin{pmatrix} 0 & 0 \\\\ 1 & 0 \end{pmatrix}$. Isso também demonstra a existência de **divisores de zero** no anel de matrizes $M_n(K)$ ($AB=0$ com $A \neq 0$ e $B \neq 0$) [^30].

4.  **Matriz Identidade:** Para matrizes quadradas de dimensão $n$, a **matriz identidade** $I_n$, definida como a matriz com 1s na diagonal principal e 0s fora dela [^8, ^26], atua como elemento neutro para a multiplicação:
    $$ AI_n = A \quad \text{e} \quad I_n A = A $$
    para qualquer $A \in M_n(K)$ [^27].

5.  **Matriz Inversa:** Para uma matriz quadrada $A \in M_n(K)$, sua **inversa**, denotada por $A^{-1}$, é uma matriz única (se existir) tal que:
    $$ AA^{-1} = A^{-1}A = I_n $$
    Uma matriz que possui inversa é chamada **invertível** ou **não singular**; caso contrário, é chamada **singular** [^8, ^27]. A existência da inversa está intimamente ligada à independência linear das colunas de A (Proposição 3.14 [^28]), à condição de que $Ax=0$ implica $x=0$ (Proposição 3.15 [^29]), e ao determinante ser não nulo [^8]. A Proposição 3.13 [^27] estabelece que a existência de uma inversa à esquerda ou à direita é suficiente para garantir a invertibilidade de uma matriz quadrada. Além disso, se A e B são invertíveis, então AB também é, e $(AB)^{-1} = B^{-1}A^{-1}$ [^28].

6.  **Matriz Transposta:** A **transposta** de uma matriz $A = (a_{ij}) \in M_{m,n}(K)$ é a matriz $A^T = (a^T_{ji}) \in M_{n,m}(K)$ onde $a^T_{ji} = a_{ij}$ [^9, ^26]. Essencialmente, as linhas de $A^T$ são as colunas de $A$, e vice-versa [^27]. O contexto fornece a definição [^9, ^26] e um exemplo [^27], mas não explora propriedades como $(AB)^T = B^T A^T$.

#### Conexão com Mapas Lineares

Como mencionado na introdução e sugerido em [^6], a multiplicação de matrizes está intrinsecamente ligada aos **mapas lineares** [^31]. A matriz $A$ pode ser vista como a representação de um mapa linear $f_A: K^n \to K^m$ tal que $f_A(x) = Ax$. A multiplicação de matrizes $AB$ corresponde à composição dos mapas lineares $f_A \circ f_B$. As propriedades algébricas da multiplicação de matrizes, como associatividade, refletem propriedades análogas da composição de funções (mapas lineares). O conjunto das matrizes quadradas $M_n(K)$ forma um anel não comutativo com unidade $I_n$ [^30], que é fundamental na álgebra linear e suas aplicações.

### Conclusão

A multiplicação de matrizes é uma operação central na álgebra linear, servindo como a ponte algébrica para a composição de transformações lineares. Sua definição, $ (AB)_{ij} = \sum_k a_{ik} b_{kj} $ [^1, ^7, ^26], permite múltiplas interpretações úteis, incluindo a transformação de vetores coluna [^7], o produto interno de linhas por colunas [^6, ^7, ^26] e a formação de combinações lineares das colunas [^6]. Apesar de suas propriedades algébricas familiares como associatividade e bilinearidade [^30], a característica marcante da não comutatividade ($AB \neq BA$ em geral [^7, ^30]) distingue a álgebra de matrizes da álgebra de números reais ou complexos. A existência de elementos neutro (identidade $I_n$ [^27]) e inverso ($A^{-1}$ [^27]), quando aplicável, enriquece a estrutura algébrica, formando o grupo linear geral $GL(n, K)$ de matrizes invertíveis (mencionado em Definição 3.24 [^35] no contexto de automorfismos). Esta operação é indispensável para a análise e solução de sistemas lineares [^5, ^8], a representação de mapas lineares [^6, ^31] e algoritmos avançados como SVD [^9] e compressão de dados [^11].

### Referências

[^1]: Contexto inicial fornecido pelo usuário sobre a definição de multiplicação de matrizes.
[^2]: OCR Page 1 (p. 49) - Introdução a vetores, combinações lineares, sistemas lineares.
[^3]: OCR Page 2 (p. 50) - Definição de vetores coluna/linha, independência linear, combinação linear única.
[^4]: OCR Page 3 (p. 51) - Determinante para independência linear, matriz A como colunas (u v w).
[^5]: OCR Page 4 (p. 52) - Combinação linear como Ax, sistema como Ax=b, dependência linear e soluções.
[^6]: OCR Page 5 (p. 53) - Mapa x -> Ax como transformação linear, propriedades, Ax como combinação linear de colunas, interpretação via produto interno linha-coluna.
[^7]: OCR Page 6 (p. 54) - Produto interno, definição de AB via colunas (ABʲ), definição via produto interno linha-coluna (Σ aᵢₖbₖⱼ), não comutatividade.
[^8]: OCR Page 7 (p. 55) - Matriz inversa A⁻¹, identidade Iₙ, BA=Iₙ => AB=Iₙ, invertível/singular, equivalências (colunas L.I., det ≠ 0).
[^9]: OCR Page 8 (p. 56) - Transposta Aᵀ, matriz ortogonal, SVD, pseudo-inversa.
[^10]: OCR Page 9 (p. 57) - Interpretação geométrica de Ax=b.
[^11]: OCR Page 12 (p. 60) - Compressão de dados, low-rank decomposition A ≈ BC.
[^12]: OCR Page 14 (p. 62) - Definição formal de Espaço Vetorial (Def 3.1).
[^13]: OCR Page 15 (p. 63) - Exemplos de Espaços Vetoriais (incluindo Matrizes M<sub>m,n</sub>(R)).
[^14]: OCR Pages 16-21 (pp. 64-69) - Famílias indexadas, notação de soma Σ.
[^15]: OCR Page 23 (p. 71) - Definição de combinação linear e independência linear para famílias (Def 3.3).
[^16]: OCR Page 25 (p. 73) & Page 27 (p. 75) - Definição de subespaço (Def 3.4), Span(S) (Prop 3.5).
[^17]: OCR Page 28 (p. 76) - Combinações afins, cônicas, convexas, famílias de suporte finito (Def 3.5).
[^18]: OCR Page 29 (p. 77) - Definição de Base (Def 3.6).
[^19]: OCR Page 29 (p. 77) & Page 30 (p. 78) - Lemma 3.6, Teorema 3.7 (Existência de base).
[^20]: OCR Page 30 (p. 78) - Definição 3.7 (Família maximal L.I., minimal geradora), Proposição 3.8.
[^21]: OCR Page 31 (p. 79) & Page 33 (p. 81) - Lemma de Substituição (Props 3.9, 3.10).
[^22]: OCR Page 34 (p. 82) & Page 35 (p. 83) - Teorema 3.11 (Dimensão), Definição 3.8 (Dimensão), Definição 3.9 (Linha, plano, hiperplano).
[^23]: OCR Page 35 (p. 83) - Proposição 3.12 (Unicidade das coordenadas).
[^24]: OCR Page 36 (p. 84) - Espaço K⁽ᴵ⁾, base canônica, introdução da Seção 3.6 Matrizes.
[^25]: OCR Page 37 (p. 85) - Definição formal de Matriz (Def 3.12), M<sub>m,n</sub>(K), M<sub>n</sub>(K), Adição de Matrizes (Def 3.13).
[^26]: OCR Page 38 (p. 86) - Multiplicação por escalar λA, Produto AB (Definição Σ aᵢₖbₖⱼ), interpretação linha-coluna, Matriz Identidade Iₙ (Def 3.14), Transposta Aᵀ (Def 3.15).
[^27]: OCR Page 39 (p. 87) - Exemplo de transposta, AB = Σ AⁱBᵢ, Matriz Inversa A⁻¹ (Def 3.16), invertível/singular, Prop 3.13 (inversa lateral).
[^28]: OCR Page 40 (p. 88) - Prova Prop 3.13, (AB)⁻¹ = B⁻¹A⁻¹, Prop 3.14 (invertível <=> colunas L.I.).
[^29]: OCR Page 41 (p. 89) - Prop 3.15 (invertível <=> Ax=0 => x=0), M<sub>m,n</sub>(K) é espaço vetorial, Base Eᵢⱼ (Def 3.17), dimensão mn, menção a módulos.
[^30]: OCR Page 42 (p. 90) - Prop 3.16 (Associatividade, Bilinearidade), M<sub>n</sub>(K) é anel não comutativo com divisores de zero (Exemplo 3.5).
[^31]: OCR Page 43 (p. 91) - Definição de Mapa Linear (Def 3.18).
[^32]: OCR Page 44 (p. 92) - Definição de Imagem e Kernel (Def 3.19), Prop 3.17 (propriedades Im/Ker).
[^33]: OCR Page 45 (p. 93) - Definição de Rank (Def 3.20).
[^34]: OCR Page 45 (p. 93) - Proposição 3.18 (Extensão homomórfica única).
[^35]: OCR Page 48 (p. 96) & Page 49 (p. 97) - Definição de Isomorfismo (Def 3.21), Automorphism, Grupo Linear GL(E) (Def 3.24).
[^36]: OCR Page 51 (p. 99) - Introdução a Espaços Quociente (Seção 3.8).
[^37]: OCR Page 52 (p. 100) - Formas Lineares, Espaço Dual E* (Def 3.26).
[^38]: OCR Page 54 (p. 102) - Forma Coordenada, Base Dual (Def 3.27, Teorema 3.23).
[^39]: OCR Page 55 (p. 103) - Sumário do Capítulo 3.
[^40]: OCR Page 56 (p. 104) - Início da seção de Problemas.

<!-- END -->