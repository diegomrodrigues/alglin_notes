## Inversas Unilaterais e Isomorfismos de Aplicações Lineares em Dimensão Finita

### Introdução

No estudo de espaços vetoriais, bases e aplicações lineares, como detalhado ao longo deste capítulo [^1], um ponto fundamental é a compreensão das propriedades estruturais preservadas por essas aplicações. Definimos uma **aplicação linear** $f: E \\to F$ como uma função que satisfaz $f(x + y) = f(x) + f(y)$ e $f(\\lambda x) = \\lambda f(x)$ [^43]. Um tipo particular de aplicação linear de grande interesse são os **isomorfismos**, que são aplicações lineares bijetivas entre dois espaços vetoriais [^48]. A existência de um isomorfismo entre $E$ e $F$ implica que eles são estruturalmente idênticos como espaços vetoriais. Uma questão natural que surge é: sob quais condições podemos garantir que uma aplicação linear é um isomorfismo?

Expandindo os conceitos apresentados anteriormente sobre inversas de matrizes [^7, ^39] e suas conexões com a resolução de sistemas lineares [^7] e a independência linear das colunas [^40], investigaremos agora uma propriedade análoga para aplicações lineares. Especificamente, este capítulo foca na Proposição 3.21 [^49], que estabelece uma condição suficiente notável para que uma aplicação linear $f: E \\to E$, onde $E$ é um espaço vetorial de dimensão finita, seja um isomorfismo. Demonstraremos que a mera existência de uma **inversa à esquerda** ou uma **inversa à direita** para $f$ é suficiente para garantir que $f$ seja bijetiva e, portanto, um isomorfismo. Este resultado destaca uma característica importante dos espaços vetoriais de dimensão finita [^34, ^49].

### Conceitos Fundamentais e Prova da Proposição 3.21

Relembremos que, conforme a Definição 3.21 [^48], uma aplicação linear $f: E \\to F$ é um isomorfismo se existe uma aplicação linear $g: F \\to E$ tal que $g \\circ f = \\text{id}_E$ e $f \\circ g = \\text{id}_F$. A aplicação $g$ é única e denominada a **inversa** de $f$, denotada por $f^{-1}$ [^49].

A Proposição 3.21 [^49] considera o caso especial em que $E=F$ e $E$ tem dimensão finita $n \\ge 1$. Ela afirma o seguinte:

> **Proposição 3.21.** Seja $E$ um espaço vetorial de dimensão finita $n \\ge 1$ e seja $f : E \\to E$ uma aplicação linear qualquer. As seguintes propriedades são válidas:
> (1) Se $f$ possui uma **inversa à esquerda** $g$, isto é, se $g$ é uma aplicação linear tal que $g \\circ f = \\text{id}$, então $f$ é um isomorfismo e $f^{-1} = g$. [^49]
> (2) Se $f$ possui uma **inversa à direita** $h$, isto é, se $h$ é uma aplicação linear tal que $f \\circ h = \\text{id}$, então $f$ é um isomorfismo e $f^{-1} = h$. [^49]

**Prova:**

(1) Suponha que existe uma aplicação linear $g: E \\to E$ tal que $g \\circ f = \\text{id}$.
Primeiro, mostramos que $f$ é **injetiva**. Se $f(x) = f(y)$ para quaisquer $x, y \\in E$, então aplicando $g$ a ambos os lados, obtemos $g(f(x)) = g(f(y))$. Como $g \\circ f = \\text{id}$, isso implica $\\text{id}(x) = \\text{id}(y)$, ou seja, $x = y$. Portanto, $f$ é injetiva [^50].
Agora, seja $(u_1, \\dots, u_n)$ uma base de $E$ [^29, ^35]. Como $f$ é injetiva, a Proposição 3.18 [^45, ^46] garante que a família $(f(u_1), \\dots, f(u_n))$ é linearmente independente em $E$. Uma vez que $E$ tem dimensão $n$ [^35, ^49], qualquer família de $n$ vetores linearmente independentes forma uma base para $E$ (uma consequência do Teorema 3.11 [^34] e da Proposição 3.8 [^30]). Portanto, $(f(u_1), \\dots, f(u_n))$ é uma base de $E$ [^50].
O fato de $(f(u_1), \\dots, f(u_n))$ ser uma base de $E$ implica que $f$ também é **surjetiva**. Isso ocorre porque qualquer vetor $v \\in E$ pode ser escrito como uma combinação linear da base $(f(u_1), \\dots, f(u_n))$, digamos $v = \\sum_{i=1}^n \\lambda_i f(u_i)$. Pela linearidade de $f$ [^43], $v = f(\\sum_{i=1}^n \\lambda_i u_i)$. Como $\\sum_{i=1}^n \\lambda_i u_i$ está em $E$, mostramos que para todo $v \\in E$, existe um elemento em $E$ (neste caso, $\\sum \\lambda_i u_i$) cuja imagem sob $f$ é $v$. Alternativamente, a Proposição 3.18 [^45] afirma que se a imagem de uma base gera o espaço de chegada, a aplicação é surjetiva.
Como $f$ é injetiva e surjetiva, ela é bijetiva. Sendo uma aplicação linear bijetiva, $f$ é um isomorfismo [^48, ^49]. Sua inversa, $f^{-1}$, existe e é também uma aplicação linear [^49].
Para mostrar que $g = f^{-1}$, usamos a existência de $f^{-1}$ e a hipótese $g \\circ f = \\text{id}$:\n$$ g = g \\circ \\text{id} = g \\circ (f \\circ f^{-1}) = (g \\circ f) \\circ f^{-1} = \\text{id} \\circ f^{-1} = f^{-1} $$\n[^50]. Isso completa a prova da parte (1).

(2) Suponha que existe uma aplicação linear $h: E \\to E$ tal que $f \\circ h = \\text{id}$.
Primeiro, mostramos que $f$ é **surjetiva**. Para qualquer $y \\in E$, considere $x = h(y)$. Então $f(x) = f(h(y)) = (f \\circ h)(y) = \\text{id}(y) = y$. Isso mostra que todo elemento $y$ no contradomínio $E$ é a imagem de algum elemento $x$ no domínio $E$, logo $f$ é surjetiva [^50].
Seja $(u_1, \\dots, u_n)$ uma base de $E$ [^29, ^35]. Como $f$ é surjetiva, a Proposição 3.18 [^45, ^46] implica que a família $(f(u_1), \\dots, f(u_n))$ gera $E$. Como $E$ tem dimensão $n$ [^35, ^49], qualquer família geradora com $n$ vetores deve ser linearmente independente (caso contrário, conteria uma base com menos de $n$ vetores após remover vetores dependentes, contradizendo o Teorema 3.11 [^34] que afirma que todas as bases têm a mesma dimensão $n$). Assim, $(f(u_1), \\dots, f(u_n))$ é uma base de $E$ [^50]. (A prova em [^50] argumenta que se não fosse linearmente independente, conteria uma base com dimensão estritamente menor que $n$, contradizendo o Teorema 3.11, dado que ela gera $E$).
O fato de $(f(u_1), \\dots, f(u_n))$ ser uma base implica que $f$ também é **injetiva**. Se $f(x)=0$, escrevemos $x = \\sum \\lambda_i u_i$. Então $f(x) = \\sum \\lambda_i f(u_i) = 0$. Como $(f(u_1), \\dots, f(u_n))$ é uma base, ela é linearmente independente [^23], o que força $\\lambda_i = 0$ para todo $i$. Logo, $x=0$. Pela Proposição 3.17 [^44], $f$ é injetiva se e somente se $\\text{Ker } f = \\{0\\}$.
Como $f$ é injetiva e surjetiva, ela é bijetiva. Sendo uma aplicação linear bijetiva, $f$ é um isomorfismo [^48, ^49]. Sua inversa $f^{-1}$ existe e é uma aplicação linear [^49].
Para mostrar que $h = f^{-1}$, usamos a existência de $f^{-1}$ e a hipótese $f \\circ h = \\text{id}$:\n$$ h = \\text{id} \\circ h = (f^{-1} \\circ f) \\circ h = f^{-1} \\circ (f \\circ h) = f^{-1} \\circ \\text{id} = f^{-1} $$\n[^50]. Isso completa a prova da parte (2).
$\\blacksquare$

### Conclusão

A Proposição 3.21 [^49] revela uma propriedade poderosa das aplicações lineares em espaços vetoriais de dimensão finita. Ao contrário do caso geral de funções ou de aplicações lineares em espaços de dimensão infinita, a existência de uma inversa unilateral (à esquerda ou à direita) para uma aplicação linear $f: E \\to E$ é suficiente para garantir que a aplicação seja um isomorfismo. A prova [^50] depende crucialmente das propriedades das bases [^29] em espaços de dimensão finita, particularmente o Teorema 3.11 [^34], que garante que todas as bases têm o mesmo número de elementos (a dimensão), e que $n$ vetores linearmente independentes ou $n$ vetores geradores em um espaço de dimensão $n$ formam necessariamente uma base. Este resultado simplifica a verificação de isomorfismos em muitos contextos, conectando elegantemente os conceitos de invertibilidade unilateral, bases e a estrutura fundamental dos espaços vetoriais finito-dimensionais explorados neste capítulo [^1].

### Referências

[^1]: Chapter 3: Vector Spaces, Bases, Linear Maps
[^2]: Page 50: Discussão sobre combinações lineares e independência linear.
[^4]: Page 52: Definição de dependência linear e exemplo.
[^5]: Page 53: Aplicação linear $x \\mapsto Ax$ e suas propriedades.
[^7]: Page 55: Matriz inversa $A^{-1}$ e sua relação com sistemas lineares e invertibilidade.
[^13]: Page 61: Introdução formal aos espaços vetoriais.
[^14]: Page 62: Definição formal de espaço vetorial (Definição 3.1) e suas propriedades axiomáticas.
[^15]: Page 63: Exemplos de espaços vetoriais.
[^23]: Page 71: Definição de combinação linear e independência/dependência linear para famílias de vetores (Definição 3.3).
[^24]: Page 72: Discussão sobre independência/dependência linear de famílias.
[^29]: Page 77: Definição de base de um espaço vetorial (Definição 3.6).
[^30]: Page 78: Definição de família maximalmente linearmente independente e família geradora minimal (Definição 3.7).
[^31]: Page 79: Proposição 3.8 caracterizando bases.
[^34]: Page 82: Teorema 3.11 (Teorema Fundamental sobre bases em dimensão finita).
[^35]: Page 83: Definição de dimensão de um espaço vetorial (Definição 3.8) e conceitos relacionados (reta, plano, hiperplano - Definição 3.9). Proposição 3.12 sobre unicidade de coordenadas.
[^39]: Page 87: Definição de matriz inversa $A^{-1}$ (Definição 3.16) e Proposição 3.13 sobre inversas unilaterais de matrizes.
[^40]: Page 88: Prova da Proposição 3.13 e Proposição 3.14 (matriz invertível sse colunas L.I.).
[^43]: Page 91: Definição de aplicação linear (Definição 3.18).
[^44]: Page 92: Definição de Imagem e Kernel (Definição 3.19) e Proposição 3.17 (injetividade sse Ker f = {0}).
[^45]: Page 93: Definição de Rank (Definição 3.20) e Proposição 3.18 (extensão única, propriedades de injetividade/surjetividade).
[^46]: Page 94: Discussão da Proposição 3.18 e suas consequências para bases e isomorfismos.
[^48]: Page 96: Definição de isomorfismo de aplicações lineares (Definição 3.21).
[^49]: Page 97: Definição da inversa $f^{-1}$ e enunciado da Proposição 3.21 sobre inversas unilaterais.
[^50]: Page 98: Prova da Proposição 3.21.

<!-- END -->