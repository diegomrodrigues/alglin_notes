## Capítulo 4: Isomorfismos Lineares e a Preservação de Bases

### Introdução

Nos capítulos anteriores, exploramos os conceitos fundamentais de **espaços vetoriais** [^14], **bases** [^29] e **aplicações lineares** [^50]. Estabelecemos que uma base fornece uma representação única e eficiente para todos os vetores em um espaço vetorial [^37], servindo como a espinha dorsal estrutural do espaço. As aplicações lineares, por sua vez, foram introduzidas como funções que preservam a estrutura do espaço vetorial, transformando combinações lineares em combinações lineares [^50]. Um tipo particular de aplicação linear, o **isomorfismo** [^57], representa uma correspondência estrutural completa entre dois espaços vetoriais. Como mencionado brevemente na discussão da Proposição 3.18 [^58], uma propriedade crucial dos isomorfismos é sua capacidade de mapear bases em bases. Este capítulo aprofundará essa propriedade fundamental, demonstrando formalmente como um isomorfismo $f: E \\to F$ transforma uma base de $E$ em uma base de $F$. Compreender essa preservação é *essencial para entender como aplicações lineares transformam bases* e, consequentemente, como as representações de vetores mudam sob transformações lineares estruturalmente equivalentes.

### Preservação de Bases sob Isomorfismos

Iniciamos formalizando a propriedade central deste capítulo, que conecta diretamente a noção de isomorfismo com a estrutura fundamental das bases.

> **Proposição 4.1:** Seja $f: E \\to F$ uma aplicação linear entre dois espaços vetoriais $E$ e $F$ sobre um corpo $K$. Se $(u_i)_{i \\in I}$ é uma base de $E$ e $f$ é um **isomorfismo**, então a família $(f(u_i))_{i \\in I}$ é uma base de $F$.

**Demonstração:**

Para provar que a família $(f(u_i))_{i \\in I}$ é uma base de $F$, precisamos demonstrar duas condições, conforme a Definição 3.6 [^29]:
1.  A família $(f(u_i))_{i \\in I}$ é **linearmente independente** em $F$.
2.  A família $(f(u_i))_{i \\in I}$ **gera** o espaço vetorial $F$.

**(1) Linear Independência:**

Consideremos uma combinação linear finita da família $(f(u_i))_{i \\in I}$ que resulta no vetor nulo de $F$. Seja $J \\subseteq I$ um subconjunto finito de índices e $(\\lambda_j)_{j \\in J}$ uma família de escalares em $K$ tal que:
$$ \\sum_{j \\in J} \\lambda_j f(u_j) = 0_F $$
Como $f$ é uma aplicação linear (Definição 3.18 [^50]), ela preserva combinações lineares. Portanto, podemos reescrever a equação acima como:
$$ f\\left(\\sum_{j \\in J} \\lambda_j u_j\\right) = 0_F $$
Esta equação significa que o vetor $x = \\sum_{j \\in J} \\lambda_j u_j$ pertence ao **kernel** de $f$, denotado por Ker $f$ [^51].
Um isomorfismo, por definição (Definição 3.21 [^57]), é uma aplicação linear bijetiva. Em particular, $f$ é injetiva. Como vimos na Proposição 3.17 [^53], uma aplicação linear é injetiva se, e somente se, seu kernel é o subespaço trivial, ou seja, Ker $f = \\{0_E\\}$.
Portanto, da equação $f(x) = 0_F$, concluímos que $x = 0_E$. Isso implica:
$$ \\sum_{j \\in J} \\lambda_j u_j = 0_E $$
Agora, por hipótese, a família $(u_i)_{i \\in I}$ é uma base de $E$. Uma das propriedades definidoras de uma base é que ela é linearmente independente [^29]. A condição de independência linear (Definição 3.3 [^23]) aplicada à equação acima implica que todos os escalares $\\lambda_j$ devem ser nulos, i.e., $\\lambda_j = 0$ para todo $j \\in J$.
Como partimos de uma combinação linear genérica nula de $(f(u_i))_{i \\in I}$ e concluímos que todos os coeficientes devem ser zero, demonstramos que a família $(f(u_i))_{i \\in I}$ é linearmente independente em $F$.

**(2) Geração de F:**

Precisamos mostrar que qualquer vetor $y \\in F$ pode ser expresso como uma combinação linear (finita) de vetores da família $(f(u_i))_{i \\in I}$.
Seja $y$ um vetor arbitrário em $F$. Como $f: E \\to F$ é um isomorfismo, $f$ é sobrejetiva [^57]. A sobrejetividade significa que a imagem de $f$, Im $f = f(E)$, é igual a $F$ [^51]. Portanto, para qualquer $y \\in F$, existe (pelo menos) um vetor $x \\in E$ tal que $f(x) = y$.
Por hipótese, $(u_i)_{i \\in I}$ é uma base de $E$. Isso significa que a família $(u_i)_{i \\in I}$ gera $E$ [^29]. Assim, o vetor $x \\in E$ pode ser escrito como uma combinação linear (única e finita) dos vetores da base:
$$ x = \\sum_{j \\in J} \\lambda_j u_j $$
onde $J \\subseteq I$ é um subconjunto finito e $(\\lambda_j)_{j \\in J}$ são escalares em $K$.
Aplicando a aplicação linear $f$ a ambos os lados desta equação, obtemos:
$$ y = f(x) = f\\left(\\sum_{j \\in J} \\lambda_j u_j\\right) $$
Usando novamente a propriedade de linearidade de $f$ [^50]:
$$ y = \\sum_{j \\in J} \\lambda_j f(u_j) $$
Esta equação mostra que um vetor arbitrário $y \\in F$ pode ser expresso como uma combinação linear finita dos vetores da família $(f(u_i))_{i \\in I}$. Portanto, a família $(f(u_i))_{i \\in I}$ gera $F$.

Tendo demonstrado que a família $(f(u_i))_{i \\in I}$ é tanto linearmente independente quanto geradora de $F$, concluímos, pela Definição 3.6 [^29], que $(f(u_i))_{i \\in I}$ constitui uma base de $F$.
$\\blacksquare$

Esta proposição tem implicações significativas. Ela garante que a estrutura fundamental de um espaço vetorial, encapsulada por sua base, é preservada sob isomorfismos. Se dois espaços vetoriais $E$ e $F$ são isomorfos, eles compartilham a mesma "essência" linear-algébrica. Em particular, se $E$ tem dimensão finita $n$, qualquer base de $E$ terá $n$ elementos (Teorema 3.11 [^35]). A Proposição 4.1 garante que a imagem dessa base sob um isomorfismo $f: E \\to F$ será uma base de $F$, que também deve ter $n$ elementos. Isso corrobora o resultado fundamental de que dois espaços vetoriais de dimensão finita são isomorfos se, e somente se, eles têm a mesma dimensão. A preservação de bases é a manifestação concreta dessa equivalência estrutural no nível dos elementos geradores e linearmente independentes.

Como um corolário direto da Proposição 3.8 [^32] e da Proposição 4.1, se $f: E \\to F$ é um isomorfismo e $E, F$ têm dimensão finita $n$, então $f$ mapeia famílias linearmente independentes maximais de $E$ para famílias linearmente independentes maximais de $F$, e famílias geradoras minimais de $E$ para famílias geradoras minimais de $F$.

### Conclusão

Neste capítulo, demonstramos rigorosamente uma propriedade fundamental dos isomorfismos lineares: a preservação de bases. Vimos que se $f: E \\to F$ é um isomorfismo e $(u_i)_{i \\in I}$ é uma base de $E$, então a família imagem $(f(u_i))_{i \\in I}$ forma necessariamente uma base para $F$. A prova baseou-se nas propriedades definidoras de isomorfismos (bijetividade e linearidade [^57]), nas propriedades do kernel para aplicações injetivas [^53], e nas definições de base (independência linear e geração [^29]).

Esta propriedade solidifica a noção de que espaços vetoriais isomorfos são estruturalmente indistinguíveis do ponto de vista da álgebra linear. A capacidade de um isomorfismo de mapear bases em bases é crucial para entender como as coordenadas de vetores se transformam sob mudanças de base induzidas por aplicações lineares bijetivas e para estabelecer equivalências formais entre diferentes representações de espaços vetoriais, como entre um espaço vetorial $E$ de dimensão $n$ e o espaço $K^n$ [^58]. Este resultado é uma pedra angular na teoria dos espaços vetoriais e suas transformações.

### Referências

[^1]: Capítulo 3, Introdução a Vetores e Combinações Lineares (p. 49)
[^2]: Definição implícita de Combinação Linear (p. 50)
[^3]: Definição implícita de Independência Linear (p. 50)
[^4]: Cálculo de determinante para verificar independência linear (p. 51)
[^5]: Exemplo de dependência linear (p. 52)
[^6]: Relação entre sistemas lineares e combinações lineares (p. 53)
[^7]: Aplicação linear $x \\mapsto Ax$ (p. 53)
[^8]: Propriedades de linearidade da multiplicação matricial (p. 53)
[^9]: Definição de produto interno e norma Euclidiana (p. 54)
[^10]: Multiplicação de matrizes e produto interno (p. 54)
[^11]: Matriz Inversa e sistemas lineares (p. 55)
[^12]: Transposta e Matriz Ortogonal (p. 56)
[^13]: Decomposição SVD (p. 56)
[^14]: Definição 3.1: Espaço Vetorial (p. 62)
[^15]: Exemplo 3.1: Exemplos de Espaços Vetoriais (p. 63)
[^16]: Conjunto de funções como espaço vetorial (p. 64)
[^17]: Definição 3.2: Família Indexada (p. 65)
[^18]: Discussão sobre Soma Indexada (p. 65-68)
[^19]: Proposição 3.2: Associatividade da Soma Indexada (p. 66)
[^20]: Proposição 3.3: Comutatividade da Soma Indexada (p. 68)
[^21]: Definição de Soma Indexada para famílias (p. 69)
[^22]: Introdução a Bases e Dimensão (p. 70)
[^23]: Definição 3.3: Combinação Linear e Independência Linear para Famílias (p. 71)
[^24]: Discussão sobre Independência Linear para Famílias vs. Conjuntos (p. 72)
[^25]: Definição 3.4: Subespaço Vetorial (p. 73)
[^26]: Proposição 3.4: Propriedades de Subespaços (p. 74)
[^27]: Proposição 3.5: Subespaço Gerado (Span) (p. 75)
[^28]: Combinações Afins, Cônicas e Convexas (p. 76)
[^29]: Definição 3.6: Base de um Espaço Vetorial (p. 77)
[^30]: Lema 3.6: Extensão de Famílias Linearmente Independentes (p. 77)
[^31]: Teorema 3.7: Existência de Base (caso finito gerado) (p. 78)
[^32]: Proposição 3.8: Caracterizações Equivalentes de Base (p. 78-79)
[^33]: Proposição 3.9: Lema da Substituição (versão 1) (p. 79)
[^34]: Proposição 3.10: Lema da Substituição (versão 2, formal) (p. 81)
[^35]: Teorema 3.11: Teorema Fundamental da Dimensão (p. 82)
[^36]: Definição 3.8 e 3.9: Dimensão, Linha, Plano, Hiperplano (p. 83)
[^37]: Proposição 3.12: Unicidade da Representação em Base (p. 83)
[^38]: Definição 3.11: Espaço Vetorial K(I) (p. 84)
[^39]: Definição 3.12: Matriz (p. 85)
[^40]: Definição 3.13: Soma de Matrizes (p. 85)
[^41]: Definição de Multiplicação por Escalar para Matrizes (p. 86)
[^42]: Definição de Produto de Matrizes e Matriz Identidade (p. 86)
[^43]: Definição 3.15: Transposta de Matriz (p. 86)
[^44]: Definição 3.16: Matriz Inversa (p. 87)
[^45]: Proposição 3.13: Inversas Laterais implicam Invertibilidade (p. 87)
[^46]: Proposição 3.14: Invertibilidade e Independência Linear das Colunas (p. 88)
[^47]: Proposição 3.15: Invertibilidade e Solução Única para Ax=0 (p. 89)
[^48]: Definição 3.17: Matrizes Eij como Base de Mm,n(K) (p. 89)
[^49]: Proposição 3.16: Propriedades da Multiplicação de Matrizes (Associatividade, Bilinearidade) (p. 90)
[^50]: Definição 3.18: Aplicação Linear (p. 91)
[^51]: Definição 3.19: Imagem e Kernel de uma Aplicação Linear (p. 92)
[^52]: Definição 3.20: Posto (Rank) de uma Aplicação Linear (p. 93)
[^53]: Proposição 3.17: Propriedades de Imagem e Kernel (Subespaços, Critério de Injetividade) (p. 92, 93)
[^54]: Proposição 3.18: Extensão Homomórfica Única e Mapeamento de Bases/Geradores (p. 93)
[^55]: Proposição 3.19: Propriedade Universal de K(I) (p. 94)
[^56]: Proposição 3.20: Relação entre Geradores/LI e Unicidade/Existência de Aplicações Lineares (p. 95)
[^57]: Definição 3.21: Isomorfismo (p. 96)
[^58]: Discussão sobre Isomorfismos e Bases, Proposição 3.21 (Inversas Laterais em dim finita) (p. 97)
[^59]: Definição 3.22: Espaço Hom(E, F) (p. 98)
[^60]: Definição 3.26: Espaço Dual E* (p. 100)
[^61]: Definição 3.27: Formas Coordenadas e Base Dual (p. 102)
[^62]: Teorema 3.23: Existência de Bases Duais (p. 102)

<!-- END -->