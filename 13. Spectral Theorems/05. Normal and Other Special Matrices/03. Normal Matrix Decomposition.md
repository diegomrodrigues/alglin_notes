## Decomposição de Matrizes Normais: Uma Perspectiva Espectral

### Introdução
Este capítulo explora a decomposição de matrizes normais, um conceito fundamental na análise matricial, especialmente em espaços Euclidianos e Hermitinianos. O objetivo principal é demonstrar que, para cada matriz normal, existe uma matriz ortogonal que permite transformá-la em uma forma diagonal em blocos, facilitando a análise e simplificando cálculos [^1]. Este resultado, conhecido como o teorema espectral, tem implicações profundas em diversas áreas, incluindo otimização, teoria da informação e física quântica.

### Conceitos Fundamentais
**Definição de Matriz Normal:** Uma matriz $A$ é considerada normal se $AA^* = A^*A$, onde $A^*$ denota a transposta conjugada de $A$ [^20]. Essa propriedade é crucial, pois garante a existência de uma base ortonormal de autovetores, conforme explorado nas seções subsequentes.

**Teorema Espectral para Matrizes Normais:** O teorema espectral estabelece que, para toda matriz normal $A$, existe uma matriz ortogonal $P$ e uma matriz diagonal em blocos $D$ tal que $A = PDP^T$ [^19]. A matriz $D$ possui uma estrutura específica, onde os blocos diagonais são ou matrizes de dimensão um (escalares reais) ou matrizes de dimensão dois da forma:
$$
D_j = \begin{pmatrix}
\lambda_j & -\mu_j \\
\mu_j & \lambda_j
\end{pmatrix}
$$
onde $\lambda_j, \mu_j \in \mathbb{R}$, com $\mu_j > 0$ [^19].

**Demonstração do Teorema Espectral:** A demonstração do teorema espectral [^12] é realizada por indução na dimensão $n$ do espaço Euclidiano $E$. O caso base, $n = 1$, é trivial. Para $n \geq 2$, utiliza-se o fato de que $\mathbb{C}$ é algebricamente fechado, garantindo que a transformação linear $f_c: E_c \rightarrow E_c$ possui um autovalor $z = \lambda + i\mu$, onde $\lambda, \mu \in \mathbb{R}$. Seja $w = u + iv$ um autovetor de $f_c$ correspondente a $\lambda + i\mu$, onde $u, v \in E$.

**Proposição 17.11 [^11]:** Se $\mu \neq 0$, então $(u, v) = 0$ e $||u|| = ||v||$, o que implica que $u$ e $v$ são linearmente independentes. Se $W$ é o subespaço gerado por $u$ e $v$, então $f(W) = W$ e $f^*(W) = W$. A restrição de $f$ a $W$ possui a matriz:
$$
\begin{pmatrix}
\lambda & \mu \\
-\mu & \lambda
\end{pmatrix}
$$
Se $\mu = 0$, então $\lambda$ é um autovalor real de $f$, e ou $u$ ou $v$ é um autovetor de $f$ para $\lambda$. Se $W$ é o subespaço gerado por $u$ (se $u \neq 0$) ou por $v$ (se $u = 0$), então $f(W) \subseteq W$ e $f^*(W) \subseteq W$.

**Continuação da Demonstração:** Se $\mu = 0$, então ou $u$ ou $v$ é um autovetor de $f$ para $\lambda \in \mathbb{R}$. Seja $W$ o subespaço de dimensão 1 gerado por $e_1 = u/||u||$ se $u \neq 0$, ou por $e_1 = v/||v||$ caso contrário. É evidente que $f(W) \subseteq W$ e $f^*(W) \subseteq W$. O complemento ortogonal $W^\perp$ de $W$ tem dimensão $n-1$, e pela Proposição 17.9 [^9], temos $f(W^\perp) \subseteq W^\perp$. A restrição de $f$ a $W^\perp$ também é normal, e podemos aplicar a hipótese de indução a $W^\perp$.

Se $\mu \neq 0$, então $(u, v) = 0$ e $(u, u) = (v, v)$, e se $W$ é o subespaço gerado por $u/||u||$ e $v/||v||$, então $f(W) = W$ e $f^*(W) = W$. Também sabemos que a restrição de $f$ a $W$ tem a matriz:
$$
\begin{pmatrix}
\lambda & \mu \\
-\mu & \lambda
\end{pmatrix}
$$
em relação à base $(u/||u||, v/||v||)$. Se $\mu < 0$, definimos $\lambda_1 = \lambda$, $\mu_1 = -\mu$, $e_1 = u/||u||$, e $e_2 = v/||v||$. Se $\mu > 0$, definimos $\lambda_1 = \lambda$, $\mu_1 = \mu$, $e_1 = v/||v||$, e $e_2 = u/||u||$. Em todos os casos, verifica-se facilmente que a matriz da restrição de $f$ a $W$ em relação à base ortonormal $(e_1, e_2)$ é:
$$
A_1 = \begin{pmatrix}
\lambda_1 & -\mu_1 \\
\mu_1 & \lambda_1
\end{pmatrix}
$$
Entretanto, $W^\perp$ tem dimensão $n-2$, e pela Proposição 17.9 [^9], temos $f(W^\perp) \subseteq W^\perp$. Como a restrição de $f$ a $W^\perp$ também é normal, concluímos aplicando a hipótese de indução a $W^\perp$. $\blacksquare$

**Corolário:** O Teorema 17.18 [^19]  afirma que para cada matriz normal $A$, existe uma matriz ortogonal $P$ e uma matriz diagonal em blocos $D$ tal que $A = PDP^T$, onde $D$ é da forma descrita acima.

### Conclusão
A decomposição de matrizes normais através do teorema espectral oferece uma ferramenta poderosa para simplificar a análise e os cálculos envolvendo essas matrizes. Ao expressar uma matriz normal em termos de uma matriz ortogonal e uma matriz diagonal em blocos, é possível reduzir a complexidade de diversos problemas, facilitando a obtenção de soluções e a compreensão das propriedades espectrais da matriz. A aplicação deste teorema é vasta, abrangendo desde a otimização e a análise de dados até a física quântica e a engenharia.

### Referências
[^1]: Capítulo 17, Introdução
[^2]: Capítulo 17, Definição 17.1
[^9]: Capítulo 17, Proposição 17.9
[^11]: Capítulo 17, Proposição 17.11
[^12]: Capítulo 17, Teorema 17.12
[^19]: Capítulo 17, Teorema 17.18
[^20]: Capítulo 17, Definição 17.4
<!-- END -->