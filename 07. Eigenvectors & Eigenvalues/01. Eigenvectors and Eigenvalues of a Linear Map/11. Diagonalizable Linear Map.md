## Diagonalização de Aplicações Lineares

### Introdução
Este capítulo explora a diagonalização de aplicações lineares, um conceito fundamental na álgebra linear com profundas implicações em diversas áreas da matemática e suas aplicações. Construindo sobre a definição de **autovetores** e **autovalores** [^1], este capítulo investiga as condições sob as quais uma aplicação linear pode ser representada por uma matriz diagonal em alguma base, simplificando significativamente a análise e o cálculo envolvendo essa aplicação. A diagonalização está intimamente ligada à estrutura dos **autoespaços** associados aos autovalores.

### Conceitos Fundamentais

Uma aplicação linear $f: E \\rightarrow E$ é **diagonalizável** se existe uma base $(e_1, \\dots, e_n)$ de $E$ em relação à qual $f$ é representada por uma matriz diagonal [^1]. Equivalentemente, $f$ é diagonalizável se existe uma matriz invertível $P$ e uma matriz diagonal $D$ tal que $A = PDP^{-1}$, onde $A$ é a matriz que representa $f$ em alguma base [^1]. Os elementos diagonais de $D$ são os autovalores de $f$, e as colunas de $P$ são os autovetores correspondentes.

**Definição:** Uma aplicação linear $f$ é diagonalizável se $E$ é a soma direta de seus autoespaços [^8], isto é,

$$E = E_{\\lambda_1} \\oplus \\dots \\oplus E_{\\lambda_m},$$

onde $E_{\\lambda_i}$ é o autoespaço associado ao autovalor $\\lambda_i$ [^3].

**Proposição:** Se $u_1, \\dots, u_m$ são autovetores associados a autovalores distintos $\\lambda_1, \\dots, \\lambda_m$, então a família $(u_1, \\dots, u_m)$ é linearmente independente [^7].

*Prova:* Assuma que $(u_1, \\dots, u_m)$ é linearmente dependente. Então existem $\\mu_1, \\dots, \\mu_k \\in K$ tais que

$$\\mu_1 u_{i_1} + \\dots + \\mu_k u_{i_k} = 0,$$

onde $1 \\leq k \\leq m$, $\\mu_i \\neq 0$ para todo $i$, $1 \\leq i \\leq k$, $\\{i_1, \\dots, i_k\\} \\subseteq \\{1, \\dots, m\\}$, e nenhuma subfamília própria de $(u_{i_1}, \\dots, u_{i_k})$ é linearmente dependente (em outras palavras, consideramos uma relação de dependência com $k$ mínimo). Aplicando $f$ a essa relação de dependência, obtemos

$$\\mu_1 \\lambda_{i_1} u_{i_1} + \\dots + \\mu_k \\lambda_{i_k} u_{i_k} = 0.$$

Multiplicando a relação de dependência original por $\\lambda_{i_1}$ e subtraindo da equação acima, obtemos

$$\\mu_2 (\\lambda_{i_2} - \\lambda_{i_1}) u_{i_2} + \\dots + \\mu_k (\\lambda_{i_k} - \\lambda_{i_1}) u_{i_k} = 0,$$

que é uma relação de dependência linear não trivial entre uma subfamília própria de $(u_{i_1}, \\dots, u_{i_k})$, já que os $\\lambda_i$ são todos distintos e os $\\mu_i$ são não nulos, o que contradiz a minimalidade de $k$. Portanto, $(u_1, \\dots, u_m)$ deve ser linearmente independente. $\\blacksquare$

**Corolário:** Se $\\lambda_1, \\dots, \\lambda_m$ são todos os autovalores distintos de $f$ (onde $m \\leq n$), então temos uma soma direta

$$E_{\\lambda_1} \\oplus \\dots \\oplus E_{\\lambda_m}$$

dos autoespaços $E_{\\lambda_i}$ [^8].

Nem sempre é o caso que $E = E_{\\lambda_1} \\oplus \\dots \\oplus E_{\\lambda_m}$ [^8].

Para que $f$ seja diagonalizável, a **multiplicidade algébrica** (a multiplicidade de $\\lambda_i$ como raiz do polinômio característico) deve ser igual à **multiplicidade geométrica** (a dimensão do autoespaço $E_{\\lambda_i}$) para cada autovalor $\\lambda_i$ [^7]. Em particular, quando o polinômio característico tem $n$ raízes distintas, $f$ é diagonalizável [^8].

**Teorema Espectral para Matrizes Simétricas Reais:** Matrizes simétricas reais possuem autovalores reais e podem ser diagonalizadas por uma matriz ortogonal [^8]. Isso significa que se $A$ é uma matriz simétrica real, existe uma matriz ortogonal $Q$ (isto é, $Q^T = Q^{-1}$) e uma matriz diagonal $D$ tal que $A = QDQ^T$.

### Conclusão
A diagonalização de aplicações lineares é uma ferramenta poderosa que simplifica muitos problemas em álgebra linear. Através da decomposição de um espaço vetorial em uma soma direta de autoespaços, podemos representar aplicações lineares por matrizes diagonais, facilitando o cálculo de potências de matrizes, a solução de sistemas de equações diferenciais lineares e a análise de transformações lineares. O Teorema Espectral para matrizes simétricas reais garante que uma ampla classe de matrizes pode ser diagonalizada, tornando a diagonalização uma técnica amplamente aplicável.

### Referências
[^1]: Capítulo 15, Eigenvectors and Eigenvalues, p. 553.
[^3]: Capítulo 15, Eigenvectors and Eigenvalues, p. 555.
[^7]: Capítulo 15, Eigenvectors and Eigenvalues, p. 559.
[^8]: Capítulo 15, Eigenvectors and Eigenvalues, p. 560.
<!-- END -->