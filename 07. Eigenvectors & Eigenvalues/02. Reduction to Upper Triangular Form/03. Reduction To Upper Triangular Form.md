## Redução à Forma Triangular Superior

### Introdução
Como vimos anteriormente, nem toda aplicação linear em um espaço vetorial complexo pode ser diagonalizada. A busca por uma forma mais geral nos leva ao conceito de *triangularização*, onde buscamos uma base em relação à qual a matriz representativa possua entradas nulas abaixo da diagonal principal [^561].

### Conceitos Fundamentais

**Definição de Matriz Triangular Superior:**
Uma matriz quadrada $A$ é dita *triangular superior* se todas as suas entradas abaixo da diagonal principal são zero, ou seja, $a_{ij} = 0$ sempre que $j < i$, com $1 \leq i, j \leq n$ [^561].

**Teorema da Triangularização:**
Dado um espaço vetorial de dimensão finita sobre um corpo $K$, para qualquer aplicação linear $f: E \rightarrow E$, existe uma base $(u_1, ..., u_n)$ em relação à qual $f$ é representada por uma matriz triangular superior (em $M_n(K)$) se e somente se todos os *eigenvalues* de $f$ pertencem a $K$ [^561]. Equivalentemente, para toda matriz $n \times n$, $A \in M_n(K)$, existe uma matriz inversível $P$ e uma matriz triangular superior $T$ (ambas em $M_n(K)$) tal que $A = PTP^{-1}$ se e somente se todos os *eigenvalues* de $A$ pertencem a $K$ [^561].

*Prova:*
Se existe uma base $(u_1, ..., u_n)$ em relação à qual $f$ é representada por uma matriz triangular superior $T$ em $M_n(K)$, então os *eigenvalues* de $f$ são as entradas diagonais de $T$ e, portanto, pertencem a $K$ [^561].

Reciprocamente, procedemos por indução na dimensão $n$ de $E$ [^561]. Para $n = 1$, o resultado é trivial [^561]. Se $n > 1$, como por hipótese $f$ possui todos os seus *eigenvalues* em $K$, escolhemos um *eigenvalue* $\lambda_1 \in K$ de $f$, e seja $u_1$ um *eigenvector* correspondente [^561]. Podemos encontrar $n-1$ vetores $(v_2, ..., v_n)$ tais que $(u_1, v_2, ..., v_n)$ seja uma base de $E$ [^561]. Seja $F$ o subespaço de dimensão $n-1$ gerado por $(v_2, ..., v_n)$ [^561]. Na base $(u_1, v_2, ..., v_n)$, a matriz de $f$ tem a forma

$$\
U = \begin{pmatrix}
\lambda_1 & a_{12} & \cdots & a_{1n} \\
0 & a_{22} & \cdots & a_{2n} \\
\vdots & \vdots & \ddots & \vdots \\
0 & a_{n2} & \cdots & a_{nn}
\end{pmatrix}
$$

pois sua primeira coluna contém as coordenadas de $\lambda_1 u_1$ sobre a base $(u_1, v_2, ..., v_n)$ [^561]. Seja $p: E \rightarrow F$ a projeção definida por $p(u_1) = 0$ e $p(v_i) = v_i$ para $2 \leq i \leq n$ [^561]. A aplicação linear $g: F \rightarrow F$ definida como a restrição de $p \circ f$ a $F$ é representada pela matriz $V = (a_{ij})_{2 \leq i, j \leq n}$ na base $(v_2, ..., v_n)$ [^562]. Precisamos provar que todos os *eigenvalues* de $g$ pertencem a $K$ [^562]. No entanto, como as entradas da primeira coluna de $U$ são todas zero para $i = 2, ..., n$, temos

$$\
\chi_U(X) = \det(XI - U) = (X - \lambda_1) \det(XI - V) = (X - \lambda_1) \chi_V(X),
$$

onde $\chi_U(X)$ é o polinômio característico de $U$ e $\chi_V(X)$ é o polinômio característico de $V$ [^562]. Segue que $\chi_V(X)$ divide $\chi_U(X)$, e como todas as raízes de $\chi_U(X)$ estão em $K$, todas as raízes de $\chi_V(X)$ também estão em $K$ [^562]. Consequentemente, podemos aplicar a hipótese de indução, e existe uma base $(u_2, ..., u_n)$ de $F$ tal que $g$ é representada por uma matriz triangular superior $(b_{ij})_{1 \leq i, j \leq n-1}$ [^562]. No entanto,

$$\
E = Ku_1 \oplus F,
$$

e assim $(u_1, ..., u_n)$ é uma base para $E$ [^562]. Como $p$ é a projeção de $E = Ku_1 \oplus F$ sobre $F$ e $g: F \rightarrow F$ é a restrição de $p \circ f$ a $F$, temos $f(u_1) = \lambda_1 u_1$ e

$$\
f(u_{i+1}) = a_{1i}u_1 + \sum_{j=1}^{i} b_{ij}u_{j+1}
$$

para algum $a_{1i} \in K$, quando $1 \leq i \leq n-1$ [^562]. Mas então a matriz de $f$ com respeito a $(u_1, ..., u_n)$ é triangular superior [^562].

Para a versão matricial, assumimos que $A$ é a matriz de $f$ com respeito a alguma base [^562]. Então, acabamos de provar que existe uma matriz de mudança de base $P$ tal que $A = PTP^{-1}$, onde $T$ é triangular superior [^562]. $\blacksquare$

**Observação Importante:**
Se $A = PTP^{-1}$, onde $T$ é triangular superior, as entradas diagonais de $T$ são os *eigenvalues* $\lambda_1, ..., \lambda_n$ de $A$ [^562]. De fato, $A$ e $T$ possuem o mesmo polinômio característico [^562]. Além disso, se $A$ é uma matriz real cujos *eigenvalues* são todos reais, então $P$ pode ser escolhida real, e se $A$ é uma matriz racional cujos *eigenvalues* são todos racionais, então $P$ pode ser escolhida racional [^562]. Como qualquer polinômio sobre $\mathbb{C}$ tem todas as suas raízes em $\mathbb{C}$, o Teorema 15.5 implica que toda matriz $n \times n$ complexa pode ser triangularizada [^562].

**Lema de Schur:**
Se $E$ é um espaço hermitiano (ver Capítulo 14), a prova do Teorema 15.5 pode ser facilmente adaptada para provar que existe uma base ortonormal $(u_1, ..., u_n)$ em relação à qual a matriz de $f$ é triangular superior [^562]. Este resultado é geralmente conhecido como o *Lema de Schur* [^562].

**Decomposição de Schur:**
Dada qualquer aplicação linear $f: E \rightarrow E$ sobre um espaço hermitiano complexo $E$, existe uma base ortonormal $(u_1, ..., u_n)$ em relação à qual $f$ é representada por uma matriz triangular superior [^562]. Equivalentemente, para toda matriz $A \in M_n(\mathbb{C})$, existe uma matriz unitária $U$ e uma matriz triangular superior $T$ tal que $A = UTU^*$ [^562].

### Conclusão
A redução à forma triangular superior é uma ferramenta poderosa na análise de *eigenvalues* e *eigenvectors*, especialmente quando a diagonalização não é possível [^562]. O Teorema 15.5 e o Lema de Schur fornecem métodos para triangularizar matrizes e aplicações lineares, com importantes implicações teóricas e práticas [^562].

### Referências
[^561]: Capítulo 15, Eigenvectors and Eigenvalues, página 561
[^562]: Capítulo 15, Eigenvectors and Eigenvalues, página 562
<!-- END -->