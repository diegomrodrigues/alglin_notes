## Triangularização de uma Aplicação Linear

### Introdução
Como vimos anteriormente, nem toda aplicação linear em um espaço vetorial complexo pode ser diagonalizada. A **triangularização** surge como uma alternativa, buscando uma base na qual a representação matricial possua apenas zeros abaixo da diagonal principal [^561]. Este processo simplifica cálculos e revela propriedades importantes da aplicação linear. Em continuidade ao conceito de diagonalização, exploraremos a triangularização como uma forma de simplificação e análise de aplicações lineares.

### Conceitos Fundamentais

Uma matriz quadrada $A$ é dita **triangular superior** se tiver a seguinte forma [^561]:

$$
A = \begin{pmatrix}
a_{11} & a_{12} & a_{13} & \cdots & a_{1,n-1} & a_{1n} \\
0 & a_{22} & a_{23} & \cdots & a_{2,n-1} & a_{2 n} \\
0 & 0 & a_{33} & \cdots & a_{3,n-1} & a_{3 n} \\
\vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\
0 & 0 & 0 & \cdots & a_{n-1,n-1} & a_{n-1n} \\
0 & 0 & 0 & \cdots & 0 & a_{nn}
\end{pmatrix}
$$

Formalmente, $a_{ij} = 0$ sempre que $j < i$, com $1 \leq i, j \leq n$ [^561].

**Teorema 15.5:** Dado um espaço vetorial de dimensão finita sobre um corpo $K$, para qualquer aplicação linear $f: E \rightarrow E$, existe uma base $(u_1, ..., u_n)$ com respeito à qual $f$ é representada por uma matriz triangular superior (em $M_n(K)$) se e somente se todos os autovalores de $f$ pertencem a $K$ [^561]. Equivalentemente, para cada matriz $n \times n$, $A \in M_n(K)$, existe uma matriz inversível $P$ e uma matriz triangular superior $T$ (ambas em $M_n(K)$) tal que $A = PTP^{-1}$ se e somente se todos os autovalores de $A$ pertencem a $K$ [^561].

*Prova:* Se existe uma base $(u_1, ..., u_n)$ com respeito à qual $f$ é representada por uma matriz triangular superior $T$ em $M_n(K)$, então os autovalores de $f$ são as entradas diagonais de $T$, e portanto, todos os autovalores de $f$ pertencem a $K$ [^561].

Para a recíproca, procedemos por indução na dimensão $n$ de $E$ [^561]. Para $n = 1$, o resultado é trivial. Se $n > 1$, como por hipótese $f$ tem todos os seus autovalores em $K$, escolhemos um autovalor $\lambda_1 \in K$ de $f$, e seja $u_1$ um autovetor correspondente (não nulo) [^561]. Podemos encontrar $n - 1$ vetores $(v_2, ..., v_n)$ tais que $(u_1, v_2, ..., v_n)$ é uma base de $E$, e seja $F$ o subespaço de dimensão $n - 1$ gerado por $(v_2, ..., v_n)$ [^561]. Na base $(u_1, v_2, ..., v_n)$, a matriz de $f$ tem a forma [^561]:

$$
U = \begin{pmatrix}
\lambda_1 & a_{12} & \cdots & a_{1n} \\
0 & a_{22} & \cdots & a_{2n} \\
\vdots & \vdots & \ddots & \vdots \\
0 & a_{n2} & \cdots & a_{nn}
\end{pmatrix}
$$

Como a primeira coluna contém as coordenadas de $\lambda_1 u_1$ sobre a base $(u_1, v_2, ..., v_n)$ [^561]. Seja $p: E \rightarrow F$ a projeção definida tal que $p(u_1) = 0$ e $p(v_i) = v_i$ quando $2 \leq i \leq n$, e seja $g: F \rightarrow F$ a aplicação linear definida como a restrição de $p \circ f$ a $F$ [^561]. A aplicação $g$ é representada pela matriz $(a_{ij})_{2 \leq i,j \leq n}$ [^561]. Precisamos provar que todos os autovalores de $g$ pertencem a $K$ [^562]. No entanto, como as entradas na primeira coluna de $U$ são todas zero para $i = 2, ..., n$, obtemos [^562]:

$$
\chi_U(X) = \det(XI - U) = (X - \lambda_1) \det(XI - V) = (X - \lambda_1) \chi_V(X),
$$

onde $\chi_U(X)$ é o polinômio característico de $U$ e $\chi_V(X)$ é o polinômio característico de $V$ [^562]. Segue que $\chi_V(X)$ divide $\chi_U(X)$, e como todas as raízes de $\chi_U(X)$ estão em $K$, todas as raízes de $\chi_V(X)$ também estão em $K$ [^562]. Consequentemente, podemos aplicar a hipótese de indução, e existe uma base $(u_2, ..., u_n)$ de $F$ tal que $g$ é representada por uma matriz triangular superior $(b_{ij})_{1 \leq i,j \leq n-1}$ [^562]. No entanto,

$$
E = Ku_1 \oplus F,
$$

e assim $(u_1, ..., u_n)$ é uma base para $E$ [^562]. Como $p$ é a projeção de $E = Ku_1 \oplus F$ sobre $F$ e $g: F \rightarrow F$ é a restrição de $p \circ f$ a $F$, temos [^562]:

$$
f(u_1) = \lambda_1 u_1
$$

e

$$
f(u_{i+1}) = a_{1i} u_1 + \sum_{j=1}^{i} b_{ij} u_{j+1}
$$

para algum $a_{1i} \in K$, quando $1 \leq i \leq n - 1$ [^562]. Mas então a matriz de $f$ com respeito a $(u_1, ..., u_n)$ é triangular superior [^562].

Para a versão matricial, assumimos que $A$ é a matriz de $f$ com respeito a alguma base [^562]. Então, acabamos de provar que existe uma mudança de matriz de base $P$ tal que $A = PTP^{-1}$ onde $T$ é triangular superior. $\blacksquare$

Se $A = PTP^{-1}$ onde $T$ é triangular superior, observe que as entradas diagonais de $T$ são os autovalores $\lambda_1, ..., \lambda_n$ de $A$ [^562]. De fato, $A$ e $T$ têm o mesmo polinômio característico [^562]. Além disso, se $A$ é uma matriz real cujos autovalores são todos reais, então $P$ pode ser escolhido para ser real, e se $A$ é uma matriz racional cujos autovalores são todos racionais, então $P$ pode ser escolhido para ser racional [^562]. Como qualquer polinômio sobre $\mathbb{C}$ tem todas as suas raízes em $\mathbb{C}$, o Teorema 15.5 implica que cada matriz complexa $n \times n$ pode ser triangularizada [^562].

Se $E$ é um espaço Hermitiano (ver Capítulo 14), a prova do Teorema 15.5 pode ser facilmente adaptada para provar que existe uma base ortonormal $(u_1, ..., u_n)$ com respeito à qual a matriz de $f$ é triangular superior [^562]. Isso é geralmente conhecido como o Lema de Schur [^562].

**Teorema 15.6 (Decomposição de Schur):** Dada qualquer aplicação linear $f: E \rightarrow E$ sobre um espaço Hermitiano complexo $E$, existe uma base ortonormal $(u_1, ..., u_n)$ com respeito à qual $f$ é representada por uma matriz triangular superior [^562]. Equivalentemente, para cada matriz $A \in M_n(\mathbb{C})$, existe uma matriz unitária $U$ e uma matriz triangular superior $T$ tal que $A = UTU^*$ [^562].

### Conclusão

A triangularização de uma aplicação linear oferece uma alternativa valiosa à diagonalização, especialmente quando esta última não é possível [^561]. Ao encontrar uma base apropriada, a representação matricial da aplicação se torna triangular superior, o que simplifica cálculos e facilita a análise das propriedades da aplicação [^561]. O Teorema 15.5 e a Decomposição de Schur fornecem as bases teóricas para a existência e construção dessas representações triangulares [^562].

### Referências
[^561]: Capítulo 15, Eigenvectors and Eigenvalues, página 561.
[^562]: Capítulo 15, Eigenvectors and Eigenvalues, página 562.
<!-- END -->